{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Snowpark Scala in Workspace Notebooks (Prototype)\n",
    "\n",
    "This notebook demonstrates running **Scala** and **Snowpark Scala** within a\n",
    "Snowflake Workspace Notebook using a `%%scala` cell magic powered by JPype.\n",
    "\n",
    "**Architecture:** Python kernel → JPype (JNI) → JVM (in-process) → Scala REPL → Snowpark\n",
    "\n",
    "---\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Installation & Configuration](#1)\n",
    "2. [Basic Scala Execution](#2)\n",
    "3. [Python ↔ Scala Interop](#3)\n",
    "4. [Snowpark Scala Session](#4)\n",
    "5. [Diagnostics](#5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"1\"></a>\n",
    "## 1. Installation & Configuration\n",
    "\n",
    "### 1.1 Install JDK, Scala, and Snowpark JAR\n",
    "\n",
    "Run the setup script. This takes ~2-4 minutes on first run (installs\n",
    "OpenJDK 17, Scala 2.12, Ammonite, Snowpark JAR via micromamba + coursier).\n",
    "\n",
    "On subsequent runs it detects what is already installed and skips those steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!bash setup_scala_environment.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Configure Python Environment & Register %%scala Magic\n",
    "\n",
    "This cell:\n",
    "1. Sets `JAVA_HOME` and `PATH`\n",
    "2. Installs JPype1 into the kernel venv (if needed)\n",
    "3. Starts the JVM in-process with the Scala + Snowpark classpath\n",
    "4. Initialises the Scala REPL (Ammonite-lite or IMain)\n",
    "5. Registers the `%%scala` cell magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scala_helpers import setup_scala_environment\n",
    "\n",
    "result = setup_scala_environment()\n",
    "\n",
    "print(f\"Success:          {result['success']}\")\n",
    "print(f\"Java version:     {result['java_version']}\")\n",
    "print(f\"Scala version:    {result['scala_version']}\")\n",
    "print(f\"Interpreter type: {result['interpreter_type']}\")\n",
    "print(f\"JVM started:      {result['jvm_started']}\")\n",
    "print(f\"Magic registered: {result['magic_registered']}\")\n",
    "\n",
    "if result['errors']:\n",
    "    print(f\"\\nErrors:\")\n",
    "    for err in result['errors']:\n",
    "        print(f\"  - {err}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Verify Scala Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala\n",
    "println(s\"Hello from Scala ${util.Properties.versionString}\")\n",
    "println(s\"Java: ${System.getProperty(\"java.version\")}\")\n",
    "println(s\"OS: ${System.getProperty(\"os.name\")}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"2\"></a>\n",
    "## 2. Basic Scala Execution\n",
    "\n",
    "State persists across `%%scala` cells — vals, defs, imports, and classes\n",
    "defined in one cell are available in the next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala\n",
    "// Define a value\n",
    "val greeting = \"Hello from Snowflake Workspace Notebook!\"\n",
    "println(greeting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala\n",
    "// Previous cell's 'greeting' is still in scope\n",
    "println(s\"Greeting length: ${greeting.length}\")\n",
    "\n",
    "// Define a function\n",
    "def factorial(n: Int): BigInt = if (n <= 1) 1 else n * factorial(n - 1)\n",
    "\n",
    "println(s\"10! = ${factorial(10)}\")\n",
    "println(s\"20! = ${factorial(20)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala\n",
    "// Collections and functional programming\n",
    "val numbers = (1 to 10).toList\n",
    "val squares = numbers.map(n => n * n)\n",
    "val evenSquares = squares.filter(_ % 2 == 0)\n",
    "\n",
    "println(s\"Numbers:      $numbers\")\n",
    "println(s\"Squares:      $squares\")\n",
    "println(s\"Even squares: $evenSquares\")\n",
    "println(s\"Sum:          ${evenSquares.sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala\n",
    "// Case classes and pattern matching\n",
    "case class Employee(name: String, department: String, salary: Double)\n",
    "\n",
    "val employees = List(\n",
    "  Employee(\"Alice\", \"Engineering\", 120000),\n",
    "  Employee(\"Bob\", \"Engineering\", 115000),\n",
    "  Employee(\"Carol\", \"Data Science\", 130000),\n",
    "  Employee(\"Dave\", \"Data Science\", 125000),\n",
    "  Employee(\"Eve\", \"Product\", 110000)\n",
    ")\n",
    "\n",
    "val byDept = employees.groupBy(_.department).map {\n",
    "  case (dept, emps) => (dept, emps.map(_.salary).sum / emps.size)\n",
    "}\n",
    "\n",
    "byDept.toList.sortBy(-_._2).foreach {\n",
    "  case (dept, avgSalary) =>\n",
    "    println(f\"  $dept%-20s $$${avgSalary}%,.0f\")\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"3\"></a>\n",
    "## 3. Python ↔ Scala Interoperability\n",
    "\n",
    "### 3.1 Push values from Python to Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scala_helpers import push_to_scala\n",
    "\n",
    "# Push a string and number from Python into the Scala interpreter\n",
    "push_to_scala(\"pythonMessage\", \"Hello from Python!\")\n",
    "push_to_scala(\"pythonNumber\", 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala\n",
    "// Access the variables pushed from Python\n",
    "println(s\"From Python: $pythonMessage\")\n",
    "println(s\"Number: $pythonNumber\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Pull values from Scala to Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala\n",
    "val scalaResult = (1 to 100).sum\n",
    "println(s\"Sum 1..100 = $scalaResult\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scala_helpers import pull_from_scala\n",
    "\n",
    "value = pull_from_scala(\"scalaResult\")\n",
    "print(f\"Pulled from Scala: {value} (type: {type(value).__name__})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"4\"></a>\n",
    "## 4. Snowpark Scala Session\n",
    "\n",
    "### 4.1 Inject credentials from Python session\n",
    "\n",
    "The Python kernel already has an active Snowpark session. We extract its\n",
    "credentials and set them as environment variables for the Scala side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowflake.snowpark.context import get_active_session\n",
    "from scala_helpers import inject_session_credentials\n",
    "\n",
    "session = get_active_session()\n",
    "creds = inject_session_credentials(session)\n",
    "\n",
    "print(\"Credentials injected:\")\n",
    "for k, v in creds.items():\n",
    "    if k == \"SNOWFLAKE_PAT\":\n",
    "        print(f\"  {k}: {'SET' if v else 'NOT SET'}\")\n",
    "    else:\n",
    "        print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Create PAT for authentication\n",
    "\n",
    "If you haven't already created a PAT (from the R notebook setup), create one now.\n",
    "This is the same PATManager used for R/ADBC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment and run if SNOWFLAKE_PAT is not already set\n",
    "# from r_helpers import PATManager\n",
    "# pat_mgr = PATManager(session)\n",
    "# pat_result = pat_mgr.create_pat(days_to_expiry=1, force_recreate=True)\n",
    "# print(pat_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Create Snowpark Scala Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scala_helpers import create_snowpark_scala_session_code\n",
    "\n",
    "# Preview the code that will be executed\n",
    "code = create_snowpark_scala_session_code(use_pat=True)\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala\n",
    "import com.snowflake.snowpark._\n",
    "import com.snowflake.snowpark.functions._\n",
    "\n",
    "val session = Session.builder.configs(Map(\n",
    "  \"URL\"           -> sys.env(\"SNOWFLAKE_URL\"),\n",
    "  \"USER\"          -> sys.env(\"SNOWFLAKE_USER\"),\n",
    "  \"ROLE\"          -> sys.env(\"SNOWFLAKE_ROLE\"),\n",
    "  \"DB\"            -> sys.env(\"SNOWFLAKE_DATABASE\"),\n",
    "  \"SCHEMA\"        -> sys.env(\"SNOWFLAKE_SCHEMA\"),\n",
    "  \"WAREHOUSE\"     -> sys.env(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "  \"TOKEN\"         -> sys.env(\"SNOWFLAKE_PAT\"),\n",
    "  \"AUTHENTICATOR\" -> \"oauth\"\n",
    ")).create\n",
    "\n",
    "println(\"Snowpark Scala session created!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Query Snowflake from Scala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala\n",
    "// Basic query\n",
    "session.sql(\"SELECT CURRENT_USER() AS user, CURRENT_ROLE() AS role, CURRENT_WAREHOUSE() AS warehouse\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala\n",
    "// DataFrame operations\n",
    "val df = session.sql(\"SELECT 'Scala' AS language, 'Snowpark' AS framework, CURRENT_TIMESTAMP() AS ts\")\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala\n",
    "// Show available tables\n",
    "session.sql(\"SHOW TABLES LIMIT 5\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Cross-language Data Sharing\n",
    "\n",
    "Both Python and Scala sessions connect to the same Snowflake account.\n",
    "Use temp tables to share data between them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python: create a temp table\n",
    "session.sql(\"\"\"\n",
    "    CREATE OR REPLACE TEMPORARY TABLE scala_demo (\n",
    "        id INT, name STRING, value DOUBLE\n",
    "    ) AS\n",
    "    SELECT column1, column2, column3 FROM VALUES\n",
    "        (1, 'alpha', 10.5),\n",
    "        (2, 'beta', 20.3),\n",
    "        (3, 'gamma', 30.7)\n",
    "\"\"\").collect()\n",
    "print(\"Temp table 'scala_demo' created from Python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%scala\n",
    "// Scala: read the temp table created by Python\n",
    "val demo = session.table(\"scala_demo\")\n",
    "demo.show()\n",
    "\n",
    "// Compute something\n",
    "val total = demo.select(sum(col(\"VALUE\"))).collect()(0).getDouble(0)\n",
    "println(s\"Total value: $total\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<a id=\"5\"></a>\n",
    "## 5. Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scala_helpers import print_diagnostics\n",
    "print_diagnostics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
