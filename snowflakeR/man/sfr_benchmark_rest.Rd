% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/rest_inference.R
\name{sfr_benchmark_rest}
\alias{sfr_benchmark_rest}
\title{Benchmark SPCS inference via REST}
\usage{
sfr_benchmark_rest(
  endpoint,
  new_data,
  n = 10L,
  token = NULL,
  conn = NULL,
  method = "predict",
  verbose = TRUE
)
}
\arguments{
\item{endpoint}{An \code{sfr_endpoint} object or URL string.}

\item{new_data}{A data.frame with input data.}

\item{n}{Integer. Number of iterations. Default: 10.}

\item{token}{Character or NULL. Snowflake PAT.}

\item{method}{Character. Model method name. Default: \code{"predict"}.}

\item{verbose}{Logical. Print per-iteration results? Default: \code{TRUE}.}
}
\value{
A list (invisibly) with timing stats (same structure as
\code{\link[=sfr_benchmark_inference]{sfr_benchmark_inference()}}).
}
\description{
Runs \code{n} inference requests directly via the REST endpoint and reports
timing statistics.  Measures true service latency without Python bridge
overhead.
}
\examples{
\dontrun{
ep <- sfr_service_endpoint(conn, "mpg_service")
bench <- sfr_benchmark_rest(ep, new_data, n = 20)
}

}
