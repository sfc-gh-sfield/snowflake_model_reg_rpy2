{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat_minor": 4,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000001",
      "metadata": {
        "name": "md__title",
        "codeCollapsed": true
      },
      "source": "# Model Registry: Train, Register, and Serve R Models\n\nThis notebook demonstrates the `snowflakeR` package workflow for registering R models\nin the Snowflake Model Registry and running inference.\n\n**What you'll do:**\n1. Train models in R (as usual)\n2. Test predictions locally\n3. Register to Snowflake Model Registry with one function call\n4. Manage versions and metrics\n5. Run remote inference via SPCS\n\n**Under the hood:** `snowflakeR` auto-generates a Python `CustomModel` wrapper\nthat uses `rpy2` to load and call your R model. You never write Python.\n\nThis notebook is for **Snowflake Workspace Notebooks** (Python kernel + `%%R` magic).\nFor local environments (RStudio, Posit, JupyterLab), use `local_model_registry.ipynb`.\n\n**Before you start:** Copy `notebook_config.yaml.template` to `notebook_config.yaml`\nand edit it with your warehouse, database, and schema.\n\n**Sections:**\n1. [Setup](#section-1-setup)\n2. [Connect](#section-2-connect)\n3. [Train a Model](#section-3-train)\n4. [Test Locally](#section-4-local-test)\n5. [Register to Snowflake](#section-5-register)\n6. [Manage Models](#section-6-manage)\n7. [Remote Inference](#section-7-inference)\n8. [Advanced: Custom Predict Code](#section-8-custom-predict)\n9. [Cleanup](#section-9-cleanup)\n\n---"
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000002",
      "metadata": {
        "name": "md__setup_header",
        "codeCollapsed": true
      },
      "source": "## 1. Setup\n\n### Step 1: Install R environment (~3 minutes, first time only)"
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000003",
      "metadata": {
        "language": "python",
        "name": "PY__install_r_env"
      },
      "source": "# Install R + rpy2 via setup script (included in this directory)\n!bash setup_r_environment.sh --basic",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000004",
      "metadata": {
        "name": "md__configure_rpy2",
        "codeCollapsed": true
      },
      "source": "### Step 2: Configure rpy2 and register `%%R` magic"
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000005",
      "metadata": {
        "language": "python",
        "name": "PY__setup_rpy2"
      },
      "source": "from r_helpers import setup_r_environment\nresult = setup_r_environment()\n\nif result['success']:\n    print(f\"R {result['r_version']} ready. %%R magic registered.\")\nelse:\n    print(\"Setup failed:\", result['errors'])",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000006",
      "metadata": {
        "name": "md__install_snowflakeR",
        "codeCollapsed": true
      },
      "source": "### Step 3: Install and load snowflakeR"
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000007",
      "metadata": {
        "language": "python",
        "name": "PY__resolve_pkg_path"
      },
      "source": "# Resolve the absolute path to the snowflakeR package root.\n# This notebook lives at snowflakeR/inst/notebooks/, so the package root\n# (the directory containing DESCRIPTION) is two levels up.\nimport os\nsnowflaker_path = os.path.normpath(os.path.join(os.getcwd(), \"..\", \"..\"))\nprint(f\"snowflakeR path: {snowflaker_path}\")\nassert os.path.isfile(os.path.join(snowflaker_path, \"DESCRIPTION\")), \\\n    f\"DESCRIPTION not found in {snowflaker_path} -- check your working directory\"\n\n# Export as env var so R can read it via Sys.getenv()\nos.environ[\"SNOWFLAKER_PATH\"] = snowflaker_path",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000008",
      "metadata": {
        "language": "python",
        "name": "R__install_snowflakeR"
      },
      "source": "%%R\n# Suppress interactive prompts (Workspace Notebooks have no stdin)\noptions(repos = c(CRAN = \"https://cloud.r-project.org\"))\n\n# Remove stale install (if any) so we always get the latest source\ntry(remove.packages(\"snowflakeR\"), silent = TRUE)\n\n# Install required dependencies from CRAN first (repos=NULL skips CRAN)\ndeps <- c(\"DBI\", \"methods\", \"reticulate\", \"cli\", \"rlang\")\nfor (pkg in deps) {\n  if (!requireNamespace(pkg, quietly = TRUE))\n    install.packages(pkg, type = \"source\", quiet = TRUE)\n}\n\n# Option 1: Install from local repo cloned into the Workspace\n# (absolute path resolved in the previous Python cell via env var)\ninstall.packages(Sys.getenv(\"SNOWFLAKER_PATH\"), repos = NULL, type = \"source\")\n\n# Option 2: Install from GitHub via pak (once published to public repo)\n# install.packages(\"pak\", type = \"source\", quiet = TRUE)\n# pak::pak(\"Snowflake-Labs/snowflakeR\", ask = FALSE, upgrade = FALSE)\n\nlibrary(snowflakeR)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000009",
      "metadata": {
        "name": "md__connect_header",
        "codeCollapsed": true
      },
      "source": "---\n## 2. Connect & Set Execution Context\n\nWorkspace Notebooks do **not** auto-set database or schema.\n`sfr_load_notebook_config()` reads `notebook_config.yaml` and runs\n`USE WAREHOUSE / DATABASE / SCHEMA` to set the execution context.\n\nAll table references in this notebook use fully qualified names via `sfr_fqn()`."
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000010",
      "metadata": {
        "language": "python",
        "name": "R__connect_and_config"
      },
      "source": "%%R\n# Connect (auto-detects Workspace session)\nconn <- sfr_connect()\n\n# Load config and set execution context\nconn <- sfr_load_notebook_config(conn)\nconn\n\n# Create a Model Registry context\nreg <- sfr_model_registry(conn)\nreg",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000011",
      "metadata": {
        "name": "md__train_header",
        "codeCollapsed": true
      },
      "source": "---\n## 3. Train a Model\n\n### Example A: Linear regression on mtcars\n\nTrain any R model as you normally would -- nothing snowflakeR-specific here."
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000012",
      "metadata": {
        "language": "python",
        "name": "R__train_model"
      },
      "source": "%%R\n# Train a simple linear model\nmodel_lm <- lm(mpg ~ wt + hp + cyl, data = mtcars)\nsummary(model_lm)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000013",
      "metadata": {
        "name": "md__timeseries_example",
        "codeCollapsed": true
      },
      "source": "### Example B: Time series with forecast\n\n```r\n%%R\nlibrary(forecast)\nmodel_arima <- auto.arima(AirPassengers)\nsummary(model_arima)\n```\n\n---"
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000014",
      "metadata": {
        "name": "md__test_local_header",
        "codeCollapsed": true
      },
      "source": "## 4. Test Locally\n\n`sfr_predict_local()` runs the **exact same prediction logic** that will execute\ninside Snowflake, but entirely in R. Use this to verify before registering."
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000015",
      "metadata": {
        "language": "python",
        "name": "R__test_local"
      },
      "source": "%%R\n# Create test data\ntest_data <- data.frame(\n  wt  = c(2.5, 3.0, 3.5, 4.0),\n  hp  = c(110, 150, 200, 245),\n  cyl = c(4L, 6L, 8L, 8L)\n)\n\n# Test locally -- same predict path as remote\npreds <- sfr_predict_local(model_lm, test_data)\nrprint(cbind(test_data, preds))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000016",
      "metadata": {
        "name": "md__register_header",
        "codeCollapsed": true
      },
      "source": "---\n## 5. Register to Snowflake\n\nOne call to `sfr_log_model()` handles everything:\n- Saves the R model to `.rds`\n- Auto-generates a Python `CustomModel` wrapper\n- Registers in the Snowflake Model Registry"
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000017",
      "metadata": {
        "language": "python",
        "name": "R__register_model"
      },
      "source": "%%R\nmv <- sfr_log_model(\n  reg,\n  model        = model_lm,\n  model_name   = \"SFR_DEMO_MPG\",\n  version_name = \"V1\",\n  input_cols   = list(wt = \"double\", hp = \"double\", cyl = \"integer\"),\n  output_cols  = list(prediction = \"double\"),\n  comment      = \"Linear regression: MPG from weight, horsepower, cylinders\"\n)\n\nmv",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000018",
      "metadata": {
        "name": "md__log_model_params",
        "codeCollapsed": true
      },
      "source": "### Key parameters for `sfr_log_model()`\n\n| Parameter | Description |\n|-----------|-------------|\n| `model` | Any R object that can be `saveRDS()`'d |\n| `model_name` | Registry name (uppercase recommended) |\n| `input_cols` | Named list: column name -> type (`double`, `integer`, `string`, `boolean`) |\n| `output_cols` | Named list: output column name -> type |\n| `predict_fn` | R function name (default: `\"predict\"`) |\n| `predict_pkgs` | R packages needed at inference time |\n| `conda_deps` | Extra conda packages (`r-base`, `rpy2`, and `numpy<2.0` always included) |\n| `target_platforms` | `\"SNOWPARK_CONTAINER_SERVICES\"` (default) or `\"WAREHOUSE\"` |\n\n> **Container version note:** The default `conda_deps` include `numpy<2.0`.\n> This is required because without it the SPCS conda solver resolves to\n> Python 3.12 + numpy 2.x for R model containers, which triggers a\n> server-side `recarray has no attribute fillna` crash. Pinning `numpy<2.0`\n> causes the solver to select Python 3.11 (matching pure Python model\n> containers), which avoids the bug entirely.\n\n---"
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000019",
      "metadata": {
        "name": "md__manage_header",
        "codeCollapsed": true
      },
      "source": "## 6. Manage Models\n\n### List and inspect models"
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000020",
      "metadata": {
        "language": "python",
        "name": "R__list_models"
      },
      "source": "%%R\n# List all models in the registry\nmodels <- sfr_show_models(reg)\nrprint(models)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000021",
      "metadata": {
        "language": "python",
        "name": "R__get_model"
      },
      "source": "%%R\n# Get a specific model\nm <- sfr_get_model(reg, \"SFR_DEMO_MPG\")\nm\n\n# Show versions\nsfr_show_model_versions(reg, \"SFR_DEMO_MPG\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000022",
      "metadata": {
        "name": "md__metrics_header",
        "codeCollapsed": true
      },
      "source": "### Metrics\n\nAttach evaluation metrics to model versions:"
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000023",
      "metadata": {
        "language": "python",
        "name": "R__set_metrics"
      },
      "source": "%%R\n# Calculate and set metrics\npreds_train <- predict(model_lm, mtcars)\nrmse <- sqrt(mean((mtcars$mpg - preds_train)^2))\nr_sq <- summary(model_lm)$r.squared\n\nsfr_set_model_metric(reg, \"SFR_DEMO_MPG\", \"V1\", \"rmse\", rmse)\nsfr_set_model_metric(reg, \"SFR_DEMO_MPG\", \"V1\", \"r_squared\", r_sq)\n\nrcat(sprintf(\"RMSE: %.3f, R-squared: %.3f\", rmse, r_sq))",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000024",
      "metadata": {
        "language": "python",
        "name": "R__show_metrics"
      },
      "source": "%%R\n# Retrieve metrics\nsfr_show_model_metrics(reg, \"SFR_DEMO_MPG\", \"V1\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000025",
      "metadata": {
        "name": "md__v2_header",
        "codeCollapsed": true
      },
      "source": "### Log a second version"
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000026",
      "metadata": {
        "language": "python",
        "name": "R__log_v2"
      },
      "source": "%%R\n# Train a better model (added displacement)\nmodel_v2 <- lm(mpg ~ wt + hp + cyl + disp, data = mtcars)\n\nmv2 <- sfr_log_model(\n  reg,\n  model        = model_v2,\n  model_name   = \"SFR_DEMO_MPG\",\n  version_name = \"V2\",\n  input_cols   = list(wt = \"double\", hp = \"double\", cyl = \"integer\", disp = \"double\"),\n  output_cols  = list(prediction = \"double\"),\n  comment      = \"V2: added displacement\"\n)\n\n# Set as default\nsfr_set_default_model_version(reg, \"SFR_DEMO_MPG\", \"V2\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000027",
      "metadata": {
        "name": "md__inference_header",
        "codeCollapsed": true
      },
      "source": "---\n## 7. Inference\n\n### Local prediction (works everywhere)\n\n`sfr_predict_local()` runs the **exact same prediction logic** that the registered model\nuses, but entirely in your local R session. Use this to verify predictions before\ndeploying to production.\n\n> **Note:** R models require `rpy2` and `r-base` at inference time, which are\n> not available in the Snowflake warehouse Anaconda channel. Therefore, warehouse\n> inference (`sfr_predict()` without a service) is not supported for R models.\n> For production inference in Snowflake, deploy via SPCS (see below)."
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000028",
      "metadata": {
        "language": "python",
        "name": "R__write_predict_input"
      },
      "source": "%%R\n# Test data\nnew_data <- data.frame(\n  wt   = c(2.62, 3.44, 3.57),\n  hp   = c(110, 175, 245),\n  cyl  = c(4L, 6L, 8L),\n  disp = c(120.3, 258.0, 360.0)\n)\n\n# Predict locally -- same logic as the registered model\npreds <- sfr_predict_local(model_lm, new_data)\ncbind(new_data, preds)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000029",
      "metadata": {
        "name": "md__deploy_spcs",
        "codeCollapsed": true
      },
      "source": "### Production inference via SPCS\n\nFor production inference **inside Snowflake**, deploy the model as a\nSnowpark Container Services (SPCS) service. This creates a container with\nR, rpy2, and your model, then serves predictions via a REST endpoint.\n\nThe cells below create the SPCS infrastructure (compute pool + image repo)\nif it doesn't already exist, then deploy, wait, test, benchmark, and undeploy.\nEach step is a separate cell so you can re-run individually."
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-00000000002a",
      "metadata": {
        "language": "python",
        "name": "R__spcs_setup_deploy"
      },
      "source": "%%R\n# -- 0. Create SPCS infrastructure (if not exists) --\nsfr_create_compute_pool(conn, \"R_FORECAST_POOL\", instance_family = \"CPU_X64_M\")\nsfr_create_image_repo(conn, sfr_fqn(conn, \"R_FORECAST_IMAGES\"))\n\n# -- 1. Deploy as SPCS service (force = TRUE drops existing service first)\nsfr_deploy_model(\n  reg,\n  model_name   = \"SFR_DEMO_MPG\",\n  version_name = \"V2\",\n  service_name = \"mpg_service\",\n  compute_pool = \"R_FORECAST_POOL\",\n  image_repo   = sfr_fqn(conn, \"R_FORECAST_IMAGES\"),\n  force        = TRUE\n)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-00000000002b",
      "metadata": {
        "language": "python",
        "name": "R__spcs_wait"
      },
      "source": "%%R\n# -- 2. Check service status (one-off) --\nst <- sfr_get_service_status(reg, \"mpg_service\")\nrcat(sprintf(\"Status: %s | Message: %s | FQN: %s\", st$status, st$message, st$fqn))\nif (!is.null(st$containers)) rprint(st$containers[, c(\"containerName\", \"status\", \"message\")])",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "a1b2c3d4-wait-cell-v2-000000000001",
      "metadata": {
        "language": "python",
        "name": "R__spcs_wait"
      },
      "source": "%%R\n# -- 3. Wait for service to be ready --\n# Polls every 15 seconds, times out after 10 minutes\nsfr_wait_for_service(reg, \"mpg_service\", timeout_min = 10, poll_sec = 15)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-00000000002c",
      "metadata": {
        "language": "python",
        "name": "R__spcs_predict"
      },
      "source": "%%R\n# -- 4. Run inference via the service (Python bridge path) --\npreds <- sfr_predict(reg, \"SFR_DEMO_MPG\", new_data, service_name = \"mpg_service\")\nrprint(preds)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000002c01",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "### Direct REST Inference (faster, no Python bridge)\n\n`sfr_predict_rest()` calls the SPCS model endpoint directly from R using `httr2`,\nbypassing the Python/rpy2 bridge entirely. This avoids the `basic_string::substr`\ncrash and gives lower latency.\n\n**Auth:** In Workspace, set `SNOWFLAKE_PAT` or pass a connection with key-pair auth\nfor auto-JWT generation."
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000002c02",
      "metadata": {
        "language": "python"
      },
      "source": "%%R\n# -- 5a. Discover the REST endpoint --\nep <- sfr_service_endpoint(conn, \"mpg_service\")\nep",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000002c03",
      "metadata": {
        "language": "python"
      },
      "source": "%%R\n# -- 5b. REST predict (pure R, no Python bridge) --\n# Uses JWT auto-generated from the connection's key-pair auth.\n# Or set: Sys.setenv(SNOWFLAKE_PAT = \"your_token\")\nrest_preds <- sfr_predict_rest(ep, new_data, conn = conn)\nrprint(rest_preds)",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000002c04",
      "metadata": {
        "language": "python"
      },
      "source": "%%R\n# -- 5c. Benchmark REST inference --\nrest_bench <- sfr_benchmark_rest(ep, new_data, n = 20, conn = conn)\ncat(\"\\nREST  median:\", round(rest_bench$median_sec, 3), \"s\\n\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-00000000002d",
      "metadata": {
        "language": "python",
        "name": "R__spcs_undeploy"
      },
      "source": "%%R\n# -- 6. Undeploy when done --\nsfr_undeploy_model(reg, \"SFR_DEMO_MPG\", \"V2\", \"mpg_service\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000030",
      "metadata": {
        "name": "md__custom_predict_header",
        "codeCollapsed": true
      },
      "source": "## 8. Advanced -- Custom Predict Code\n\nFor models that need special prediction logic (e.g., `forecast`, multi-step pipelines),\nuse the `predict_body` template.\n\n### Template variables\n\n| Variable | Description |\n|----------|-------------|\n| `{{MODEL}}` | The loaded R model object |\n| `{{INPUT}}` | The input data.frame |\n| `{{UID}}` | Unique ID for variable naming |\n| `{{N}}` | Number of rows in input |"
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000031",
      "metadata": {
        "language": "python",
        "name": "R__custom_predict"
      },
      "source": "%%R\n# Example: forecast model with custom output\n# (Uncomment and adapt for your use case)\n\n# library(forecast)\n# arima_model <- auto.arima(AirPassengers)\n#\n# mv_forecast <- sfr_log_model(\n#   reg,\n#   model        = arima_model,\n#   model_name   = \"SFR_DEMO_FORECAST\",\n#   predict_fn   = \"forecast\",\n#   predict_pkgs = c(\"forecast\"),\n#   predict_body = '\n#     pred_{{UID}} <- forecast({{MODEL}}, h = {{N}})\n#     result_{{UID}} <- data.frame(\n#       period = seq_len({{N}}),\n#       point_forecast = as.numeric(pred_{{UID}}$mean),\n#       lower_95 = as.numeric(pred_{{UID}}$lower[,2]),\n#       upper_95 = as.numeric(pred_{{UID}}$upper[,2])\n#     )\n#   ',\n#   input_cols  = list(period = \"integer\"),\n#   output_cols = list(\n#     period = \"integer\", point_forecast = \"double\",\n#     lower_95 = \"double\", upper_95 = \"double\"\n#   )\n# )",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000032",
      "metadata": {
        "name": "md__cleanup_header",
        "codeCollapsed": true
      },
      "source": "---\n\n## 9. Cleanup"
    },
    {
      "cell_type": "code",
      "id": "e5f6a7b8-5000-4000-8000-000000000033",
      "metadata": {
        "language": "python",
        "name": "R__cleanup"
      },
      "source": "%%R\n# Uncomment to clean up demo objects\n# (commented out to avoid accidental deletion on Run All)\n#\n# sfr_delete_model(reg, \"SFR_DEMO_MPG\")\n# sfr_execute(conn, paste(\"DROP TABLE IF EXISTS\", sfr_fqn(conn, \"SFR_DEMO_PREDICT_INPUT\")))\n# sfr_disconnect(conn)\n# rcat(\"Cleanup complete.\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "id": "e5f6a7b8-5000-4000-8000-000000000034",
      "metadata": {
        "name": "md__supported_models",
        "codeCollapsed": true
      },
      "source": "---\n\n## Supported model types\n\nAny R model that can be serialised with `saveRDS()` works:\n\n- `lm()`, `glm()` (base R)\n- `randomForest::randomForest()`\n- `xgboost::xgb.train()`\n- `ranger::ranger()`\n- `forecast::auto.arima()`, `forecast::ets()`\n- `tidymodels` workflows\n- Custom S3/S4 model objects\n\n## Next steps\n\n- **Feature Store:** See `workspace_feature_store.ipynb`\n- **Full documentation:** `vignette(\"model-registry\", package = \"snowflakeR\")`"
    }
  ]
}