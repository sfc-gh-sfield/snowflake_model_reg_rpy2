{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# R Forecasting Model: Train, Register, and Inference\n",
        "\n",
        "This notebook demonstrates an end-to-end workflow for R-based forecasting in Snowflake:\n",
        "\n",
        "1. **Query Data** from Snowflake (TPC-H sample)\n",
        "2. **Train** a time series model in R using the `forecast` package\n",
        "3. **Register** the model to Snowflake Model Registry\n",
        "4. **Run Inference** via Snowpark Container Services\n",
        "5. **Visualize** results with ggplot2\n",
        "\n",
        "**Target Audience:** Data scientists who prefer R but need to integrate with Snowflake's MLOps ecosystem.\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Configuration](#section-1-configuration)\n",
        "2. [Environment Setup](#section-2-environment-setup)\n",
        "3. [Data Exploration](#section-3-data-exploration)\n",
        "4. [Time Series Preparation](#section-4-time-series-preparation)\n",
        "5. [Model Training (R)](#section-5-model-training-r)\n",
        "6. [Model Packaging](#section-6-model-packaging)\n",
        "7. [Model Registration](#section-7-model-registration)\n",
        "8. [Inference](#section-8-inference)\n",
        "9. [Visualization](#section-9-visualization)\n",
        "10. [Cleanup](#section-10-cleanup)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 1: Configuration\n",
        "\n",
        "Configure your Snowflake environment settings below. These variables are used throughout the notebook.\n",
        "\n",
        "**Modify these values to match your Snowflake account:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# =============================================================================\n",
        "# USER CONFIGURATION - Modify these values for your environment\n",
        "# =============================================================================\n",
        "\n",
        "# Database and schema for model artifacts and registry\n",
        "MODEL_DATABASE = \"SIMON\"         # Your database (USER$<username> for personal DB)\n",
        "MODEL_SCHEMA = \"R_FORECAST_DEMO\"      # Schema for models and artifacts\n",
        "\n",
        "# Warehouse for queries (use a warehouse you have access to)\n",
        "WAREHOUSE = \"SIMON_XS\"                   # Your warehouse name\n",
        "\n",
        "# Model naming\n",
        "MODEL_NAME = \"TPCH_ORDERS_FORECAST\"   # Name in Model Registry\n",
        "MODEL_VERSION = \"V1\"                  # Version identifier\n",
        "\n",
        "# SPCS resources (will be created if they don't exist)\n",
        "COMPUTE_POOL = \"R_FORECAST_POOL\"      # Compute pool for inference\n",
        "IMAGE_REPO = \"R_FORECAST_IMAGES\"      # Image repository\n",
        "SERVICE_NAME = \"orders_forecast_svc\"  # Service name for deployment\n",
        "\n",
        "# Stage for model artifacts\n",
        "ARTIFACTS_STAGE = \"ML_ARTIFACTS_STAGE\"\n",
        "\n",
        "# Data source (TPC-H sample data - available in all accounts)\n",
        "SOURCE_DATABASE = \"SNOWFLAKE_SAMPLE_DATA\"\n",
        "SOURCE_SCHEMA = \"TPCH_SF1\"            # SF1 = Scale Factor 1 (smallest)\n",
        "\n",
        "print(\"Configuration loaded:\")\n",
        "print(f\"  Model location: {MODEL_DATABASE}.{MODEL_SCHEMA}\")\n",
        "print(f\"  Warehouse: {WAREHOUSE}\")\n",
        "print(f\"  Model name: {MODEL_NAME}\")\n",
        "print(f\"  Data source: {SOURCE_DATABASE}.{SOURCE_SCHEMA}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 2: Environment Setup\n",
        "\n",
        "Set up the R environment and connect to Snowflake."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.1 Install R Environment\n",
        "\n",
        "Run the setup script to install R and required packages. This only needs to run once per session."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Install R environment with ADBC support\n",
        "# --adbc includes the forecast package needed for time series modeling\n",
        "!bash setup_r_environment.sh --adbc 2>&1 | tail -20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2 Configure Python-R Bridge"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Configure R environment and register %%R magic\n",
        "from r_helpers import setup_r_environment, print_diagnostics\n",
        "\n",
        "result = setup_r_environment()\n",
        "\n",
        "if result['success']:\n",
        "    print(f\"\u2713 R environment configured successfully\")\n",
        "    print(f\"  R version: {result['r_version']}\")\n",
        "    print(f\"  rpy2 installed: {result['rpy2_installed']}\")\n",
        "    print(f\"  %%R magic registered: {result['magic_registered']}\")\n",
        "else:\n",
        "    print(f\"\u2717 Setup failed: {result['errors']}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.2.1 Install forecast Package (if needed)\n",
        "\n",
        "If forecast wasn't installed via the setup script, you can install it interactively:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R\n",
        "# Install forecast package into the micromamba environment\n",
        "lib_path <- \"/root/.local/share/mamba/envs/r_env/lib/R/library\"\n",
        ".libPaths(lib_path)\n",
        "\n",
        "if (!require(\"forecast\", quietly = TRUE)) {\n",
        "    cat(\"Installing forecast package...\\n\")\n",
        "    install.packages(\"forecast\", repos = \"https://cloud.r-project.org/\", lib = lib_path)\n",
        "}\n",
        "\n",
        "library(forecast)\n",
        "cat(\"forecast version:\", as.character(packageVersion(\"forecast\")), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R\n",
        "# Verify R is working and forecast package is available\n",
        "library(forecast)\n",
        "library(ggplot2)\n",
        "library(dplyr)\n",
        "\n",
        "cat(\"R packages loaded successfully\\n\")\n",
        "cat(\"forecast version:\", as.character(packageVersion(\"forecast\")), \"\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.3 Connect to Snowflake"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from snowflake.snowpark import Session\n",
        "from snowflake.snowpark.context import get_active_session\n",
        "from snowflake.ml.registry import Registry\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Get the active Snowpark session (built-in to Workspace Notebooks)\n",
        "session = get_active_session()\n",
        "\n",
        "# Set warehouse\n",
        "session.sql(f\"USE WAREHOUSE {WAREHOUSE}\").collect()\n",
        "\n",
        "print(f\"Connected to Snowflake\")\n",
        "print(f\"  Account: {session.get_current_account()}\")\n",
        "print(f\"  User: {session.get_current_user()}\")\n",
        "print(f\"  Warehouse: {session.get_current_warehouse()}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2.4 Create Schema and Artifacts Stage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create schema if it doesn't exist\n",
        "session.sql(f\"CREATE SCHEMA IF NOT EXISTS {MODEL_DATABASE}.{MODEL_SCHEMA}\").collect()\n",
        "session.sql(f\"USE SCHEMA {MODEL_DATABASE}.{MODEL_SCHEMA}\").collect()\n",
        "\n",
        "# Create stage for model artifacts\n",
        "session.sql(f\"\"\"\n",
        "    CREATE STAGE IF NOT EXISTS {ARTIFACTS_STAGE}\n",
        "    COMMENT = 'Stage for R model artifacts'\n",
        "\"\"\").collect()\n",
        "\n",
        "print(f\"\u2713 Using schema: {MODEL_DATABASE}.{MODEL_SCHEMA}\")\n",
        "print(f\"\u2713 Artifacts stage: {ARTIFACTS_STAGE}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 3: Data Exploration\n",
        "\n",
        "Explore the TPC-H orders data that we'll use for forecasting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Query order volume by month\n",
        "orders_query = f\"\"\"\n",
        "SELECT \n",
        "    DATE_TRUNC('MONTH', O_ORDERDATE) as ORDER_MONTH,\n",
        "    COUNT(*) as ORDER_COUNT,\n",
        "    SUM(O_TOTALPRICE) as TOTAL_REVENUE,\n",
        "    AVG(O_TOTALPRICE) as AVG_ORDER_VALUE\n",
        "FROM {SOURCE_DATABASE}.{SOURCE_SCHEMA}.ORDERS\n",
        "GROUP BY DATE_TRUNC('MONTH', O_ORDERDATE)\n",
        "ORDER BY ORDER_MONTH\n",
        "\"\"\"\n",
        "\n",
        "orders_df = session.sql(orders_query).to_pandas()\n",
        "print(f\"Loaded {len(orders_df)} months of order data\")\n",
        "print(f\"Date range: {orders_df['ORDER_MONTH'].min()} to {orders_df['ORDER_MONTH'].max()}\")\n",
        "orders_df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R -i orders_df -w 900 -h 400\n",
        "library(ggplot2)\n",
        "library(dplyr)\n",
        "library(scales)\n",
        "\n",
        "# Convert to proper date type\n",
        "orders_df$ORDER_MONTH <- as.Date(orders_df$ORDER_MONTH)\n",
        "\n",
        "# Plot order count time series\n",
        "p <- ggplot(orders_df, aes(x = ORDER_MONTH, y = ORDER_COUNT)) +\n",
        "    geom_line(color = \"steelblue\", linewidth = 1) +\n",
        "    geom_point(color = \"steelblue\", size = 2) +\n",
        "    scale_y_continuous(labels = comma) +\n",
        "    scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n",
        "    labs(\n",
        "        title = \"Monthly Order Volume (TPC-H)\",\n",
        "        subtitle = \"Time series data for forecasting\",\n",
        "        x = \"Month\",\n",
        "        y = \"Number of Orders\"\n",
        "    ) +\n",
        "    theme_minimal(base_size = 12) +\n",
        "    theme(plot.title = element_text(face = \"bold\"))\n",
        "\n",
        "print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 4: Time Series Preparation\n",
        "\n",
        "Prepare the data as an R time series object for modeling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R -i orders_df\n",
        "library(forecast)\n",
        "\n",
        "# Ensure proper ordering\n",
        "orders_df <- orders_df[order(orders_df$ORDER_MONTH), ]\n",
        "\n",
        "# Extract the target variable (order count)\n",
        "order_counts <- orders_df$ORDER_COUNT\n",
        "\n",
        "# Get start date for ts object\n",
        "start_date <- as.Date(min(orders_df$ORDER_MONTH))\n",
        "start_year <- as.numeric(format(start_date, \"%Y\"))\n",
        "start_month <- as.numeric(format(start_date, \"%m\"))\n",
        "\n",
        "# Create time series object (monthly frequency = 12)\n",
        "orders_ts <- ts(order_counts, start = c(start_year, start_month), frequency = 12)\n",
        "\n",
        "cat(\"Time Series Summary:\\n\")\n",
        "cat(\"  Length:\", length(orders_ts), \"observations\\n\")\n",
        "cat(\"  Start:\", start(orders_ts), \"\\n\")\n",
        "cat(\"  End:\", end(orders_ts), \"\\n\")\n",
        "cat(\"  Frequency:\", frequency(orders_ts), \"(monthly)\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R -w 900 -h 500\n",
        "# Decompose the time series to understand components\n",
        "# Use STL decomposition (works well for monthly data)\n",
        "decomp <- stl(orders_ts, s.window = \"periodic\")\n",
        "plot(decomp, main = \"Time Series Decomposition\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 5: Model Training (R)\n",
        "\n",
        "Train a forecasting model using R's `forecast` package. We'll use `auto.arima()` which automatically selects the best ARIMA parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R\n",
        "library(forecast)\n",
        "\n",
        "# Split data: use last 12 months as test set\n",
        "n_test <- 12\n",
        "n_train <- length(orders_ts) - n_test\n",
        "\n",
        "train_ts <- window(orders_ts, end = c(start_year + floor((n_train-1)/12), ((start_month + n_train - 2) %% 12) + 1))\n",
        "test_ts <- window(orders_ts, start = c(start_year + floor(n_train/12), ((start_month + n_train - 1) %% 12) + 1))\n",
        "\n",
        "cat(\"Training set:\", length(train_ts), \"months\\n\")\n",
        "cat(\"Test set:\", length(test_ts), \"months\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R\n",
        "# Train ARIMA model with automatic parameter selection\n",
        "cat(\"Training ARIMA model (auto parameter selection)...\\n\")\n",
        "arima_model <- auto.arima(train_ts, \n",
        "                          seasonal = TRUE,\n",
        "                          stepwise = FALSE,  # More thorough search\n",
        "                          trace = FALSE)\n",
        "\n",
        "cat(\"\\nModel Summary:\\n\")\n",
        "print(summary(arima_model))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R -w 900 -h 400\n",
        "# Generate forecast for test period\n",
        "forecast_result <- forecast(arima_model, h = n_test)\n",
        "\n",
        "# Plot forecast vs actuals\n",
        "autoplot(forecast_result) +\n",
        "    autolayer(test_ts, series = \"Actual\", color = \"red\") +\n",
        "    labs(\n",
        "        title = \"ARIMA Forecast vs Actual\",\n",
        "        subtitle = paste(\"Model:\", arima_model$method),\n",
        "        x = \"Time\",\n",
        "        y = \"Order Count\"\n",
        "    ) +\n",
        "    theme_minimal() +\n",
        "    theme(legend.position = \"bottom\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R\n",
        "# Calculate accuracy metrics\n",
        "accuracy_metrics <- accuracy(forecast_result, test_ts)\n",
        "cat(\"\\nModel Accuracy:\\n\")\n",
        "print(accuracy_metrics)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5.2 Train Final Model on Full Data\n",
        "\n",
        "Now train the final model on all available data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R\n",
        "# Train final model on full dataset\n",
        "cat(\"Training final model on full dataset...\\n\")\n",
        "final_model <- auto.arima(orders_ts, \n",
        "                          seasonal = TRUE,\n",
        "                          stepwise = FALSE)\n",
        "\n",
        "cat(\"\\nFinal Model:\\n\")\n",
        "print(final_model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R\n",
        "# Save model to file\n",
        "model_path <- \"/tmp/orders_forecast_model.rds\"\n",
        "saveRDS(final_model, file = model_path)\n",
        "cat(\"Model saved to:\", model_path, \"\\n\")\n",
        "cat(\"File size:\", file.size(model_path), \"bytes\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 6: Model Packaging\n",
        "\n",
        "Create a Python wrapper class that enables the R model to work with Snowflake Model Registry."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Define the model wrapper class\n",
        "# Following dj_ml_rpy2 pattern: input rows = output rows (1:1 mapping)\n",
        "# Pass periods (1, 2, ..., N) as input, get N forecast rows as output\n",
        "\n",
        "wrapper_code = \"\"\"\n",
        "# Python wrapper for R forecast model using rpy2\n",
        "# Follows dj_ml_rpy2 pattern: number of output rows = number of input rows\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import uuid\n",
        "from snowflake.ml.model import custom_model\n",
        "\n",
        "\n",
        "def _get_rpy2_components():\n",
        "    import rpy2.robjects as ro\n",
        "    from rpy2.robjects import pandas2ri, r\n",
        "    from rpy2.robjects.vectors import FloatVector, IntVector\n",
        "    from rpy2.robjects.conversion import localconverter\n",
        "    from rpy2.rinterface_lib.embedded import RRuntimeError\n",
        "    from rpy2.robjects import numpy2ri\n",
        "    \n",
        "    combined_converter = ro.default_converter + pandas2ri.converter + numpy2ri.converter\n",
        "    return ro, r, FloatVector, IntVector, localconverter, RRuntimeError, combined_converter\n",
        "\n",
        "\n",
        "class ForecastModelWrapper(custom_model.CustomModel):\n",
        "    \n",
        "    def __init__(self, context: custom_model.ModelContext):\n",
        "        super().__init__(context)\n",
        "        self._initialized = False\n",
        "        self._r_model_name = f\"forecast_model_{uuid.uuid4().hex[:8]}\"\n",
        "    \n",
        "    def _ensure_initialized(self):\n",
        "        if self._initialized:\n",
        "            return\n",
        "        \n",
        "        ro, _, _, _, localconverter, _, combined_converter = _get_rpy2_components()\n",
        "        \n",
        "        with localconverter(combined_converter):\n",
        "            ro.r(\"library(forecast)\")\n",
        "            model_path = self.context[\"model_rds\"]\n",
        "            ro.r(f'{self._r_model_name} <- readRDS(\"{model_path}\")')\n",
        "        \n",
        "        self._initialized = True\n",
        "    \n",
        "    @custom_model.inference_api\n",
        "    def predict(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        # Following dj_ml_rpy2 pattern: output rows = input rows\n",
        "        self._ensure_initialized()\n",
        "        \n",
        "        # Number of periods to forecast = number of input rows\n",
        "        n_ahead = len(X)\n",
        "        \n",
        "        ro, r, _, _, localconverter, RRuntimeError, combined_converter = _get_rpy2_components()\n",
        "        \n",
        "        uid = uuid.uuid4().hex[:8]\n",
        "        var_pred = f\"pred_{uid}\"\n",
        "        var_mean = f\"mean_{uid}\"\n",
        "        var_lower = f\"lower_{uid}\"\n",
        "        var_upper = f\"upper_{uid}\"\n",
        "        \n",
        "        try:\n",
        "            with localconverter(combined_converter):\n",
        "                # Generate forecast for n_ahead periods\n",
        "                r_code = f'{var_pred} <- forecast({self._r_model_name}, h={n_ahead}); '\n",
        "                r_code += f'{var_mean} <- as.numeric({var_pred}$mean); '\n",
        "                r_code += f'{var_lower} <- as.matrix({var_pred}$lower); '\n",
        "                r_code += f'{var_upper} <- as.matrix({var_pred}$upper)'\n",
        "                ro.r(r_code)\n",
        "                \n",
        "                forecast_mean = np.array(ro.globalenv[var_mean]).flatten()\n",
        "                lower_intervals = np.array(ro.globalenv[var_lower])\n",
        "                upper_intervals = np.array(ro.globalenv[var_upper])\n",
        "                \n",
        "                if lower_intervals.ndim == 1:\n",
        "                    lower_intervals = lower_intervals.reshape(-1, 2)\n",
        "                if upper_intervals.ndim == 1:\n",
        "                    upper_intervals = upper_intervals.reshape(-1, 2)\n",
        "                \n",
        "                ro.r(f\"rm({var_pred}, {var_mean}, {var_lower}, {var_upper})\")\n",
        "            \n",
        "            # Return DataFrame with same number of rows as input\n",
        "            return pd.DataFrame({\n",
        "                \"period\": range(1, n_ahead + 1),\n",
        "                \"point_forecast\": forecast_mean,\n",
        "                \"lower_80\": lower_intervals[:, 0],\n",
        "                \"upper_80\": upper_intervals[:, 0],\n",
        "                \"lower_95\": lower_intervals[:, 1],\n",
        "                \"upper_95\": upper_intervals[:, 1]\n",
        "            })\n",
        "            \n",
        "        except RRuntimeError as e:\n",
        "            try:\n",
        "                ro.r(f\"rm({var_pred}, {var_mean}, {var_lower}, {var_upper})\")\n",
        "            except:\n",
        "                pass\n",
        "            raise RuntimeError(f\"R execution error: {str(e)}\")\n",
        "\"\"\"\n",
        "\n",
        "# Write wrapper to file\n",
        "wrapper_path = \"/tmp/forecast_model_wrapper.py\"\n",
        "with open(wrapper_path, \"w\") as f:\n",
        "    f.write(wrapper_code)\n",
        "\n",
        "print(f\"Model wrapper saved to: {wrapper_path}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Test the wrapper locally\n",
        "import sys\n",
        "sys.path.insert(0, '/tmp')\n",
        "\n",
        "# Reload the module to pick up changes\n",
        "import importlib\n",
        "import forecast_model_wrapper\n",
        "importlib.reload(forecast_model_wrapper)\n",
        "\n",
        "from forecast_model_wrapper import ForecastModelWrapper\n",
        "from snowflake.ml.model import custom_model\n",
        "\n",
        "# Create model context pointing to the saved model\n",
        "test_context = custom_model.ModelContext(\n",
        "    model_rds='/tmp/orders_forecast_model.rds'\n",
        ")\n",
        "\n",
        "# Instantiate wrapper\n",
        "wrapper = ForecastModelWrapper(test_context)\n",
        "\n",
        "# Test prediction - pass 6 rows to get 6-period forecast\n",
        "# Following dj_ml_rpy2 pattern: input rows = output rows\n",
        "test_input = pd.DataFrame({'period': range(1, 7)})  # 6 rows\n",
        "print(f\"Input shape: {test_input.shape}\")\n",
        "\n",
        "test_predictions = wrapper.predict(test_input)\n",
        "print(f\"Output shape: {test_predictions.shape}\")\n",
        "print(f\"\\nLocal test predictions (6 periods):\")\n",
        "test_predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 7: Model Registration\n",
        "\n",
        "Register the model to Snowflake Model Registry for managed deployment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Upload model artifact to stage\n",
        "session.file.put(\n",
        "    \"/tmp/orders_forecast_model.rds\",\n",
        "    f\"@{MODEL_DATABASE}.{MODEL_SCHEMA}.{ARTIFACTS_STAGE}/r_models/\",\n",
        "    auto_compress=False,\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "print(f\"Model uploaded to stage: @{ARTIFACTS_STAGE}/r_models/orders_forecast_model.rds\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Initialize Model Registry\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "reg = Registry(\n",
        "    session=session,\n",
        "    database_name=MODEL_DATABASE,\n",
        "    schema_name=MODEL_SCHEMA\n",
        ")\n",
        "\n",
        "print(f\"Registry initialized: {MODEL_DATABASE}.{MODEL_SCHEMA}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "from snowflake.ml.model import custom_model\n",
        "from snowflake.ml.model.model_signature import ModelSignature, FeatureSpec, DataType\n",
        "\n",
        "# Create model context\n",
        "model_context = custom_model.ModelContext(\n",
        "    model_rds='/tmp/orders_forecast_model.rds'\n",
        ")\n",
        "\n",
        "# Instantiate wrapper\n",
        "model_wrapper = ForecastModelWrapper(model_context)\n",
        "\n",
        "# Define model signature\n",
        "# Following dj_ml_rpy2 pattern: input rows = output rows\n",
        "# Pass N rows with period indices, get N forecast rows back\n",
        "predict_signature = ModelSignature(\n",
        "    inputs=[\n",
        "        FeatureSpec(name=\"period\", dtype=DataType.INT64)\n",
        "    ],\n",
        "    outputs=[\n",
        "        FeatureSpec(name=\"period\", dtype=DataType.INT64),\n",
        "        FeatureSpec(name=\"point_forecast\", dtype=DataType.DOUBLE),\n",
        "        FeatureSpec(name=\"lower_80\", dtype=DataType.DOUBLE),\n",
        "        FeatureSpec(name=\"upper_80\", dtype=DataType.DOUBLE),\n",
        "        FeatureSpec(name=\"lower_95\", dtype=DataType.DOUBLE),\n",
        "        FeatureSpec(name=\"upper_95\", dtype=DataType.DOUBLE)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Sample input for model validation (must match signature)\n",
        "sample_input = pd.DataFrame({'period': range(1, 7)})  # 6 rows\n",
        "\n",
        "print(\"Model signature defined:\")\n",
        "print(f\"  Input: period (INT64) - N rows for N-period forecast\")\n",
        "print(f\"  Output: 6 columns with N rows (1:1 row mapping)\")\n",
        "print(f\"  Sample input shape: {sample_input.shape}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Log model to registry\n",
        "# Note: version_name is commented out to allow auto-generation (makes notebook re-runnable)\n",
        "model_version = reg.log_model(\n",
        "    model_wrapper,\n",
        "    model_name=MODEL_NAME,\n",
        "    # version_name=MODEL_VERSION,  # Comment out to auto-generate unique version\n",
        "    target_platforms=[\"SNOWPARK_CONTAINER_SERVICES\"],\n",
        "    conda_dependencies=[\n",
        "        \"r-base>=4.1\",\n",
        "        \"r-forecast>=8.0\",\n",
        "        \"rpy2>=3.5\"\n",
        "    ],\n",
        "    signatures={\"predict\": predict_signature},\n",
        "    sample_input_data=sample_input,\n",
        "    comment=\"R ARIMA forecast model for TPC-H orders (trained with auto.arima)\"\n",
        ")\n",
        "\n",
        "print(f\"\\n\u2713 Model registered successfully!\")\n",
        "print(f\"  Name: {model_version.model_name}\")\n",
        "print(f\"  Version: {model_version.version_name}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# View registered models\n",
        "reg.show_models()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 8: Inference\n",
        "\n",
        "Deploy the model and run predictions via SPCS."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create SPCS resources\n",
        "session.sql(f\"\"\"\n",
        "    CREATE COMPUTE POOL IF NOT EXISTS {COMPUTE_POOL}\n",
        "    MIN_NODES = 1\n",
        "    MAX_NODES = 2\n",
        "    INSTANCE_FAMILY = 'CPU_X64_M'\n",
        "    AUTO_RESUME = TRUE\n",
        "    COMMENT = 'Compute pool for R forecast model inference'\n",
        "\"\"\").collect()\n",
        "print(f\"\u2713 Compute pool: {COMPUTE_POOL}\")\n",
        "\n",
        "session.sql(f\"\"\"\n",
        "    CREATE IMAGE REPOSITORY IF NOT EXISTS {MODEL_DATABASE}.{MODEL_SCHEMA}.{IMAGE_REPO}\n",
        "    COMMENT = 'Repository for R forecast model images'\n",
        "\"\"\").collect()\n",
        "print(f\"\u2713 Image repository: {IMAGE_REPO}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Deploy model to SPCS\n",
        "model_version.create_service(\n",
        "    service_name=SERVICE_NAME,\n",
        "    service_compute_pool=COMPUTE_POOL,\n",
        "    image_repo=IMAGE_REPO,\n",
        "    ingress_enabled=True,\n",
        "    max_instances=1\n",
        ")\n",
        "\n",
        "print(f\"Model deployment started: {SERVICE_NAME}\")\n",
        "print(\"Building container image... (this may take 5-10 minutes for first deployment)\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Check service status\n",
        "import time\n",
        "\n",
        "for i in range(20):\n",
        "    status = session.sql(f\"SHOW SERVICES LIKE '{SERVICE_NAME}'\").collect()\n",
        "    if status:\n",
        "        current_status = status[0]['status']\n",
        "        print(f\"Service status: {current_status}\")\n",
        "        if current_status == 'RUNNING':\n",
        "            print(\"\u2713 Service is running!\")\n",
        "            break\n",
        "    time.sleep(30)\n",
        "else:\n",
        "    print(\"Service not ready yet - check status manually\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Run inference - pass 12 rows to get 12-month forecast\n",
        "# Following dj_ml_rpy2 pattern: input rows = output rows\n",
        "\n",
        "# Create input with 12 rows (one per forecast period)\n",
        "inference_input = session.create_dataframe(\n",
        "    pd.DataFrame({'period': range(1, 13)})  # 12 rows\n",
        ")\n",
        "\n",
        "print(f\"Input: {inference_input.count()} rows\")\n",
        "print(\"Running inference via SPCS...\")\n",
        "start_time = time.time()\n",
        "\n",
        "predictions = model_version.run(\n",
        "    inference_input,\n",
        "    function_name=\"predict\",\n",
        "    service_name=SERVICE_NAME\n",
        ")\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"Inference completed in {elapsed:.2f} seconds\")\n",
        "\n",
        "# Convert to pandas for display\n",
        "predictions_df = predictions.to_pandas()\n",
        "print(f\"Output: {len(predictions_df)} rows\")\n",
        "predictions_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 9: Visualization\n",
        "\n",
        "Visualize the forecast results with ggplot2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R -i predictions_df -i orders_df -w 900 -h 500\n",
        "library(ggplot2)\n",
        "library(dplyr)\n",
        "library(scales)\n",
        "\n",
        "# Get the last date from historical data\n",
        "orders_df$ORDER_MONTH <- as.Date(orders_df$ORDER_MONTH)\n",
        "last_date <- max(orders_df$ORDER_MONTH)\n",
        "\n",
        "# Create future dates for predictions\n",
        "predictions_df$forecast_date <- seq.Date(\n",
        "    from = last_date + 30,\n",
        "    by = \"month\",\n",
        "    length.out = nrow(predictions_df)\n",
        ")\n",
        "\n",
        "# Prepare data for plotting\n",
        "forecast <- data.frame(\n",
        "    date = predictions_df$forecast_date,\n",
        "    value = predictions_df$POINT_FORECAST,\n",
        "    lower_80 = predictions_df$LOWER_80,\n",
        "    upper_80 = predictions_df$UPPER_80,\n",
        "    lower_95 = predictions_df$LOWER_95,\n",
        "    upper_95 = predictions_df$UPPER_95\n",
        ")\n",
        "\n",
        "# Create the plot\n",
        "p <- ggplot() +\n",
        "    geom_ribbon(data = forecast, \n",
        "                aes(x = date, ymin = lower_95, ymax = upper_95),\n",
        "                fill = \"steelblue\", alpha = 0.2) +\n",
        "    geom_ribbon(data = forecast,\n",
        "                aes(x = date, ymin = lower_80, ymax = upper_80),\n",
        "                fill = \"steelblue\", alpha = 0.3) +\n",
        "    geom_line(data = orders_df, \n",
        "              aes(x = ORDER_MONTH, y = ORDER_COUNT),\n",
        "              color = \"black\", linewidth = 1) +\n",
        "    geom_line(data = forecast,\n",
        "              aes(x = date, y = value),\n",
        "              color = \"steelblue\", linewidth = 1, linetype = \"dashed\") +\n",
        "    geom_point(data = forecast,\n",
        "               aes(x = date, y = value),\n",
        "               color = \"steelblue\", size = 2) +\n",
        "    scale_y_continuous(labels = comma) +\n",
        "    scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n",
        "    labs(\n",
        "        title = \"TPC-H Orders Forecast\",\n",
        "        subtitle = \"12-month forecast with 80% and 95% confidence intervals\",\n",
        "        x = \"Date\",\n",
        "        y = \"Order Count\"\n",
        "    ) +\n",
        "    theme_minimal(base_size = 12) +\n",
        "    theme(plot.title = element_text(face = \"bold\"))\n",
        "\n",
        "print(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "%%R -w 700 -h 400\n",
        "# Save the forecast plot\n",
        "ggsave(\"/tmp/orders_forecast.png\", p, width = 10, height = 6, dpi = 150)\n",
        "cat(\"Forecast plot saved to /tmp/orders_forecast.png\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Display saved plot\n",
        "from IPython.display import Image, display\n",
        "display(Image(filename=\"/tmp/orders_forecast.png\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "# Section 10: Cleanup\n",
        "\n",
        "Optional cleanup of resources created in this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Uncomment to clean up resources\n",
        "\n",
        "# Delete service\n",
        "# model_version.delete_service(SERVICE_NAME)\n",
        "# print(f\"Deleted service: {SERVICE_NAME}\")\n",
        "\n",
        "# Delete model from registry\n",
        "# reg.delete_model(MODEL_NAME)\n",
        "# print(f\"Deleted model: {MODEL_NAME}\")\n",
        "\n",
        "# Drop SPCS resources\n",
        "# session.sql(f\"DROP COMPUTE POOL IF EXISTS {COMPUTE_POOL}\").collect()\n",
        "# session.sql(f\"DROP IMAGE REPOSITORY IF EXISTS {MODEL_DATABASE}.{MODEL_SCHEMA}.{IMAGE_REPO}\").collect()\n",
        "# print(\"Dropped compute pool and image repository\")\n",
        "\n",
        "print(\"Cleanup section - uncomment lines above to delete resources\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **R Environment Setup** - Installing R and forecast package in Workspace Notebooks\n",
        "2. **Data Exploration** - Querying TPC-H data from Snowflake\n",
        "3. **Time Series Preparation** - Creating R time series objects\n",
        "4. **Model Training** - Using `auto.arima()` for automatic model selection\n",
        "5. **Model Packaging** - Creating a Python wrapper with rpy2 for registry compatibility\n",
        "6. **Model Registration** - Logging to Snowflake Model Registry\n",
        "7. **Inference** - Running predictions via SPCS\n",
        "8. **Visualization** - Creating publication-quality charts with ggplot2\n",
        "\n",
        "### Key Technologies\n",
        "\n",
        "| Component | Purpose |\n",
        "|-----------|---------|\n",
        "| rpy2 | Python-R bridge for %%R magic cells |\n",
        "| forecast (R) | Time series modeling (ARIMA, ETS, etc.) |\n",
        "| Snowflake Model Registry | Model versioning and management |\n",
        "| SPCS | Container-based inference runtime |\n",
        "| ggplot2 | Publication-quality visualizations |\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Try different forecasting models (ETS, Prophet, etc.)\n",
        "- Add exogenous variables for ARIMAX models\n",
        "- Set up scheduled inference with Snowflake Tasks\n",
        "- Create dashboards with Streamlit in Snowflake"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}