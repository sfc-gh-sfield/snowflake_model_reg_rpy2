{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "# R Forecasting Model: Train, Register, and Inference\n\nThis notebook demonstrates an end-to-end workflow for R-based forecasting in Snowflake:\n\n1. **Query Data** from Snowflake (TPC-H sample)\n2. **Train** a time series model in R using the `forecast` package\n3. **Register** the model to Snowflake Model Registry\n4. **Run Inference** via Snowpark Container Services\n5. **Visualize** results with ggplot2\n\n**Target Audience:** Data scientists who prefer R but need to integrate with Snowflake's MLOps ecosystem.\n\n---\n\n## Table of Contents\n\n1. [Configuration](#section-1-configuration)\n2. [Environment Setup](#section-2-environment-setup)\n3. [Data Exploration](#section-3-data-exploration)\n4. [Time Series Preparation](#section-4-time-series-preparation)\n5. [Model Training (R)](#section-5-model-training-r)\n6. [Model Packaging](#section-6-model-packaging)\n7. [Model Registration](#section-7-model-registration)\n8. [Inference](#section-8-inference)\n9. [Visualization](#section-9-visualization)\n10. [Cleanup](#section-10-cleanup)",
      "id": "60cba106-d4a0-4e76-bafa-ef51cd937dfc"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "---\n\n# Section 1: Configuration\n\nConfigure your Snowflake environment settings below. These variables are used throughout the notebook.\n\n**Modify these values to match your Snowflake account:**",
      "id": "6c050d21-d884-4bbd-9179-897a1de3d2cc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# =============================================================================\n# USER CONFIGURATION - Modify these values for your environment\n# =============================================================================\n\n# Database and schema for model artifacts and registry\nMODEL_DATABASE = \"SIMON\"         # Your database (USER$<username> for personal DB)\nMODEL_SCHEMA = \"R_FORECAST_DEMO\"      # Schema for models and artifacts\n\n# Warehouse for queries (use a warehouse you have access to)\nWAREHOUSE = \"SIMON_XS\"                   # Your warehouse name\n\n# Model naming\nMODEL_NAME = \"TPCH_ORDERS_FORECAST\"   # Name in Model Registry\nMODEL_VERSION = \"V1\"                  # Version identifier\n\n# SPCS resources (will be created if they don't exist)\nCOMPUTE_POOL = \"R_FORECAST_POOL\"      # Compute pool for inference\nIMAGE_REPO = \"R_FORECAST_IMAGES\"      # Image repository\nSERVICE_NAME = \"orders_forecast_svc\"  # Service name for deployment\n\n# Stage for model artifacts\nARTIFACTS_STAGE = \"ML_ARTIFACTS_STAGE\"\n\n# Data source (TPC-H sample data - available in all accounts)\nSOURCE_DATABASE = \"SNOWFLAKE_SAMPLE_DATA\"\nSOURCE_SCHEMA = \"TPCH_SF1\"            # SF1 = Scale Factor 1 (smallest)\n\nprint(\"Configuration loaded:\")\nprint(f\"  Model location: {MODEL_DATABASE}.{MODEL_SCHEMA}\")\nprint(f\"  Warehouse: {WAREHOUSE}\")\nprint(f\"  Model name: {MODEL_NAME}\")\nprint(f\"  Data source: {SOURCE_DATABASE}.{SOURCE_SCHEMA}\")",
      "id": "1039c03e-6af7-4c7b-b599-5faa70807a05"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "---\n\n# Section 2: Environment Setup\n\nSet up the R environment and connect to Snowflake.",
      "id": "7049846a-4a78-4532-bd54-ea42dae2660d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2.1 Install R Environment\n\nRun the setup script to install R and required packages. This only needs to run once per session.",
      "id": "e3c5a90b-698d-47bb-8960-846879510de3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Install R environment with ADBC support\n# --adbc includes the forecast package needed for time series modeling\n!bash setup_r_environment.sh --adbc 2>&1 | tail -20",
      "id": "86c36312-f405-4ac3-9d9a-fcc0ed84c92a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2.2 Configure Python-R Bridge",
      "id": "8124adf3-adf2-46d5-950f-63cb4eb2b6ce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Configure R environment and register %%R magic\nfrom r_helpers import setup_r_environment, print_diagnostics\n\nresult = setup_r_environment()\n\nif result['success']:\n    print(f\"✓ R environment configured successfully\")\n    print(f\"  R version: {result['r_version']}\")\n    print(f\"  rpy2 installed: {result['rpy2_installed']}\")\n    print(f\"  %%R magic registered: {result['magic_registered']}\")\nelse:\n    print(f\"✗ Setup failed: {result['errors']}\")",
      "id": "df879fb8-61f7-41c2-aac2-478eee680518"
    },
    {
      "id": "1139eeaf-924c-4734-a6f8-c0612ff31534",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "%%R\n# Install R packages into the micromamba environment\n# This is an alternative to adding packages to r_packages.yaml\n\n# Set the library path to the micromamba R environment\nlib_path <- \"/root/.local/share/mamba/envs/r_env/lib/R/library\"\n\n# Install from CRAN (use a reliable mirror)\ninstall.packages(\n    c(\"forecast\"),\n    repos = \"https://cloud.r-project.org/\",\n    lib = lib_path\n)\n\n# Verify installation\nlibrary(forecast)\ncat(\"forecast version:\", as.character(packageVersion(\"forecast\")), \"\\n\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "%%R\n# Verify R is working and forecast package is available\nlibrary(forecast)\nlibrary(ggplot2)\nlibrary(dplyr)\n\ncat(\"R packages loaded successfully\\n\")\ncat(\"forecast version:\", as.character(packageVersion(\"forecast\")), \"\\n\")",
      "id": "0ba8a90f-55fb-4340-bcb4-0a9b1f2c4e3c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2.3 Connect to Snowflake",
      "id": "aede0137-8a83-4765-8775-60368ea229fc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "from snowflake.snowpark import Session\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.ml.registry import Registry\nimport pandas as pd\nimport numpy as np\n\n# Get the active Snowpark session (built-in to Workspace Notebooks)\nsession = get_active_session()\n\n# Set warehouse\nsession.sql(f\"USE WAREHOUSE {WAREHOUSE}\").collect()\n\nprint(f\"Connected to Snowflake\")\nprint(f\"  Account: {session.get_current_account()}\")\nprint(f\"  User: {session.get_current_user()}\")\nprint(f\"  Warehouse: {session.get_current_warehouse()}\")",
      "id": "f85827d7-0902-471d-b296-7bb7a10c7896"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 2.4 Create Schema and Artifacts Stage",
      "id": "3cf49304-9b33-493a-94e6-7b2c0cf6e01b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Create schema if it doesn't exist\nsession.sql(f\"CREATE SCHEMA IF NOT EXISTS {MODEL_DATABASE}.{MODEL_SCHEMA}\").collect()\nsession.sql(f\"USE SCHEMA {MODEL_DATABASE}.{MODEL_SCHEMA}\").collect()\n\n# Create stage for model artifacts\nsession.sql(f\"\"\"\n    CREATE STAGE IF NOT EXISTS {ARTIFACTS_STAGE}\n    COMMENT = 'Stage for R model artifacts'\n\"\"\").collect()\n\nprint(f\"✓ Using schema: {MODEL_DATABASE}.{MODEL_SCHEMA}\")\nprint(f\"✓ Artifacts stage: {ARTIFACTS_STAGE}\")",
      "id": "b694cee8-4863-4a96-a84b-c5c3726397be"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "---\n\n# Section 3: Data Exploration\n\nExplore the TPC-H orders data that we'll use for forecasting.",
      "id": "05baa599-8171-4288-813b-0a8ff48517a4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Query order volume by month\norders_query = f\"\"\"\nSELECT \n    DATE_TRUNC('MONTH', O_ORDERDATE) as ORDER_MONTH,\n    COUNT(*) as ORDER_COUNT,\n    SUM(O_TOTALPRICE) as TOTAL_REVENUE,\n    AVG(O_TOTALPRICE) as AVG_ORDER_VALUE\nFROM {SOURCE_DATABASE}.{SOURCE_SCHEMA}.ORDERS\nGROUP BY DATE_TRUNC('MONTH', O_ORDERDATE)\nORDER BY ORDER_MONTH\n\"\"\"\n\norders_df = session.sql(orders_query).to_pandas()\nprint(f\"Loaded {len(orders_df)} months of order data\")\nprint(f\"Date range: {orders_df['ORDER_MONTH'].min()} to {orders_df['ORDER_MONTH'].max()}\")\norders_df.head(10)",
      "id": "c9e704f0-f7d2-42a2-a6d4-b5a9a015b662"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "%%R -i orders_df -w 900 -h 400\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\n# Convert to proper date type\norders_df$ORDER_MONTH <- as.Date(orders_df$ORDER_MONTH)\n\n# Plot order count time series\np <- ggplot(orders_df, aes(x = ORDER_MONTH, y = ORDER_COUNT)) +\n    geom_line(color = \"steelblue\", linewidth = 1) +\n    geom_point(color = \"steelblue\", size = 2) +\n    scale_y_continuous(labels = comma) +\n    scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n    labs(\n        title = \"Monthly Order Volume (TPC-H)\",\n        subtitle = \"Time series data for forecasting\",\n        x = \"Month\",\n        y = \"Number of Orders\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(plot.title = element_text(face = \"bold\"))\n\nprint(p)",
      "id": "58a30de0-264a-4868-80fb-f30cd9f1de75"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "---\n\n# Section 4: Time Series Preparation\n\nPrepare the data as an R time series object for modeling.",
      "id": "2f424318-8133-40ac-895d-fd29fe0b1c94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "%%R -i orders_df\nlibrary(forecast)\n\n# Ensure proper ordering\norders_df <- orders_df[order(orders_df$ORDER_MONTH), ]\n\n# Extract the target variable (order count)\norder_counts <- orders_df$ORDER_COUNT\n\n# Get start date for ts object\nstart_date <- as.Date(min(orders_df$ORDER_MONTH))\nstart_year <- as.numeric(format(start_date, \"%Y\"))\nstart_month <- as.numeric(format(start_date, \"%m\"))\n\n# Create time series object (monthly frequency = 12)\norders_ts <- ts(order_counts, start = c(start_year, start_month), frequency = 12)\n\ncat(\"Time Series Summary:\\n\")\ncat(\"  Length:\", length(orders_ts), \"observations\\n\")\ncat(\"  Start:\", start(orders_ts), \"\\n\")\ncat(\"  End:\", end(orders_ts), \"\\n\")\ncat(\"  Frequency:\", frequency(orders_ts), \"(monthly)\\n\")",
      "id": "bcf64fee-c8ac-45b6-a6f1-144196f3ec1b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "%%R -w 900 -h 500\n# Decompose the time series to understand components\n# Use STL decomposition (works well for monthly data)\ndecomp <- stl(orders_ts, s.window = \"periodic\")\nplot(decomp, main = \"Time Series Decomposition\")",
      "id": "d4cee0e6-98f9-4043-b8ad-eb4adb6f67ac"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "---\n\n# Section 5: Model Training (R)\n\nTrain a forecasting model using R's `forecast` package. We'll use `auto.arima()` which automatically selects the best ARIMA parameters.",
      "id": "0f362d93-605b-4afc-8ca0-1946ec20e33a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "%%R\nlibrary(forecast)\n\n# Split data: use last 12 months as test set\nn_test <- 12\nn_train <- length(orders_ts) - n_test\n\ntrain_ts <- window(orders_ts, end = c(start_year + floor((n_train-1)/12), ((start_month + n_train - 2) %% 12) + 1))\ntest_ts <- window(orders_ts, start = c(start_year + floor(n_train/12), ((start_month + n_train - 1) %% 12) + 1))\n\ncat(\"Training set:\", length(train_ts), \"months\\n\")\ncat(\"Test set:\", length(test_ts), \"months\\n\")",
      "id": "f47841c8-be82-4a87-8e7b-27de7c5c4ec9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "%%R\n# Train ARIMA model with automatic parameter selection\ncat(\"Training ARIMA model (auto parameter selection)...\\n\")\narima_model <- auto.arima(train_ts, \n                          seasonal = TRUE,\n                          stepwise = FALSE,  # More thorough search\n                          trace = FALSE)\n\ncat(\"\\nModel Summary:\\n\")\nprint(summary(arima_model))",
      "id": "ccfee61d-da42-46c8-8b38-e0cd6675de72"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "%%R -w 900 -h 400\n# Generate forecast for test period\nforecast_result <- forecast(arima_model, h = n_test)\n\n# Plot forecast vs actuals\nautoplot(forecast_result) +\n    autolayer(test_ts, series = \"Actual\", color = \"red\") +\n    labs(\n        title = \"ARIMA Forecast vs Actual\",\n        subtitle = paste(\"Model:\", arima_model$method),\n        x = \"Time\",\n        y = \"Order Count\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"bottom\")",
      "id": "8ac60042-5d28-4e4b-9a38-d5f4f12e0558"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "%%R\n# Calculate accuracy metrics\naccuracy_metrics <- accuracy(forecast_result, test_ts)\ncat(\"\\nModel Accuracy:\\n\")\nprint(accuracy_metrics)",
      "id": "55ef6ba2-49d9-4232-96af-dfb52166dc25"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "## 5.2 Train Final Model on Full Data\n\nNow train the final model on all available data.",
      "id": "cad4dd51-23e1-40c6-9760-a21c6a98dbe1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "%%R\n# Train final model on full dataset\ncat(\"Training final model on full dataset...\\n\")\nfinal_model <- auto.arima(orders_ts, \n                          seasonal = TRUE,\n                          stepwise = FALSE)\n\ncat(\"\\nFinal Model:\\n\")\nprint(final_model)",
      "id": "8f53250a-14af-4e9f-8317-5d2966ce86e3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "%%R\n# Save model to file\nmodel_path <- \"/tmp/orders_forecast_model.rds\"\nsaveRDS(final_model, file = model_path)\ncat(\"Model saved to:\", model_path, \"\\n\")\ncat(\"File size:\", file.size(model_path), \"bytes\\n\")",
      "id": "dbd09ac5-c7ac-4917-99de-d5095d1bab4c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "---\n\n# Section 6: Model Packaging\n\nCreate a Python wrapper class that enables the R model to work with Snowflake Model Registry.",
      "id": "e88099e1-9d9f-4a1b-8e1f-09cd3ad1388d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Define the model wrapper class\nwrapper_code = \"\"\"\"\"\"\nPython wrapper for R forecast model using rpy2.\n\"\"\"\n\nimport pandas as pd\nimport numpy as np\nimport uuid\nfrom snowflake.ml.model import custom_model\n\n\ndef _get_rpy2_components():\n    \"\"\"Lazy import of rpy2 components.\"\"\"\n    import rpy2.robjects as ro\n    from rpy2.robjects import pandas2ri, r\n    from rpy2.robjects.vectors import FloatVector, IntVector\n    from rpy2.robjects.conversion import localconverter\n    from rpy2.rinterface_lib.embedded import RRuntimeError\n    from rpy2.robjects import numpy2ri\n    \n    combined_converter = ro.default_converter + pandas2ri.converter + numpy2ri.converter\n    return ro, r, FloatVector, IntVector, localconverter, RRuntimeError, combined_converter\n\n\nclass ForecastModelWrapper(custom_model.CustomModel):\n    \"\"\"Python wrapper for R ARIMA/ETS forecast models.\"\"\"\n    \n    def __init__(self, context: custom_model.ModelContext):\n        super().__init__(context)\n        self._initialized = False\n        self._r_model_name = f\"forecast_model_{uuid.uuid4().hex[:8]}\"\n    \n    def _ensure_initialized(self):\n        if self._initialized:\n            return\n        \n        ro, _, _, _, localconverter, _, combined_converter = _get_rpy2_components()\n        \n        with localconverter(combined_converter):\n            ro.r('library(forecast)')\n            model_path = self.context['model_rds']\n            ro.r(f'{self._r_model_name} <- readRDS(\"{model_path}\")')\n        \n        self._initialized = True\n    \n    @custom_model.inference_api\n    def predict(self, X: pd.DataFrame) -> pd.DataFrame:\n        self._ensure_initialized()\n        \n        if 'h' in X.columns:\n            h = int(X['h'].iloc[0])\n        else:\n            h = len(X)\n        \n        ro, r, _, _, localconverter, RRuntimeError, combined_converter = _get_rpy2_components()\n        \n        uid = uuid.uuid4().hex[:8]\n        var_pred = f\"pred_{uid}\"\n        var_mean = f\"mean_{uid}\"\n        var_lower = f\"lower_{uid}\"\n        var_upper = f\"upper_{uid}\"\n        \n        try:\n            with localconverter(combined_converter):\n                ro.r(f\"\"\"\n                    {var_pred} <- forecast({self._r_model_name}, h={h})\n                    {var_mean} <- as.numeric({var_pred}$mean)\n                    {var_lower} <- as.matrix({var_pred}$lower)\n                    {var_upper} <- as.matrix({var_pred}$upper)\n                \"\"\")\n                \n                forecast_mean = np.array(ro.globalenv[var_mean]).flatten()\n                lower_intervals = np.array(ro.globalenv[var_lower])\n                upper_intervals = np.array(ro.globalenv[var_upper])\n                \n                if lower_intervals.ndim == 1:\n                    lower_intervals = lower_intervals.reshape(-1, 2)\n                if upper_intervals.ndim == 1:\n                    upper_intervals = upper_intervals.reshape(-1, 2)\n                \n                ro.r(f'rm({var_pred}, {var_mean}, {var_lower}, {var_upper})')\n            \n            return pd.DataFrame({\n                'period': range(1, h + 1),\n                'point_forecast': forecast_mean,\n                'lower_80': lower_intervals[:, 0],\n                'upper_80': upper_intervals[:, 0],\n                'lower_95': lower_intervals[:, 1],\n                'upper_95': upper_intervals[:, 1]\n            })\n            \n        except RRuntimeError as e:\n            raise RuntimeError(f\"R execution error: {str(e)}\")\n\"\"\"\n\n# Write wrapper to file\nwrapper_path = \"/tmp/forecast_model_wrapper.py\"\nwith open(wrapper_path, 'w') as f:\n    f.write(wrapper_code)\n\nprint(f\"Model wrapper saved to: {wrapper_path}\")",
      "id": "8c6d3631-413a-411a-b860-86316a4bbf2d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Test the wrapper locally\nimport sys\nsys.path.insert(0, '/tmp')\n\nfrom forecast_model_wrapper import ForecastModelWrapper\nfrom snowflake.ml.model import custom_model\n\n# Create model context pointing to the saved model\ntest_context = custom_model.ModelContext(\n    model_rds='/tmp/orders_forecast_model.rds'\n)\n\n# Instantiate wrapper\nwrapper = ForecastModelWrapper(test_context)\n\n# Test prediction (forecast 6 periods ahead)\ntest_input = pd.DataFrame({'h': [6]})\ntest_predictions = wrapper.predict(test_input)\n\nprint(\"Local test predictions (6 months ahead):\")\ntest_predictions",
      "id": "15c98a08-b38f-4209-ad2a-f578267f9619"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "---\n\n# Section 7: Model Registration\n\nRegister the model to Snowflake Model Registry for managed deployment.",
      "id": "2434de75-871e-4c0d-857e-5552efb55dd5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Upload model artifact to stage\nsession.file.put(\n    \"/tmp/orders_forecast_model.rds\",\n    f\"@{MODEL_DATABASE}.{MODEL_SCHEMA}.{ARTIFACTS_STAGE}/r_models/\",\n    auto_compress=False,\n    overwrite=True\n)\n\nprint(f\"Model uploaded to stage: @{ARTIFACTS_STAGE}/r_models/orders_forecast_model.rds\")",
      "id": "6ddbd6b5-ba29-471a-ad1b-ab4ccfde213a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Initialize Model Registry\nfrom snowflake.ml.registry import Registry\n\nreg = Registry(\n    session=session,\n    database_name=MODEL_DATABASE,\n    schema_name=MODEL_SCHEMA\n)\n\nprint(f\"Registry initialized: {MODEL_DATABASE}.{MODEL_SCHEMA}\")",
      "id": "f80ba15d-2caf-4377-b805-32fbc7ecce94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "from snowflake.ml.model import custom_model\nfrom snowflake.ml.model.model_signature import ModelSignature, FeatureSpec, DataType\n\n# Create model context\nmodel_context = custom_model.ModelContext(\n    model_rds='/tmp/orders_forecast_model.rds'\n)\n\n# Instantiate wrapper\nmodel_wrapper = ForecastModelWrapper(model_context)\n\n# Define model signature\npredict_signature = ModelSignature(\n    inputs=[\n        FeatureSpec(name=\"h\", dtype=DataType.INT64)\n    ],\n    outputs=[\n        FeatureSpec(name=\"period\", dtype=DataType.INT64),\n        FeatureSpec(name=\"point_forecast\", dtype=DataType.DOUBLE),\n        FeatureSpec(name=\"lower_80\", dtype=DataType.DOUBLE),\n        FeatureSpec(name=\"upper_80\", dtype=DataType.DOUBLE),\n        FeatureSpec(name=\"lower_95\", dtype=DataType.DOUBLE),\n        FeatureSpec(name=\"upper_95\", dtype=DataType.DOUBLE)\n    ]\n)\n\nsample_input = pd.DataFrame({'h': [12]})\n\nprint(\"Model signature defined\")\nprint(\"  Input: h (forecast horizon)\")\nprint(\"  Output: period, point_forecast, lower_80, upper_80, lower_95, upper_95\")",
      "id": "a197d342-f3c4-4303-91ee-7af2d54dfc3f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Log model to registry\nmodel_version = reg.log_model(\n    model_wrapper,\n    model_name=MODEL_NAME,\n    version_name=MODEL_VERSION,\n    target_platforms=[\"SNOWPARK_CONTAINER_SERVICES\"],\n    conda_dependencies=[\n        \"r-base>=4.1\",\n        \"r-forecast>=8.0\",\n        \"rpy2>=3.5\"\n    ],\n    signatures={\"predict\": predict_signature},\n    sample_input_data=sample_input,\n    comment=\"R ARIMA forecast model for TPC-H orders (trained with auto.arima)\"\n)\n\nprint(f\"\\n✓ Model registered successfully!\")\nprint(f\"  Name: {model_version.model_name}\")\nprint(f\"  Version: {model_version.version_name}\")",
      "id": "2d21a868-b50d-4716-b584-313ae9fe4902"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# View registered models\nreg.show_models()",
      "id": "5e22b9ee-9d38-4440-b0b8-fcd647555a57"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "---\n\n# Section 8: Inference\n\nDeploy the model and run predictions via SPCS.",
      "id": "a89f0afb-33fb-4ce8-b758-e6db03fa1c52"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Create SPCS resources\nsession.sql(f\"\"\"\n    CREATE COMPUTE POOL IF NOT EXISTS {COMPUTE_POOL}\n    MIN_NODES = 1\n    MAX_NODES = 2\n    INSTANCE_FAMILY = 'CPU_X64_M'\n    AUTO_RESUME = TRUE\n    COMMENT = 'Compute pool for R forecast model inference'\n\"\"\").collect()\nprint(f\"✓ Compute pool: {COMPUTE_POOL}\")\n\nsession.sql(f\"\"\"\n    CREATE IMAGE REPOSITORY IF NOT EXISTS {MODEL_DATABASE}.{MODEL_SCHEMA}.{IMAGE_REPO}\n    COMMENT = 'Repository for R forecast model images'\n\"\"\").collect()\nprint(f\"✓ Image repository: {IMAGE_REPO}\")",
      "id": "a775c1e4-393a-469a-984f-cbf011517517"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Deploy model to SPCS\nmodel_version.create_service(\n    service_name=SERVICE_NAME,\n    service_compute_pool=COMPUTE_POOL,\n    image_repo=IMAGE_REPO,\n    ingress_enabled=True,\n    max_instances=1\n)\n\nprint(f\"Model deployment started: {SERVICE_NAME}\")\nprint(\"Building container image... (this may take 5-10 minutes for first deployment)\")",
      "id": "a5651676-56db-45b8-845a-f1178e5080c1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Check service status\nimport time\n\nfor i in range(20):\n    status = session.sql(f\"SHOW SERVICES LIKE '{SERVICE_NAME}'\").collect()\n    if status:\n        current_status = status[0]['status']\n        print(f\"Service status: {current_status}\")\n        if current_status == 'READY':\n            print(\"✓ Service is ready!\")\n            break\n    time.sleep(30)\nelse:\n    print(\"Service not ready yet - check status manually\")",
      "id": "8374b243-b68e-4f09-b182-39008764091d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Run inference - forecast 12 months ahead\ninference_input = session.create_dataframe(pd.DataFrame({'h': [12]}))\n\nprint(\"Running inference via SPCS...\")\nstart_time = time.time()\n\npredictions = model_version.run(\n    inference_input,\n    function_name=\"predict\",\n    service_name=SERVICE_NAME\n)\n\nelapsed = time.time() - start_time\nprint(f\"Inference completed in {elapsed:.2f} seconds\")\n\n# Convert to pandas for display\npredictions_df = predictions.to_pandas()\npredictions_df",
      "id": "9f5f8a1d-5e01-4f27-9bb5-fe92ab7674a5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "---\n\n# Section 9: Visualization\n\nVisualize the forecast results with ggplot2.",
      "id": "ea06adfe-015e-4bd5-b450-2822aaa4ec5a"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "%%R -i predictions_df -i orders_df -w 900 -h 500\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\n# Get the last date from historical data\norders_df$ORDER_MONTH <- as.Date(orders_df$ORDER_MONTH)\nlast_date <- max(orders_df$ORDER_MONTH)\n\n# Create future dates for predictions\npredictions_df$forecast_date <- seq.Date(\n    from = last_date + 30,\n    by = \"month\",\n    length.out = nrow(predictions_df)\n)\n\n# Prepare data for plotting\nforecast <- data.frame(\n    date = predictions_df$forecast_date,\n    value = predictions_df$POINT_FORECAST,\n    lower_80 = predictions_df$LOWER_80,\n    upper_80 = predictions_df$UPPER_80,\n    lower_95 = predictions_df$LOWER_95,\n    upper_95 = predictions_df$UPPER_95\n)\n\n# Create the plot\np <- ggplot() +\n    geom_ribbon(data = forecast, \n                aes(x = date, ymin = lower_95, ymax = upper_95),\n                fill = \"steelblue\", alpha = 0.2) +\n    geom_ribbon(data = forecast,\n                aes(x = date, ymin = lower_80, ymax = upper_80),\n                fill = \"steelblue\", alpha = 0.3) +\n    geom_line(data = orders_df, \n              aes(x = ORDER_MONTH, y = ORDER_COUNT),\n              color = \"black\", linewidth = 1) +\n    geom_line(data = forecast,\n              aes(x = date, y = value),\n              color = \"steelblue\", linewidth = 1, linetype = \"dashed\") +\n    geom_point(data = forecast,\n               aes(x = date, y = value),\n               color = \"steelblue\", size = 2) +\n    scale_y_continuous(labels = comma) +\n    scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n    labs(\n        title = \"TPC-H Orders Forecast\",\n        subtitle = \"12-month forecast with 80% and 95% confidence intervals\",\n        x = \"Date\",\n        y = \"Order Count\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(plot.title = element_text(face = \"bold\"))\n\nprint(p)",
      "id": "af9ec1fc-963f-4ddd-a59e-318fd0c61b7f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "%%R -w 700 -h 400\n# Save the forecast plot\nggsave(\"/tmp/orders_forecast.png\", p, width = 10, height = 6, dpi = 150)\ncat(\"Forecast plot saved to /tmp/orders_forecast.png\\n\")",
      "id": "0dcb5b8e-9389-41c8-8ef9-dcb9e043a642"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Display saved plot\nfrom IPython.display import Image, display\ndisplay(Image(filename=\"/tmp/orders_forecast.png\"))",
      "id": "add5872f-e211-4947-8c00-6d2073f90578"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "---\n\n# Section 10: Cleanup\n\nOptional cleanup of resources created in this notebook.",
      "id": "3f748675-53a9-4c55-8cc8-402f15a568d1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": "# Uncomment to clean up resources\n\n# Delete service\n# model_version.delete_service(SERVICE_NAME)\n# print(f\"Deleted service: {SERVICE_NAME}\")\n\n# Delete model from registry\n# reg.delete_model(MODEL_NAME)\n# print(f\"Deleted model: {MODEL_NAME}\")\n\n# Drop SPCS resources\n# session.sql(f\"DROP COMPUTE POOL IF EXISTS {COMPUTE_POOL}\").collect()\n# session.sql(f\"DROP IMAGE REPOSITORY IF EXISTS {MODEL_DATABASE}.{MODEL_SCHEMA}.{IMAGE_REPO}\").collect()\n# print(\"Dropped compute pool and image repository\")\n\nprint(\"Cleanup section - uncomment lines above to delete resources\")",
      "id": "a5248770-84ca-4204-bfeb-872aa4e20ad1"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": "---\n\n## Summary\n\nThis notebook demonstrated:\n\n1. **R Environment Setup** - Installing R and forecast package in Workspace Notebooks\n2. **Data Exploration** - Querying TPC-H data from Snowflake\n3. **Time Series Preparation** - Creating R time series objects\n4. **Model Training** - Using `auto.arima()` for automatic model selection\n5. **Model Packaging** - Creating a Python wrapper with rpy2 for registry compatibility\n6. **Model Registration** - Logging to Snowflake Model Registry\n7. **Inference** - Running predictions via SPCS\n8. **Visualization** - Creating publication-quality charts with ggplot2\n\n### Key Technologies\n\n| Component | Purpose |\n|-----------|---------|\n| rpy2 | Python-R bridge for %%R magic cells |\n| forecast (R) | Time series modeling (ARIMA, ETS, etc.) |\n| Snowflake Model Registry | Model versioning and management |\n| SPCS | Container-based inference runtime |\n| ggplot2 | Publication-quality visualizations |\n\n### Next Steps\n\n- Try different forecasting models (ETS, Prophet, etc.)\n- Add exogenous variables for ARIMAX models\n- Set up scheduled inference with Snowflake Tasks\n- Create dashboards with Streamlit in Snowflake",
      "id": "29995f5b-4aa7-49e5-9f24-799d6b0c79c4"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}