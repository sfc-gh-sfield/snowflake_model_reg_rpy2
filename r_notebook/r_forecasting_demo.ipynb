{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "# R Forecasting Model: Train, Register, and Inference\n",
        "\n",
        "This notebook demonstrates an end-to-end workflow for R-based forecasting in Snowflake:\n",
        "\n",
        "1. **Query Data** from Snowflake (TPC-H sample)\n",
        "2. **Train** a time series model in R using the `forecast` package\n",
        "3. **Register** the model to Snowflake Model Registry\n",
        "4. **Run Inference** via Snowpark Container Services\n",
        "5. **Visualize** results with ggplot2\n",
        "\n",
        "**Target Audience:** Data scientists who prefer R but need to integrate with Snowflake's MLOps ecosystem.\n",
        "\n",
        "---\n",
        "\n",
        "## Table of Contents\n",
        "\n",
        "1. [Configuration](#section-1-configuration)\n",
        "2. [Environment Setup](#section-2-environment-setup)\n",
        "3. [Data Exploration](#section-3-data-exploration)\n",
        "4. [Time Series Preparation](#section-4-time-series-preparation)\n",
        "5. [Model Training (R)](#section-5-model-training-r)\n",
        "6. [Model Packaging](#section-6-model-packaging)\n",
        "7. [Model Registration](#section-7-model-registration)\n",
        "8. [Inference](#section-8-inference)\n",
        "9. [Visualization](#section-9-visualization)\n",
        "10. [Cleanup](#section-10-cleanup)"
      ],
      "id": "8bd53c06-e745-4d4b-8d6c-3c23899e749e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 1: Configuration\n",
        "\n",
        "Configure your Snowflake environment settings below. These variables are used throughout the notebook.\n",
        "\n",
        "**Modify these values to match your Snowflake account:**"
      ],
      "id": "53e1c101-2a4f-404e-90ac-a67db2183aef"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__user_configuration",
        "title": "PY__user_configuration"
      },
      "source": "# User configuration\n# =============================================================================\n# USER CONFIGURATION - Modify these values for your environment\n# =============================================================================\n\n# Database and schema for model artifacts and registry\nMODEL_DATABASE = \"SIMON\"              # Your database (e.g., \"USER$<username>\" or \"MY_DB\")\nMODEL_SCHEMA = \"R_FORECAST_DEMO\"      # Schema for models and artifacts\n\n# Warehouse for queries (use a warehouse you have access to)\nWAREHOUSE = \"SIMON_XS\"                # Your warehouse name (e.g., \"COMPUTE_WH\")\n\n# Model naming\nMODEL_NAME = \"TPCH_ORDERS_FORECAST\"   # Name in Model Registry\nMODEL_VERSION = \"V1\"                  # Version identifier\n\n# SPCS resources (will be created if they don't exist)\nCOMPUTE_POOL = \"R_FORECAST_POOL\"      # Compute pool for inference\nIMAGE_REPO = \"R_FORECAST_IMAGES\"      # Image repository\nSERVICE_NAME = \"orders_forecast_svc\"  # Service name for deployment\n\n# Stage for model artifacts\nARTIFACTS_STAGE = \"ML_ARTIFACTS_STAGE\"\n\n# Data source (TPC-H sample data - available in all accounts)\nSOURCE_DATABASE = \"SNOWFLAKE_SAMPLE_DATA\"\nSOURCE_SCHEMA = \"TPCH_SF1\"            # SF1 = Scale Factor 1 (smallest)\n\nprint(\"Configuration loaded:\")\nprint(f\"  Model location: {MODEL_DATABASE}.{MODEL_SCHEMA}\")\nprint(f\"  Warehouse: {WAREHOUSE}\")\nprint(f\"  Model name: {MODEL_NAME}\")\nprint(f\"  Data source: {SOURCE_DATABASE}.{SOURCE_SCHEMA}\")",
      "execution_count": null,
      "outputs": [],
      "id": "4da8c716-b4f1-4fde-b3df-4e53e0c5f971"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 2: Environment Setup\n",
        "\n",
        "Set up the R environment and connect to Snowflake."
      ],
      "id": "8b938359-24a9-4810-a565-56251ef2be34"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 2.1 Install R Environment\n",
        "\n",
        "Run the setup script to install R and required packages. This only needs to run once per session."
      ],
      "id": "b0592e7e-219b-4ee5-a7c3-00f9ffcadc5b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__install_r_environment",
        "title": "PY__install_r_environment"
      },
      "source": [
        "# Install R environment with ADBC support\n",
        "# --adbc includes the forecast package needed for time series modeling\n",
        "!bash setup_r_environment.sh --adbc 2>&1 | tail -20"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "12c8c30d-83e7-4cb6-ba43-94e343f35297"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 2.2 Configure Python-R Bridge"
      ],
      "id": "fa70ef5a-6a5f-42f1-b866-b9d8d46e313a"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__configure_r_bridge",
        "title": "PY__configure_r_bridge"
      },
      "source": [
        "# Configure R environment and register %%R magic\n",
        "from r_helpers import setup_r_environment, print_diagnostics\n",
        "\n",
        "result = setup_r_environment()\n",
        "\n",
        "if result['success']:\n",
        "    print(f\"\u2713 R environment configured successfully\")\n",
        "    print(f\"  R version: {result['r_version']}\")\n",
        "    print(f\"  rpy2 installed: {result['rpy2_installed']}\")\n",
        "    print(f\"  %%R magic registered: {result['magic_registered']}\")\n",
        "else:\n",
        "    print(f\"\u2717 Setup failed: {result['errors']}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "f0f046d1-31f9-4131-8831-325590a221e0"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 2.2.1 Install forecast Package (if needed)\n",
        "\n",
        "If forecast wasn't installed via the setup script, you can install it interactively:"
      ],
      "id": "dfddd46f-da04-421a-9e14-dd2cb353c3a2"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__check_forecast",
        "title": "R__check_forecast"
      },
      "source": "%%R\nR__check_forecast_pkg\n# Install forecast package into the micromamba environment\nlib_path <- \"/root/.local/share/mamba/envs/r_env/lib/R/library\"\n.libPaths(lib_path)\n\nif (!require(\"forecast\", quietly = TRUE)) {\n    cat(\"Installing forecast package...\\n\")\n    install.packages(\"forecast\", repos = \"https://cloud.r-project.org/\", lib = lib_path)\n}\n\nlibrary(forecast)\ncat(\"forecast version:\", as.character(packageVersion(\"forecast\")), \"\\n\")",
      "execution_count": null,
      "outputs": [],
      "id": "4db14aa2-6702-4b0c-b201-31386082b8f5"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__install_forecast",
        "title": "R__install_forecast"
      },
      "source": "%%R\nR__install_forecast\n# Verify R is working and forecast package is available\nlibrary(forecast)\nlibrary(ggplot2)\nlibrary(dplyr)\n\ncat(\"R packages loaded successfully\\n\")\ncat(\"forecast version:\", as.character(packageVersion(\"forecast\")), \"\\n\")",
      "execution_count": null,
      "outputs": [],
      "id": "98e6a722-de79-45dc-888e-cbe13521f16a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 2.3 Connect to Snowflake"
      ],
      "id": "5bd4d521-d312-4820-8d75-3f8544101d37"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__connect_snowflake",
        "title": "PY__connect_snowflake"
      },
      "source": "# Connect to Snowflake\nfrom snowflake.snowpark import Session\nfrom snowflake.snowpark.context import get_active_session\nfrom snowflake.ml.registry import Registry\nimport pandas as pd\nimport numpy as np\n\n# Get the active Snowpark session (built-in to Workspace Notebooks)\nsession = get_active_session()\n\n# Set warehouse\nsession.sql(f\"USE WAREHOUSE {WAREHOUSE}\").collect()\n\nprint(f\"Connected to Snowflake\")\nprint(f\"  Account: {session.get_current_account()}\")\nprint(f\"  User: {session.get_current_user()}\")\nprint(f\"  Warehouse: {session.get_current_warehouse()}\")",
      "execution_count": null,
      "outputs": [],
      "id": "e8c1e314-e2f6-4d70-bf38-d5d0076c8fd8"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 2.4 Create Schema and Artifacts Stage"
      ],
      "id": "72d097e0-4a3e-4df5-bb5d-bb5efe638044"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__create_schema_stage",
        "title": "PY__create_schema_stage"
      },
      "source": [
        "# Create schema if it doesn't exist\n",
        "session.sql(f\"CREATE SCHEMA IF NOT EXISTS {MODEL_DATABASE}.{MODEL_SCHEMA}\").collect()\n",
        "session.sql(f\"USE SCHEMA {MODEL_DATABASE}.{MODEL_SCHEMA}\").collect()\n",
        "\n",
        "# Create stage for model artifacts\n",
        "session.sql(f\"\"\"\n",
        "    CREATE STAGE IF NOT EXISTS {ARTIFACTS_STAGE}\n",
        "    COMMENT = 'Stage for R model artifacts'\n",
        "\"\"\").collect()\n",
        "\n",
        "print(f\"\u2713 Using schema: {MODEL_DATABASE}.{MODEL_SCHEMA}\")\n",
        "print(f\"\u2713 Artifacts stage: {ARTIFACTS_STAGE}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "95ccedb3-c489-481f-834f-3e949d4b7dfe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 3: Data Exploration\n",
        "\n",
        "Explore the TPC-H orders data that we'll use for forecasting."
      ],
      "id": "69b836a2-0a28-42f3-9d07-772b842d4691"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__query_order_volume",
        "title": "PY__query_order_volume"
      },
      "source": [
        "# Query order volume by month\n",
        "orders_query = f\"\"\"\n",
        "SELECT \n",
        "    DATE_TRUNC('MONTH', O_ORDERDATE) as ORDER_MONTH,\n",
        "    COUNT(*) as ORDER_COUNT,\n",
        "    SUM(O_TOTALPRICE) as TOTAL_REVENUE,\n",
        "    AVG(O_TOTALPRICE) as AVG_ORDER_VALUE\n",
        "FROM {SOURCE_DATABASE}.{SOURCE_SCHEMA}.ORDERS\n",
        "GROUP BY DATE_TRUNC('MONTH', O_ORDERDATE)\n",
        "ORDER BY ORDER_MONTH\n",
        "\"\"\"\n",
        "\n",
        "orders_df = session.sql(orders_query).to_pandas()\n",
        "print(f\"Loaded {len(orders_df)} months of order data\")\n",
        "print(f\"Date range: {orders_df['ORDER_MONTH'].min()} to {orders_df['ORDER_MONTH'].max()}\")\n",
        "orders_df.head(10)"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "eb722ad6-47f3-4586-a713-efa3a08b9f4b"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__plot_orders",
        "title": "R__plot_orders"
      },
      "source": "%%R -i orders_df -w 900 -h 400\nR__plot_order_history\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\n# Convert to proper date type\norders_df$ORDER_MONTH <- as.Date(orders_df$ORDER_MONTH)\n\n# Plot order count time series\np <- ggplot(orders_df, aes(x = ORDER_MONTH, y = ORDER_COUNT)) +\n    geom_line(color = \"steelblue\", linewidth = 1) +\n    geom_point(color = \"steelblue\", size = 2) +\n    scale_y_continuous(labels = comma) +\n    scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n    labs(\n        title = \"Monthly Order Volume (TPC-H)\",\n        subtitle = \"Time series data for forecasting\",\n        x = \"Month\",\n        y = \"Number of Orders\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(plot.title = element_text(face = \"bold\"))\n\nprint(p)",
      "execution_count": null,
      "outputs": [],
      "id": "b30454fe-2ee9-42d9-8798-caea814997a9"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 4: Time Series Preparation\n",
        "\n",
        "Prepare the data as an R time series object for modeling."
      ],
      "id": "483f36ac-a72a-4c74-82ec-72ad74f43974"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__prepare_ts",
        "title": "R__prepare_ts"
      },
      "source": "%%R -i orders_df\nR__prepare_timeseries\nlibrary(forecast)\noptions(width = 200)  # Wider console output\n\n# Ensure proper ordering\norders_df <- orders_df[order(orders_df$ORDER_MONTH), ]\n\n# Extract the target variable (order count)\norder_counts <- orders_df$ORDER_COUNT\n\n# Get start date for ts object\nstart_date <- as.Date(min(orders_df$ORDER_MONTH))\nstart_year <- as.numeric(format(start_date, \"%Y\"))\nstart_month <- as.numeric(format(start_date, \"%m\"))\n\n# Create time series object (monthly frequency = 12)\norders_ts <- ts(order_counts, start = c(start_year, start_month), frequency = 12)\n\nwriteLines(paste0(\n    \"Time Series Summary:\\n\",\n    \"  Length: \", length(orders_ts), \" observations\\n\",\n    \"  Start: \", paste(start(orders_ts), collapse = \" \"), \"\\n\",\n    \"  End: \", paste(end(orders_ts), collapse = \" \"), \"\\n\",\n    \"  Frequency: \", frequency(orders_ts), \" (monthly)\"\n))",
      "execution_count": null,
      "outputs": [],
      "id": "d142b336-2e39-421b-ba96-fa53c3c2248f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__decompose_ts",
        "title": "R__decompose_ts"
      },
      "source": "%%R -w 900 -h 500\nR__decompose_timeseries\n# Decompose the time series to understand components\n# Use STL decomposition (works well for monthly data)\ndecomp <- stl(orders_ts, s.window = \"periodic\")\nplot(decomp, main = \"Time Series Decomposition\")",
      "execution_count": null,
      "outputs": [],
      "id": "2945ac07-f86d-4db7-8e02-17be2bf26c9c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 5: Model Training (R)\n",
        "\n",
        "Train a forecasting model using R's `forecast` package. We'll use `auto.arima()` which automatically selects the best ARIMA parameters."
      ],
      "id": "0321325b-65ae-413c-8a57-5c505b9c4a07"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__train_test_split",
        "title": "R__train_test_split"
      },
      "source": "%%R\nR__train_test_split\nlibrary(forecast)\n\n# Split data: use last 12 months as test set\nn_test <- 12\nn_train <- length(orders_ts) - n_test\n\ntrain_ts <- window(orders_ts, end = c(start_year + floor((n_train-1)/12), ((start_month + n_train - 2) %% 12) + 1))\ntest_ts <- window(orders_ts, start = c(start_year + floor(n_train/12), ((start_month + n_train - 1) %% 12) + 1))\n\nwriteLines(paste0(\n    \"Training set: \", length(train_ts), \" months\\n\",\n    \"Test set: \", length(test_ts), \" months\"\n))",
      "execution_count": null,
      "outputs": [],
      "id": "d5711539-79c7-4c88-9627-8f2c1749e1e7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__train_arima",
        "title": "R__train_arima"
      },
      "source": "%%R\nR__train_arima\n# Train ARIMA model with automatic parameter selection\nwriteLines(\"Training ARIMA model (auto parameter selection)...\")\narima_model <- auto.arima(train_ts, \n                          seasonal = TRUE,\n                          stepwise = FALSE,  # More thorough search\n                          trace = FALSE)\n\nwriteLines(\"\\nModel Summary:\")\nwriteLines(capture.output(summary(arima_model)))",
      "execution_count": null,
      "outputs": [],
      "id": "36c76869-c11e-4356-b841-c618235b2546"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__plot_forecast",
        "title": "R__plot_forecast"
      },
      "source": "%%R -w 900 -h 400\nR__plot_forecast\n# Generate forecast for test period\nforecast_result <- forecast(arima_model, h = n_test)\n\n# Plot forecast vs actuals\nautoplot(forecast_result) +\n    autolayer(test_ts, series = \"Actual\", color = \"red\") +\n    labs(\n        title = \"ARIMA Forecast vs Actual\",\n        subtitle = paste(\"Model:\", arima_model$method),\n        x = \"Time\",\n        y = \"Order Count\"\n    ) +\n    theme_minimal() +\n    theme(legend.position = \"bottom\")",
      "execution_count": null,
      "outputs": [],
      "id": "f450add4-5265-49f4-ac43-a511819a95a7"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__eval_accuracy",
        "title": "R__eval_accuracy"
      },
      "source": "%%R\nR__eval_accuracy\n# Calculate accuracy metrics\naccuracy_metrics <- accuracy(forecast_result, test_ts)\nwriteLines(\"\\nModel Accuracy:\")\nwriteLines(capture.output(print(accuracy_metrics)))",
      "execution_count": null,
      "outputs": [],
      "id": "54faa1cf-4b22-4658-9ea1-db31bc20affe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 5.2 Train Final Model on Full Data\n",
        "\n",
        "Now train the final model on all available data."
      ],
      "id": "b3ea543d-58b7-410e-aa1b-eb4d520fcb43"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__train_final",
        "title": "R__train_final"
      },
      "source": "%%R\nR__train_final_model\n# Train final model on full dataset\nwriteLines(\"Training final model on full dataset...\")\nfinal_model <- auto.arima(orders_ts, \n                          seasonal = TRUE,\n                          stepwise = FALSE)\n\nwriteLines(\"\\nFinal Model:\")\nwriteLines(capture.output(print(final_model)))",
      "execution_count": null,
      "outputs": [],
      "id": "d98d4737-4d6a-4434-acca-80b5ca34e198"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__save_artifact",
        "title": "R__save_artifact"
      },
      "source": "%%R\nR__save_model_artifact\n# Save model to file\nmodel_path <- \"/tmp/orders_forecast_model.rds\"\nsaveRDS(final_model, file = model_path)\nwriteLines(paste0(\n    \"Model saved to: \", model_path, \"\\n\",\n    \"File size: \", file.size(model_path), \" bytes\"\n))",
      "execution_count": null,
      "outputs": [],
      "id": "971f304e-5550-4ff3-a8c9-8ffdeecd777a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 6: Model Packaging\n",
        "\n",
        "Create a Python wrapper class that enables the R model to work with Snowflake Model Registry."
      ],
      "id": "cb16052b-2047-4f07-8f0b-3bc2ca122650"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__define_model_wrapper",
        "title": "PY__define_model_wrapper"
      },
      "source": [
        "# Define the model wrapper class\n",
        "# Following dj_ml_rpy2 pattern: input rows = output rows (1:1 mapping)\n",
        "# Pass periods (1, 2, ..., N) as input, get N forecast rows as output\n",
        "\n",
        "wrapper_code = \"\"\"\n",
        "# Python wrapper for R forecast model using rpy2\n",
        "# Follows dj_ml_rpy2 pattern: number of output rows = number of input rows\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import uuid\n",
        "from snowflake.ml.model import custom_model\n",
        "\n",
        "\n",
        "def _get_rpy2_components():\n",
        "    import rpy2.robjects as ro\n",
        "    from rpy2.robjects import pandas2ri, r\n",
        "    from rpy2.robjects.vectors import FloatVector, IntVector\n",
        "    from rpy2.robjects.conversion import localconverter\n",
        "    from rpy2.rinterface_lib.embedded import RRuntimeError\n",
        "    from rpy2.robjects import numpy2ri\n",
        "    \n",
        "    combined_converter = ro.default_converter + pandas2ri.converter + numpy2ri.converter\n",
        "    return ro, r, FloatVector, IntVector, localconverter, RRuntimeError, combined_converter\n",
        "\n",
        "\n",
        "class ForecastModelWrapper(custom_model.CustomModel):\n",
        "    \n",
        "    def __init__(self, context: custom_model.ModelContext):\n",
        "        super().__init__(context)\n",
        "        self._initialized = False\n",
        "        self._r_model_name = f\"forecast_model_{uuid.uuid4().hex[:8]}\"\n",
        "    \n",
        "    def _ensure_initialized(self):\n",
        "        if self._initialized:\n",
        "            return\n",
        "        \n",
        "        ro, _, _, _, localconverter, _, combined_converter = _get_rpy2_components()\n",
        "        \n",
        "        with localconverter(combined_converter):\n",
        "            ro.r(\"library(forecast)\")\n",
        "            model_path = self.context[\"model_rds\"]\n",
        "            ro.r(f'{self._r_model_name} <- readRDS(\"{model_path}\")')\n",
        "        \n",
        "        self._initialized = True\n",
        "    \n",
        "    @custom_model.inference_api\n",
        "    def predict(self, X: pd.DataFrame) -> pd.DataFrame:\n",
        "        # Following dj_ml_rpy2 pattern: output rows = input rows\n",
        "        self._ensure_initialized()\n",
        "        \n",
        "        # Number of periods to forecast = number of input rows\n",
        "        n_ahead = len(X)\n",
        "        \n",
        "        ro, r, _, _, localconverter, RRuntimeError, combined_converter = _get_rpy2_components()\n",
        "        \n",
        "        uid = uuid.uuid4().hex[:8]\n",
        "        var_pred = f\"pred_{uid}\"\n",
        "        var_mean = f\"mean_{uid}\"\n",
        "        var_lower = f\"lower_{uid}\"\n",
        "        var_upper = f\"upper_{uid}\"\n",
        "        \n",
        "        try:\n",
        "            with localconverter(combined_converter):\n",
        "                # Generate forecast for n_ahead periods\n",
        "                r_code = f'{var_pred} <- forecast({self._r_model_name}, h={n_ahead}); '\n",
        "                r_code += f'{var_mean} <- as.numeric({var_pred}$mean); '\n",
        "                r_code += f'{var_lower} <- as.matrix({var_pred}$lower); '\n",
        "                r_code += f'{var_upper} <- as.matrix({var_pred}$upper)'\n",
        "                ro.r(r_code)\n",
        "                \n",
        "                forecast_mean = np.array(ro.globalenv[var_mean]).flatten()\n",
        "                lower_intervals = np.array(ro.globalenv[var_lower])\n",
        "                upper_intervals = np.array(ro.globalenv[var_upper])\n",
        "                \n",
        "                if lower_intervals.ndim == 1:\n",
        "                    lower_intervals = lower_intervals.reshape(-1, 2)\n",
        "                if upper_intervals.ndim == 1:\n",
        "                    upper_intervals = upper_intervals.reshape(-1, 2)\n",
        "                \n",
        "                ro.r(f\"rm({var_pred}, {var_mean}, {var_lower}, {var_upper})\")\n",
        "            \n",
        "            # Return DataFrame with same number of rows as input\n",
        "            return pd.DataFrame({\n",
        "                \"period\": range(1, n_ahead + 1),\n",
        "                \"point_forecast\": forecast_mean,\n",
        "                \"lower_80\": lower_intervals[:, 0],\n",
        "                \"upper_80\": upper_intervals[:, 0],\n",
        "                \"lower_95\": lower_intervals[:, 1],\n",
        "                \"upper_95\": upper_intervals[:, 1]\n",
        "            })\n",
        "            \n",
        "        except RRuntimeError as e:\n",
        "            try:\n",
        "                ro.r(f\"rm({var_pred}, {var_mean}, {var_lower}, {var_upper})\")\n",
        "            except:\n",
        "                pass\n",
        "            raise RuntimeError(f\"R execution error: {str(e)}\")\n",
        "\"\"\"\n",
        "\n",
        "# Write wrapper to file\n",
        "wrapper_path = \"/tmp/forecast_model_wrapper.py\"\n",
        "with open(wrapper_path, \"w\") as f:\n",
        "    f.write(wrapper_code)\n",
        "\n",
        "print(f\"Model wrapper saved to: {wrapper_path}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "d559ab0b-8110-4531-aa37-89c2980cf6be"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__test_wrapper_local",
        "title": "PY__test_wrapper_local"
      },
      "source": [
        "# Test the wrapper locally\n",
        "import sys\n",
        "sys.path.insert(0, '/tmp')\n",
        "\n",
        "# Reload the module to pick up changes\n",
        "import importlib\n",
        "import forecast_model_wrapper\n",
        "importlib.reload(forecast_model_wrapper)\n",
        "\n",
        "from forecast_model_wrapper import ForecastModelWrapper\n",
        "from snowflake.ml.model import custom_model\n",
        "\n",
        "# Create model context pointing to the saved model\n",
        "test_context = custom_model.ModelContext(\n",
        "    model_rds='/tmp/orders_forecast_model.rds'\n",
        ")\n",
        "\n",
        "# Instantiate wrapper\n",
        "wrapper = ForecastModelWrapper(test_context)\n",
        "\n",
        "# Test prediction - pass 6 rows to get 6-period forecast\n",
        "# Following dj_ml_rpy2 pattern: input rows = output rows\n",
        "test_input = pd.DataFrame({'period': range(1, 7)})  # 6 rows\n",
        "print(f\"Input shape: {test_input.shape}\")\n",
        "\n",
        "test_predictions = wrapper.predict(test_input)\n",
        "print(f\"Output shape: {test_predictions.shape}\")\n",
        "print(f\"\\nLocal test predictions (6 periods):\")\n",
        "test_predictions"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "cc9b4418-cb2e-4d4b-ae95-11014446035a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 7: Model Registration\n",
        "\n",
        "Register the model to Snowflake Model Registry for managed deployment."
      ],
      "id": "589191cc-25eb-4b93-a9ba-236972e14574"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__upload_artifact",
        "title": "PY__upload_artifact"
      },
      "source": [
        "# Upload model artifact to stage\n",
        "session.file.put(\n",
        "    \"/tmp/orders_forecast_model.rds\",\n",
        "    f\"@{MODEL_DATABASE}.{MODEL_SCHEMA}.{ARTIFACTS_STAGE}/r_models/\",\n",
        "    auto_compress=False,\n",
        "    overwrite=True\n",
        ")\n",
        "\n",
        "print(f\"Model uploaded to stage: @{ARTIFACTS_STAGE}/r_models/orders_forecast_model.rds\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "78f80a22-ba03-41d4-9baf-bb6242c8d9f1"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__init_registry",
        "title": "PY__init_registry"
      },
      "source": [
        "# Initialize Model Registry\n",
        "from snowflake.ml.registry import Registry\n",
        "\n",
        "reg = Registry(\n",
        "    session=session,\n",
        "    database_name=MODEL_DATABASE,\n",
        "    schema_name=MODEL_SCHEMA\n",
        ")\n",
        "\n",
        "print(f\"Registry initialized: {MODEL_DATABASE}.{MODEL_SCHEMA}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "3d00fc60-8b0b-4f80-945e-b9c2ebc9fa15"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__import_custom_model",
        "title": "PY__import_custom_model"
      },
      "source": "# Import custom model utilities\nfrom snowflake.ml.model import custom_model\nfrom snowflake.ml.model.model_signature import ModelSignature, FeatureSpec, DataType\n\n# Create model context\nmodel_context = custom_model.ModelContext(\n    model_rds='/tmp/orders_forecast_model.rds'\n)\n\n# Instantiate wrapper\nmodel_wrapper = ForecastModelWrapper(model_context)\n\n# Define model signature\n# Following dj_ml_rpy2 pattern: input rows = output rows\n# Pass N rows with period indices, get N forecast rows back\npredict_signature = ModelSignature(\n    inputs=[\n        FeatureSpec(name=\"period\", dtype=DataType.INT64)\n    ],\n    outputs=[\n        FeatureSpec(name=\"period\", dtype=DataType.INT64),\n        FeatureSpec(name=\"point_forecast\", dtype=DataType.DOUBLE),\n        FeatureSpec(name=\"lower_80\", dtype=DataType.DOUBLE),\n        FeatureSpec(name=\"upper_80\", dtype=DataType.DOUBLE),\n        FeatureSpec(name=\"lower_95\", dtype=DataType.DOUBLE),\n        FeatureSpec(name=\"upper_95\", dtype=DataType.DOUBLE)\n    ]\n)\n\n# Sample input for model validation (must match signature)\nsample_input = pd.DataFrame({'period': range(1, 7)})  # 6 rows\n\nprint(\"Model signature defined:\")\nprint(f\"  Input: period (INT64) - N rows for N-period forecast\")\nprint(f\"  Output: 6 columns with N rows (1:1 row mapping)\")\nprint(f\"  Sample input shape: {sample_input.shape}\")",
      "execution_count": null,
      "outputs": [],
      "id": "abaac3a2-aedd-4da5-9203-a113a1760536"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__log_model",
        "title": "PY__log_model"
      },
      "source": [
        "# Log model to registry\n",
        "# Note: version_name is commented out to allow auto-generation (makes notebook re-runnable)\n",
        "model_version = reg.log_model(\n",
        "    model_wrapper,\n",
        "    model_name=MODEL_NAME,\n",
        "    # version_name=MODEL_VERSION,  # Comment out to auto-generate unique version\n",
        "    target_platforms=[\"SNOWPARK_CONTAINER_SERVICES\"],\n",
        "    conda_dependencies=[\n",
        "        \"r-base>=4.1\",\n",
        "        \"r-forecast>=8.0\",\n",
        "        \"rpy2>=3.5\"\n",
        "    ],\n",
        "    signatures={\"predict\": predict_signature},\n",
        "    sample_input_data=sample_input,\n",
        "    comment=\"R ARIMA forecast model for TPC-H orders (trained with auto.arima)\"\n",
        ")\n",
        "\n",
        "print(f\"\\n\u2713 Model registered successfully!\")\n",
        "print(f\"  Name: {model_version.model_name}\")\n",
        "print(f\"  Version: {model_version.version_name}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "1d8a9237-d2ec-406b-abac-da036c9c2146"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__view_models",
        "title": "PY__view_models"
      },
      "source": [
        "# View registered models\n",
        "reg.show_models()"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "1a0be539-086f-4d47-96f8-7388c0dc0076"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 8: Inference\n",
        "\n",
        "Deploy the model and run predictions via SPCS."
      ],
      "id": "a77011c8-9ade-4a74-ab43-f51592e455ec"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__create_spcs_resources",
        "title": "PY__create_spcs_resources"
      },
      "source": [
        "# Create SPCS resources\n",
        "session.sql(f\"\"\"\n",
        "    CREATE COMPUTE POOL IF NOT EXISTS {COMPUTE_POOL}\n",
        "    MIN_NODES = 1\n",
        "    MAX_NODES = 2\n",
        "    INSTANCE_FAMILY = 'CPU_X64_M'\n",
        "    AUTO_RESUME = TRUE\n",
        "    COMMENT = 'Compute pool for R forecast model inference'\n",
        "\"\"\").collect()\n",
        "print(f\"\u2713 Compute pool: {COMPUTE_POOL}\")\n",
        "\n",
        "session.sql(f\"\"\"\n",
        "    CREATE IMAGE REPOSITORY IF NOT EXISTS {MODEL_DATABASE}.{MODEL_SCHEMA}.{IMAGE_REPO}\n",
        "    COMMENT = 'Repository for R forecast model images'\n",
        "\"\"\").collect()\n",
        "print(f\"\u2713 Image repository: {IMAGE_REPO}\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "6ff90a12-b2cd-4a83-a929-70f32fca4d61"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__deploy_model",
        "title": "PY__deploy_model"
      },
      "source": [
        "# Deploy model to SPCS\n",
        "# Drop existing service if it exists (makes notebook re-runnable)\n",
        "try:\n",
        "    session.sql(f\"DROP SERVICE IF EXISTS {MODEL_DATABASE}.{MODEL_SCHEMA}.{SERVICE_NAME}\").collect()\n",
        "    print(f\"Dropped existing service: {SERVICE_NAME}\")\n",
        "except Exception as e:\n",
        "    print(f\"Note: {e}\")\n",
        "\n",
        "model_version.create_service(\n",
        "    service_name=SERVICE_NAME,\n",
        "    service_compute_pool=COMPUTE_POOL,\n",
        "    image_repo=IMAGE_REPO,\n",
        "    ingress_enabled=True,\n",
        "    max_instances=1\n",
        ")\n",
        "\n",
        "print(f\"Model deployment started: {SERVICE_NAME}\")\n",
        "print(\"Building container image... (this may take 5-10 minutes for first deployment)\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "aa818656-7982-4ad3-b10b-2f0318f53356"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__check_service_status",
        "title": "PY__check_service_status"
      },
      "source": [
        "# Check service status\n",
        "import time\n",
        "\n",
        "for i in range(20):\n",
        "    status = session.sql(f\"SHOW SERVICES LIKE '{SERVICE_NAME}'\").collect()\n",
        "    if status:\n",
        "        current_status = status[0]['status']\n",
        "        print(f\"Service status: {current_status}\")\n",
        "        if current_status == 'RUNNING':\n",
        "            print(\"\u2713 Service is running!\")\n",
        "            break\n",
        "    time.sleep(30)\n",
        "else:\n",
        "    print(\"Service not ready yet - check status manually\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "8f9a7a80-df55-42b6-a852-75f6dc06e45d"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__run_inference",
        "title": "PY__run_inference"
      },
      "source": [
        "# Run inference - pass 12 rows to get 12-month forecast\n",
        "# Following dj_ml_rpy2 pattern: input rows = output rows\n",
        "\n",
        "# Create input with 12 rows (one per forecast period)\n",
        "inference_input = session.create_dataframe(\n",
        "    pd.DataFrame({'period': range(1, 13)})  # 12 rows\n",
        ")\n",
        "\n",
        "print(f\"Input: {inference_input.count()} rows\")\n",
        "print(\"Running inference via SPCS...\")\n",
        "start_time = time.time()\n",
        "\n",
        "predictions = model_version.run(\n",
        "    inference_input,\n",
        "    function_name=\"predict\",\n",
        "    service_name=SERVICE_NAME\n",
        ")\n",
        "\n",
        "elapsed = time.time() - start_time\n",
        "print(f\"Inference completed in {elapsed:.2f} seconds\")\n",
        "\n",
        "# Convert to pandas for display\n",
        "predictions_df = predictions.to_pandas()\n",
        "\n",
        "# Lowercase column names for R compatibility\n",
        "predictions_df.columns = [c.lower() for c in predictions_df.columns]\n",
        "\n",
        "print(f\"Output: {len(predictions_df)} rows\")\n",
        "predictions_df"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "4aeeed90-b67d-4b56-89a4-61be50686ecd"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 9: Visualization\n",
        "\n",
        "Visualize the forecast results with ggplot2."
      ],
      "id": "78f9ddc1-a382-4d6c-adcf-dfe98130faf4"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__plot_predictions",
        "title": "R__plot_predictions"
      },
      "source": "%%R -i predictions_df -i orders_df -w 900 -h 500\nR__plot_predictions\nlibrary(ggplot2)\nlibrary(dplyr)\nlibrary(scales)\n\n# Get the last date from historical data\norders_df$ORDER_MONTH <- as.Date(orders_df$ORDER_MONTH)\nlast_date <- max(orders_df$ORDER_MONTH)\n\n# Create future dates for predictions\npredictions_df$forecast_date <- seq.Date(\n    from = last_date + 30,\n    by = \"month\",\n    length.out = nrow(predictions_df)\n)\n\n# Prepare data for plotting (using lowercase column names)\nforecast <- data.frame(\n    date = predictions_df$forecast_date,\n    value = predictions_df$point_forecast,\n    lower_80 = predictions_df$lower_80,\n    upper_80 = predictions_df$upper_80,\n    lower_95 = predictions_df$lower_95,\n    upper_95 = predictions_df$upper_95\n)\n\n# Create the plot\np <- ggplot() +\n    geom_ribbon(data = forecast, \n                aes(x = date, ymin = lower_95, ymax = upper_95),\n                fill = \"steelblue\", alpha = 0.2) +\n    geom_ribbon(data = forecast,\n                aes(x = date, ymin = lower_80, ymax = upper_80),\n                fill = \"steelblue\", alpha = 0.3) +\n    geom_line(data = orders_df, \n              aes(x = ORDER_MONTH, y = ORDER_COUNT),\n              color = \"black\", linewidth = 1) +\n    geom_line(data = forecast,\n              aes(x = date, y = value),\n              color = \"steelblue\", linewidth = 1, linetype = \"dashed\") +\n    geom_point(data = forecast,\n               aes(x = date, y = value),\n               color = \"steelblue\", size = 2) +\n    scale_y_continuous(labels = comma) +\n    scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n    labs(\n        title = \"TPC-H Orders Forecast\",\n        subtitle = \"12-month forecast with 80% and 95% confidence intervals\",\n        x = \"Date\",\n        y = \"Order Count\"\n    ) +\n    theme_minimal(base_size = 12) +\n    theme(plot.title = element_text(face = \"bold\"))\n\nprint(p)",
      "execution_count": null,
      "outputs": [],
      "id": "1d25846b-42f9-4d74-8b6c-14c70997563f"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "R__save_plot",
        "title": "R__save_plot"
      },
      "source": "%%R -w 700 -h 400\nR__save_plot\n# Save the forecast plot\nggsave(\"/tmp/orders_forecast.png\", p, width = 10, height = 6, dpi = 150)\ncat(\"Forecast plot saved to /tmp/orders_forecast.png\\n\")",
      "execution_count": null,
      "outputs": [],
      "id": "16338d88-08e0-4355-b54d-43d83fae8e70"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__display_plot",
        "title": "PY__display_plot"
      },
      "source": [
        "# Display saved plot\n",
        "from IPython.display import Image, display\n",
        "display(Image(filename=\"/tmp/orders_forecast.png\"))"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "623de47c-03be-439e-9a3a-660115d55f90"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 10: Cleanup\n",
        "\n",
        "Optional cleanup of resources created in this notebook."
      ],
      "id": "d3330503-11d5-4a05-b0de-85ca65dd39ad"
    },
    {
      "cell_type": "code",
      "metadata": {
        "language": "python",
        "name": "PY__cleanup_resources",
        "title": "PY__cleanup_resources"
      },
      "source": [
        "# Uncomment to clean up resources\n",
        "\n",
        "# Delete service\n",
        "# model_version.delete_service(SERVICE_NAME)\n",
        "# print(f\"Deleted service: {SERVICE_NAME}\")\n",
        "\n",
        "# Delete model from registry\n",
        "# reg.delete_model(MODEL_NAME)\n",
        "# print(f\"Deleted model: {MODEL_NAME}\")\n",
        "\n",
        "# Drop SPCS resources\n",
        "# session.sql(f\"DROP COMPUTE POOL IF EXISTS {COMPUTE_POOL}\").collect()\n",
        "# session.sql(f\"DROP IMAGE REPOSITORY IF EXISTS {MODEL_DATABASE}.{MODEL_SCHEMA}.{IMAGE_REPO}\").collect()\n",
        "# print(\"Dropped compute pool and image repository\")\n",
        "\n",
        "print(\"Cleanup section - uncomment lines above to delete resources\")"
      ],
      "execution_count": null,
      "outputs": [],
      "id": "68864497-95b4-48b0-b557-9476954f890e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "This notebook demonstrated:\n",
        "\n",
        "1. **R Environment Setup** - Installing R and forecast package in Workspace Notebooks\n",
        "2. **Data Exploration** - Querying TPC-H data from Snowflake\n",
        "3. **Time Series Preparation** - Creating R time series objects\n",
        "4. **Model Training** - Using `auto.arima()` for automatic model selection\n",
        "5. **Model Packaging** - Creating a Python wrapper with rpy2 for registry compatibility\n",
        "6. **Model Registration** - Logging to Snowflake Model Registry\n",
        "7. **Inference** - Running predictions via SPCS\n",
        "8. **Visualization** - Creating publication-quality charts with ggplot2\n",
        "\n",
        "### Key Technologies\n",
        "\n",
        "| Component | Purpose |\n",
        "|-----------|---------|\n",
        "| rpy2 | Python-R bridge for %%R magic cells |\n",
        "| forecast (R) | Time series modeling (ARIMA, ETS, etc.) |\n",
        "| Snowflake Model Registry | Model versioning and management |\n",
        "| SPCS | Container-based inference runtime |\n",
        "| ggplot2 | Publication-quality visualizations |\n",
        "\n",
        "### Next Steps\n",
        "\n",
        "- Try different forecasting models (ETS, Prophet, etc.)\n",
        "- Add exogenous variables for ARIMAX models\n",
        "- Set up scheduled inference with Snowflake Tasks\n",
        "- Create dashboards with Streamlit in Snowflake"
      ],
      "id": "c10c546e-1ed7-4a6e-962b-7ba3ae2b1fb6"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}