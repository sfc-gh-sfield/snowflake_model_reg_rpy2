{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bb3ecf4a-ef26-4a83-9670-2a23fdf5e64d",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "# R in Snowflake Workspace Notebooks\n",
        "\n",
        "This notebook demonstrates how to use R within Snowflake Workspace Notebooks using rpy2.\n",
        "\n",
        "**Capabilities:**\n",
        "- Execute R code in `%%R` magic cells alongside Python\n",
        "- Transfer data bidirectionally between Python and R\n",
        "- Connect to Snowflake from R using ADBC (PAT or Key Pair) or Reticulate + Snowpark\n",
        "\n",
        "**Sections:**\n",
        "1. [Installation & Configuration](#section-1-installation--configuration)\n",
        "2. [Python & R Interoperability](#section-2-python--r-interoperability)\n",
        "3. [Snowflake via ADBC](#section-3-snowflake-database-connectivity) (PAT authentication)\n",
        "4. [Key Pair Authentication](#section-4-alternative-authentication---key-pair-jwt) (alternative to PAT)\n",
        "5. [Snowflake via Reticulate](#section-5-reticulate---access-snowpark-from-r) (no auth setup needed)\n",
        "6. [Data Visualization with ggplot2](#section-6-data-visualization-with-ggplot2) (charts and plots)\n",
        "7. [DuckDB Integration](#section-7-duckdb-integration-experimental) (dplyr + dbplyr workflows)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da3e6d58-aaf8-43be-90c7-cf76455e23ee",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 1: Installation & Configuration\n",
        "\n",
        "This section sets up R and rpy2 in the Workspace Notebook environment.\n",
        "\n",
        "## Overview\n",
        "\n",
        "Snowflake Workspace Notebooks run in containers with a managed Python kernel. To use R:\n",
        "\n",
        "1. **Install R** via micromamba (lightweight conda-compatible package manager)\n",
        "2. **Install rpy2** into the notebook's Python kernel\n",
        "3. **Register `%%R` magic** for R cell support\n",
        "\n",
        "## Customizing R Packages\n",
        "\n",
        "Edit `r_packages.yaml` to customize which R packages are installed:\n",
        "\n",
        "```yaml\n",
        "# Conda-forge packages (installed via micromamba)\n",
        "conda_packages:\n",
        "  - r-base           # Required: Base R\n",
        "  - r-tidyverse      # Data manipulation\n",
        "  - r-yourpackage    # Add packages here\n",
        "\n",
        "# CRAN packages (installed via install.packages)\n",
        "cran_packages:\n",
        "  - somepackage      # Packages not available on conda-forge\n",
        "```\n",
        "\n",
        "## Installation Options\n",
        "\n",
        "| Command | Description |\n",
        "|---------|-------------|\n",
        "| `bash setup_r_environment.sh` | Basic R installation |\n",
        "| `bash setup_r_environment.sh --adbc` | R + ADBC driver for Snowflake connectivity |\n",
        "| `bash setup_r_environment.sh --verbose` | Show detailed logging |\n",
        "| `bash setup_r_environment.sh --help` | Show all options |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "110f15a0-8ee6-4381-aef1-b107ce941a9a",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 1.1 Install R Environment\n",
        "\n",
        "Run the setup script. Choose `--basic` for R only, or `--adbc` to include ADBC Snowflake driver.\n",
        "\n",
        "**Note:** This step takes 2-5 minutes on first run. The `--adbc` option takes longer as it compiles the Snowflake driver.\n",
        "\n",
        "The script includes:\n",
        "- Pre-flight checks (disk space, network connectivity)\n",
        "- Automatic retry for network operations\n",
        "- Logging to `setup_r.log` for debugging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c47b16da-93c7-4d39-a76b-8b97291c3f3c",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Choose ONE of the following:\n",
        "\n",
        "# Option A: Basic R installation (faster)\n",
        "# !bash setup_r_environment.sh --basic\n",
        "\n",
        "# Option B: R + ADBC for Snowflake connectivity (required for Section 3)\n",
        "!bash setup_r_environment.sh --adbc"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b76d476-0f07-48f8-aa54-1774c1ea5d58",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 1.2 Configure Python Environment & Install rpy2\n",
        "\n",
        "This cell uses the helper module to:\n",
        "1. Point Python to the R environment\n",
        "2. Install rpy2 into the notebook kernel\n",
        "3. Register the `%%R` magic\n",
        "4. Load output helper functions for cleaner display\n",
        "\n",
        "**Run this cell after the installation script completes.**\n",
        "\n",
        "**Output Helpers:** Workspace Notebooks add extra line breaks to R output. After setup, use these R functions for cleaner formatting:\n",
        "\n",
        "| Function | Usage | Description |\n",
        "|----------|-------|-------------|\n",
        "| `rprint(x)` | `rprint(df)` | Print any object cleanly |\n",
        "| `rview(df, n)` | `rview(iris, n=10)` | View data frame with optional row limit |\n",
        "| `rglimpse(df)` | `rglimpse(df)` | Glimpse data frame structure |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8aa92858-c66e-4875-bbe0-0e8f9567e2d2",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Method 1: Using the helper module (recommended)\n",
        "import sys\n",
        "sys.path.insert(0, '.')  # Ensure current directory is in path\n",
        "\n",
        "from r_helpers import setup_r_environment\n",
        "\n",
        "result = setup_r_environment()\n",
        "\n",
        "if result['success']:\n",
        "    print(\"‚úì R environment configured successfully\")\n",
        "    print(f\"  R version: {result['r_version']}\")\n",
        "    print(f\"  rpy2 installed: {result['rpy2_installed']}\")\n",
        "    print(f\"  %%R magic registered: {result['magic_registered']}\")\n",
        "else:\n",
        "    print(\"‚úó Setup failed:\")\n",
        "    for error in result['errors']:\n",
        "        print(f\"  - {error}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6369cbe4-4fd4-4d0a-8678-db2a4bdcbca1",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Method 2: Manual configuration (if helper module not available)\n",
        "# Uncomment and run if Method 1 fails\n",
        "\n",
        "# import os\n",
        "# import sys\n",
        "# import subprocess\n",
        "\n",
        "# ENV_PREFIX = \"/root/.local/share/mamba/envs/r_env\"\n",
        "# os.environ[\"PATH\"] = f\"{ENV_PREFIX}/bin:\" + os.environ[\"PATH\"]\n",
        "# os.environ[\"R_HOME\"] = f\"{ENV_PREFIX}/lib/R\"\n",
        "\n",
        "# subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"rpy2\", \"-q\"], check=True)\n",
        "\n",
        "# from rpy2.ipython import rmagic\n",
        "# get_ipython().register_magics(rmagic.RMagics)\n",
        "# print(\"R environment configured\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6d34bdc6-d048-4c44-9ff6-36c3108708a4",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 1.3 Verify R Installation\n",
        "\n",
        "Test that R is working correctly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11c5904b-aaee-4c87-83ec-c391ae8f47db",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Print R version (simple output works fine)\n",
        "R.version.string"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d0687bf2-1bfc-479f-917b-300759dafdc1",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# List installed packages\n",
        "# Use rprint() for cleaner output in Workspace Notebooks\n",
        "ip <- as.data.frame(installed.packages()[, c(1, 3:4)])\n",
        "ip <- ip[is.na(ip$Priority), 1:2, drop = FALSE]\n",
        "rprint(ip)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd6e9057-a693-43a1-bb3c-60d64b8a9d3b",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### 1.4 Run Diagnostics (Optional)\n",
        "\n",
        "Run comprehensive environment diagnostics to verify all components are working."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6d5316e-ecac-490c-ae5f-bda9d1bdc534",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from r_helpers import check_environment, print_diagnostics\n",
        "\n",
        "# Run and display diagnostics\n",
        "print_diagnostics()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1.5 Installing Additional R Packages\n",
        "\n",
        "You can install R packages in two ways:\n",
        "\n",
        "1. **Via `r_packages.yaml`** - Add packages before running the setup script (recommended for reproducibility)\n",
        "2. **From within a `%%R` cell** - Install packages interactively during your session\n",
        "\n",
        "The examples below show how to install packages from within the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%R\n",
        "# Install R packages into the micromamba environment\n",
        "# Set the library path to ensure packages go to the right location\n",
        "lib_path <- \"/root/.local/share/mamba/envs/r_env/lib/R/library\"\n",
        ".libPaths(lib_path)\n",
        "\n",
        "# Example: Install 'forecast' package if not already installed\n",
        "if (!require(\"forecast\", quietly = TRUE)) {\n",
        "    cat(\"Installing forecast package...\\n\")\n",
        "    install.packages(\"forecast\", repos = \"https://cloud.r-project.org/\", lib = lib_path)\n",
        "}\n",
        "\n",
        "# Verify installation\n",
        "library(forecast)\n",
        "cat(\"forecast version:\", as.character(packageVersion(\"forecast\")), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%R\n",
        "# Alternative: Use micromamba for packages with complex dependencies\n",
        "# This is better for compiled packages that need system libraries\n",
        "\n",
        "# Install via micromamba (runs in background)\n",
        "system(\"/root/.local/share/mamba/bin/micromamba install -n r_env -c conda-forge r-forecast -y\", \n",
        "       ignore.stdout = TRUE)\n",
        "\n",
        "# Reload library path and verify\n",
        ".libPaths(\"/root/.local/share/mamba/envs/r_env/lib/R/library\")\n",
        "library(forecast)\n",
        "cat(\"forecast installed via micromamba\\n\")\n",
        "cat(\"Version:\", as.character(packageVersion(\"forecast\")), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eeaa30a6-e61e-4a4d-a942-742b808aaa08",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 2: Python & R Interoperability\n",
        "\n",
        "This section demonstrates how to work with data in both Python and R, including:\n",
        "- Using the `%%R` magic for R cells\n",
        "- Passing data from Python to R\n",
        "- Passing data from R to Python\n",
        "- Running R functions from Python"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8921eed3-bfee-423e-a3ea-3464d7644af4",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 2.1 Using %%R Magic Cells\n",
        "\n",
        "The `%%R` magic lets you write R code directly in a cell. The magic supports flags:\n",
        "\n",
        "| Flag | Description |\n",
        "|------|-------------|\n",
        "| `-i var` | Import Python variable `var` into R |\n",
        "| `-o var` | Export R variable `var` back to Python |\n",
        "| `-w WIDTH` | Set plot width |\n",
        "| `-h HEIGHT` | Set plot height |"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c0b6790-046d-4395-9d7f-b3dbec39def9",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Basic R operations\n",
        "x <- c(1, 2, 3, 4, 5)\n",
        "mean(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f2ef3bb-538f-437d-9629-46c6977bd5af",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Using tidyverse\n",
        "library(dplyr)\n",
        "\n",
        "rprint(\n",
        "data.frame(\n",
        "  name = c(\"Alice\", \"Bob\", \"Charlie\"),\n",
        "  score = c(85, 92, 78)\n",
        ") %>%\n",
        "  mutate(grade = case_when(\n",
        "    score >= 90 ~ \"A\",\n",
        "    score >= 80 ~ \"B\",\n",
        "    TRUE ~ \"C\"\n",
        "  ))\n",
        ")  "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f4e22a3c-b996-418b-9dc7-3c9e51cdcb9a",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 2.2 Passing Data: Python ‚Üí R\n",
        "\n",
        "Use the `-i` flag to pass Python objects into R cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62ae0e2d-6275-45c1-8878-498163bcc167",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Create a pandas DataFrame in Python\n",
        "import pandas as pd\n",
        "\n",
        "python_df = pd.DataFrame({\n",
        "    'city': ['New York', 'Los Angeles', 'Chicago', 'Houston'],\n",
        "    'population': [8336817, 3979576, 2693976, 2320268],\n",
        "    'area_sq_mi': [302.6, 468.7, 227.3, 670.6]\n",
        "})\n",
        "\n",
        "print(\"Python DataFrame:\")\n",
        "python_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96305029-d546-4e7b-9f18-f4e5cae75341",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R -i python_df\n",
        "# The Python DataFrame is now available in R as 'python_df'\n",
        "library(dplyr)\n",
        "\n",
        "cat(\"Received DataFrame in R:\\n\")\n",
        "rglimpse(python_df)  # Use rglimpse() for clean output\n",
        "\n",
        "# Perform R operations\n",
        "result <- python_df %>%\n",
        "  mutate(density = population / area_sq_mi) %>%\n",
        "  arrange(desc(density))\n",
        "\n",
        "rprint(result)  # Use rprint() for clean output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f80d038b-c7fa-44f4-b224-74e62a334d90",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 2.3 Passing Data: R ‚Üí Python\n",
        "\n",
        "Use the `-o` flag to export R objects back to Python."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6624ecbd-01c1-4737-9581-7400053d80e2",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R -o r_result\n",
        "# Create a data frame in R\n",
        "r_result <- data.frame(\n",
        "  x = 1:10,\n",
        "  y = (1:10)^2,\n",
        "  label = paste0(\"Point_\", 1:10)\n",
        ")\n",
        "\n",
        "cat(\"Created R data.frame:\\n\")\n",
        "rprint(r_result)  # Use rprint() for clean output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4f0196ae-2a28-4b7c-a644-2af75ab3e238",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# The R data.frame is now available in Python\n",
        "print(\"R result in Python:\")\n",
        "print(type(r_result))\n",
        "print(r_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dba3b2c-8594-46a9-aff9-bc47f5864621",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 2.4 Using R from Python (without magic)\n",
        "\n",
        "For more control, you can use rpy2's Python API directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e91b7472-100e-4d4a-8cf3-d75359519ecc",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects.packages import importr\n",
        "from rpy2.robjects import pandas2ri\n",
        "from rpy2.robjects.conversion import localconverter\n",
        "\n",
        "# Import R packages\n",
        "base = importr('base')\n",
        "stats = importr('stats')\n",
        "\n",
        "# Run R code and get results\n",
        "result = ro.r('sum(1:100)')\n",
        "print(f\"Sum of 1 to 100: {result[0]}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b2d9baa1-fc0a-4e7e-929c-2c023e841256",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Convert pandas DataFrame to R and run R functions on it\n",
        "import pandas as pd\n",
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "\n",
        "# Create sample data\n",
        "df = pd.DataFrame({\n",
        "    'x': [1, 2, 3, 4, 5],\n",
        "    'y': [2.1, 3.9, 6.2, 7.8, 10.1]\n",
        "})\n",
        "\n",
        "# Convert to R and run linear regression\n",
        "with (ro.default_converter + pandas2ri.converter).context():\n",
        "    r_df = ro.conversion.get_conversion().py2rpy(df)\n",
        "\n",
        "# Run linear regression in R\n",
        "lm_result = stats.lm('y ~ x', data=r_df)\n",
        "print(\"Linear Regression Results:\")\n",
        "print(base.summary(lm_result))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6cea2255-06a5-4543-a815-62ab6ac34948",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 2.5 Working with R's Built-in Datasets\n",
        "\n",
        "Access R's built-in datasets and convert them to pandas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90506701-31d8-401e-9b79-9dcebed176ae",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "import rpy2.robjects as ro\n",
        "from rpy2.robjects import pandas2ri\n",
        "from rpy2.robjects.conversion import localconverter\n",
        "\n",
        "# Load the iris dataset in R\n",
        "ro.r(\"data(iris)\")\n",
        "\n",
        "# Get the R data.frame\n",
        "iris_r = ro.r[\"iris\"]\n",
        "\n",
        "# Convert to pandas DataFrame\n",
        "with localconverter(ro.default_converter + pandas2ri.converter):\n",
        "    iris_df = pandas2ri.rpy2py(iris_r)\n",
        "\n",
        "print(\"Iris dataset (first 10 rows):\")\n",
        "iris_df.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f35bd66a-491d-4ee4-9e5e-fb66a5fb74fc",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 3: Snowflake Database Connectivity\n",
        "\n",
        "This section demonstrates connecting to Snowflake from R using ADBC.\n",
        "\n",
        "**Prerequisites:**\n",
        "- Run the setup script with `--adbc` flag (Section 1.1)\n",
        "- Have appropriate Snowflake permissions\n",
        "\n",
        "## Authentication Options\n",
        "\n",
        "| Method | Status | Notes |\n",
        "|--------|--------|-------|\n",
        "| Python `get_active_session()` | ‚úÖ Works | Use for Snowpark queries, bridge to R via rpy2 |\n",
        "| ADBC with PAT | ‚úÖ Works | Direct R-to-Snowflake, requires PAT token |\n",
        "| SPCS OAuth Token | ‚ùå Blocked | Container token not authorized for ADBC |\n",
        "| Username/Password | ‚ùå Blocked | SPCS requires OAuth |\n",
        "\n",
        "## Connection Management\n",
        "\n",
        "This notebook uses connection pooling - the ADBC connection is stored as `r_sf_con` in R's global environment and reused across cells. This avoids the overhead of creating new connections for each query."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d554f970-0734-4b7a-bac6-de8a4851afd3",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 3.1 Setup Python Session\n",
        "\n",
        "First, establish the standard Python Snowpark session."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7308601a-bba7-43b7-b962-eb71ccd7b3bf",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from snowflake.snowpark.context import get_active_session\n",
        "\n",
        "session = get_active_session()\n",
        "\n",
        "# Print connection details\n",
        "print(\"Snowflake Connection:\")\n",
        "print(f\"  Account:   {session.sql('SELECT CURRENT_ACCOUNT()').collect()[0][0]}\")\n",
        "print(f\"  User:      {session.sql('SELECT CURRENT_USER()').collect()[0][0]}\")\n",
        "print(f\"  Role:      {session.get_current_role()}\")\n",
        "print(f\"  Database:  {session.get_current_database()}\")\n",
        "print(f\"  Schema:    {session.get_current_schema()}\")\n",
        "print(f\"  Warehouse: {session.get_current_warehouse()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "009cd9dc-7edb-45c5-a9ac-4ef46cd7343f",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 3.2 Create Programmatic Access Token (PAT)\n",
        "\n",
        "ADBC requires a PAT for authentication. Use the `PATManager` helper class for token management.\n",
        "\n",
        "**Features:**\n",
        "- Automatic expiry tracking\n",
        "- Token refresh when needed\n",
        "- Secure environment variable storage\n",
        "\n",
        "**Security Notes:**\n",
        "- PAT is stored in environment variable (not persisted)\n",
        "- Token expires after specified duration\n",
        "- Use `ROLE_RESTRICTION` to limit token scope"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82c5b82f-6b67-475f-ba93-82c671356582",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from r_helpers import PATManager\n",
        "\n",
        "# Initialize PAT manager\n",
        "pat_mgr = PATManager(session)\n",
        "\n",
        "# Create a new PAT (or refresh existing one)\n",
        "result = pat_mgr.create_pat(\n",
        "    days_to_expiry=1,           # Token valid for 1 day\n",
        "    force_recreate=True,        # Replace existing token\n",
        "    network_policy_bypass_mins=240  # 4 hour bypass\n",
        ")\n",
        "\n",
        "if result['success']:\n",
        "    print(f\"‚úì PAT created successfully\")\n",
        "    print(f\"  User: {result['user']}\")\n",
        "    print(f\"  Role restriction: {result['role_restriction']}\")\n",
        "    print(f\"  Expires: {result['expires_at']}\")\n",
        "else:\n",
        "    print(f\"‚úó PAT creation failed: {result['error']}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4e60a83b-c4aa-4aa2-bb04-ea156b006f94",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Check PAT status at any time\n",
        "status = pat_mgr.get_status()\n",
        "print(\"PAT Status:\")\n",
        "for key, value in status.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "842178d4-957e-4c55-8c11-e0b39f1246be",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 3.3 Validate ADBC Prerequisites\n",
        "\n",
        "Before connecting, validate that all ADBC prerequisites are met."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6864614e-d4dc-4470-af1d-8d7664faaa2b",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from r_helpers import validate_adbc_connection\n",
        "\n",
        "valid, message = validate_adbc_connection()\n",
        "print(message)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6eff7ee7-16d2-411d-b76c-ee5773148b32",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 3.4 Initialize R Connection Management\n",
        "\n",
        "Load the connection management functions into R. This provides:\n",
        "- `get_snowflake_connection()` - Get or create connection (stored as `r_sf_con`)\n",
        "- `close_snowflake_connection()` - Close and release connection\n",
        "- `is_snowflake_connected()` - Check connection status\n",
        "- `snowflake_connection_status()` - Get detailed status"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13a8002d-624c-444d-80de-e99924526040",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from r_helpers import init_r_connection_management\n",
        "\n",
        "success, msg = init_r_connection_management()\n",
        "print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "160d5092-fac0-42e8-b661-c7f286bdd7c6",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 3.5 Connect to Snowflake from R (ADBC)\n",
        "\n",
        "Use `get_snowflake_connection()` to establish or reuse the ADBC connection.\n",
        "\n",
        "The connection is stored as `r_sf_con` in R's global environment and is automatically reused in subsequent cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e34f2297-86d4-4141-ade0-4e16e852a595",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Get or create the Snowflake connection\n",
        "# Connection is stored globally as r_sf_con\n",
        "r_sf_con <- get_snowflake_connection()\n",
        "\n",
        "# Show connection status (uses print_connection_status() for clean output)\n",
        "print_connection_status()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7253f50d-eec9-4108-a3bf-2f917bbddd8a",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 3.6 Query Snowflake from R\n",
        "\n",
        "Run queries using the `r_sf_con` connection. The connection is automatically reused across cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa4d1703-f628-4683-b543-fe90d645e996",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Simple test query using r_sf_con\n",
        "r_sf_con |>\n",
        "  read_adbc(\"SELECT CURRENT_USER() AS USER, CURRENT_ROLE() AS ROLE, CURRENT_WAREHOUSE() AS WAREHOUSE\") |>\n",
        "  tibble::as_tibble()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fb06f5a2-bd50-460c-835e-10336cf2ce26",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Query sample data from Snowflake\n",
        "# Using the shared SNOWFLAKE_SAMPLE_DATA database\n",
        "nations <- r_sf_con |>\n",
        "  read_adbc(\"\n",
        "    SELECT N_NATIONKEY, N_NAME, N_REGIONKEY \n",
        "    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.NATION \n",
        "    ORDER BY N_NATIONKEY\n",
        "    LIMIT 10\n",
        "  \") |>\n",
        "  tibble::as_tibble()\n",
        "\n",
        "nations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9b7b830e-423c-44dc-b991-5f77041f4596",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# More complex query with aggregation\n",
        "library(dplyr)\n",
        "\n",
        "orders_summary <- r_sf_con |>\n",
        "  read_adbc(\"\n",
        "    SELECT \n",
        "      O_ORDERSTATUS,\n",
        "      COUNT(*) as ORDER_COUNT,\n",
        "      SUM(O_TOTALPRICE) as TOTAL_VALUE,\n",
        "      AVG(O_TOTALPRICE) as AVG_VALUE\n",
        "    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS\n",
        "    GROUP BY O_ORDERSTATUS\n",
        "    ORDER BY ORDER_COUNT DESC\n",
        "  \") |>\n",
        "  tibble::as_tibble()\n",
        "\n",
        "orders_summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9781d24e-c833-48cf-aad8-199ab9a66dda",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Verify connection is being reused (not recreated)\n",
        "cat(\"Connection still valid:\", is_snowflake_connected(), \"\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "548ca051-cac6-49f9-96a5-96c671d6c933",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 3.7 Query from Python, Analyze in R\n",
        "\n",
        "An alternative pattern: use Python's Snowpark session for querying, then pass data to R for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5cd3f588-93a1-4a0a-a758-e6def9a507aa",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Query using Python Snowpark session\n",
        "customers_df = session.sql(\"\"\"\n",
        "    SELECT \n",
        "        C_CUSTKEY,\n",
        "        C_NAME,\n",
        "        C_NATIONKEY,\n",
        "        C_ACCTBAL\n",
        "    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER\n",
        "    LIMIT 100\n",
        "\"\"\").to_pandas()\n",
        "\n",
        "print(f\"Retrieved {len(customers_df)} rows\")\n",
        "customers_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97291af9-fb1a-44ba-bdd0-382c37bfe407",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R -i customers_df\n",
        "# Analyze the data in R\n",
        "library(dplyr)\n",
        "\n",
        "cat(\"Summary Statistics for Customer Account Balance:\\n\")\n",
        "rprint(summary(customers_df$C_ACCTBAL))\n",
        "\n",
        "cat(\"\\nCustomers by Nation (top 5):\\n\")\n",
        "result <- customers_df %>%\n",
        "  group_by(C_NATIONKEY) %>%\n",
        "  summarise(\n",
        "    count = n(),\n",
        "    avg_balance = mean(C_ACCTBAL),\n",
        "    total_balance = sum(C_ACCTBAL)\n",
        "  ) %>%\n",
        "  arrange(desc(count)) %>%\n",
        "  head(5)\n",
        "\n",
        "rprint(result)  # Use rprint() for clean output"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fa4dd5c0-f9b0-4c2b-8173-5e72053d84cd",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 3.8 Check Connection Status\n",
        "\n",
        "You can check the connection status from either Python or R."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c65cbb49-52c4-4233-8e5f-0b49fb52b95d",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Check status from Python\n",
        "from r_helpers import get_r_connection_status\n",
        "\n",
        "status = get_r_connection_status()\n",
        "print(\"R Connection Status (from Python):\")\n",
        "for key, value in status.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6f8276ca-a924-440f-9e58-0476efa92af5",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Get or create the Snowflake connection\n",
        "# Connection is stored globally as r_sf_con\n",
        "r_sf_con <- get_snowflake_connection()\n",
        "\n",
        "# Show connection status (uses print_connection_status() for clean output)\n",
        "print_connection_status()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93b418d9-faa8-435f-b2fd-5da6f377951c",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 3.9 Clean Up\n",
        "\n",
        "Close ADBC connection and optionally remove the PAT."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "15e5e418-d204-4d6f-b220-aab224bdaef3",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Close the Snowflake connection\n",
        "close_snowflake_connection()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b970b88d-e34b-4a8e-b86b-48c60e2ca6ec",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Alternative: Close from Python\n",
        "# from r_helpers import close_r_connection\n",
        "# success, msg = close_r_connection()\n",
        "# print(msg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64c429c3-d3ff-4a73-bd38-acb15f244eb1",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Remove PAT when done (optional)\n",
        "# pat_mgr.remove_pat()\n",
        "# print(\"PAT removed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c34f713-51a1-49b1-91ea-1a8d48c6b0fb",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 4: Alternative Authentication - Key Pair (JWT)\n",
        "\n",
        "This section demonstrates Key Pair (JWT) authentication as an alternative to PAT.\n",
        "\n",
        "## Authentication Methods for R ADBC\n",
        "\n",
        "| Method | Status | Notes |\n",
        "|--------|--------|-------|\n",
        "| **PAT (Programmatic Access Token)** | ‚úÖ Working | **Recommended** - easiest to set up (see Section 3) |\n",
        "| **Key Pair (JWT)** | ‚úÖ Working | Alternative - no token expiry, shown below |\n",
        "| SPCS OAuth Token | ‚ùå Blocked | Container token restricted to specific connectors |\n",
        "| Username/Password | ‚ùå Blocked | SPCS enforces OAuth for internal connections |\n",
        "\n",
        "> **Note:** For tests of non-working methods, see `archive/auth_methods_not_working.ipynb`\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "- ADBC installed (`--adbc` flag during setup)\n",
        "- RSA key pair generated\n",
        "- Public key registered with your Snowflake user"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c881522f-bb36-4052-a258-f9453b36b5e6",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 4.1 Load Alternative Auth Test Functions\n",
        "\n",
        "Load the R functions for testing different authentication methods."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f299b22-9a97-4fbc-9193-5a0f6ba41c7a",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from r_helpers import init_r_alt_auth\n",
        "\n",
        "success, msg = init_r_alt_auth()\n",
        "print(msg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f6b2a13e-1808-44df-bc82-f2e860e34329",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 4.2 Key Pair (JWT) Authentication ‚úÖ\n",
        "\n",
        "Key pair authentication uses RSA keys instead of passwords. **This method is confirmed working** and is a good alternative to PAT for users who prefer key-based auth.\n",
        "\n",
        "**Setup steps:**\n",
        "1. Generate an RSA key pair\n",
        "2. Register the public key with your Snowflake user\n",
        "3. Use the private key for authentication\n",
        "\n",
        "### Step 1: Generate Key Pair (Python)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9574456f-8ab5-498f-b95e-c7941ed73936",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "from r_helpers import KeyPairAuth\n",
        "\n",
        "# Initialize key pair auth helper\n",
        "kp_auth = KeyPairAuth()\n",
        "\n",
        "# Generate a new key pair (or use load_private_key() for existing key)\n",
        "# Note: Requires 'cryptography' package: pip install cryptography\n",
        "result = kp_auth.generate_key_pair(\n",
        "    key_size=2048,\n",
        "    output_dir=\"/tmp\",\n",
        "    passphrase=None  # Set a passphrase for encrypted key\n",
        ")\n",
        "\n",
        "if result['success']:\n",
        "    print(\"‚úì Key pair generated successfully\")\n",
        "    print(f\"  Private key: {result['private_key_path']}\")\n",
        "    print(f\"  Public key:  {result['public_key_path']}\")\n",
        "    print(f\"\\n  Public key for Snowflake registration:\")\n",
        "    print(f\"  {result['public_key_for_snowflake'][:50]}...\")\n",
        "else:\n",
        "    print(f\"‚úó Key generation failed: {result['error']}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "735ac1b2-caec-4807-9dda-acb7eeabe26f",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### Step 2: Register Public Key with Snowflake\n",
        "\n",
        "Run this SQL to register the public key with your user (requires ACCOUNTADMIN or appropriate privileges)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "093fc815-1bd0-4f97-899d-c60c1addd15a",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Generate SQL for registering the public key\n",
        "if result['success']:\n",
        "    sql = kp_auth.register_public_key_sql(result['public_key_for_snowflake'])\n",
        "    print(\"Run this SQL to register the public key:\")\n",
        "    print(\"-\" * 60)\n",
        "    print(sql)\n",
        "    print(\"-\" * 60)\n",
        "    print(\"\\nOr run via Snowpark session:\")\n",
        "    print(\"  session.sql(sql).collect()\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28554e82-cf03-48f1-bf54-697101761076",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "session.sql(sql).collect()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "229490a2-9617-4de1-a555-564dce292bef",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### Step 3: Configure and Test Key Pair Auth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "539bf7b1-8623-474c-ae55-8401f263f053",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Configure environment for key pair auth\n",
        "config = kp_auth.configure_for_adbc()\n",
        "print(\"Key Pair Auth Configuration:\")\n",
        "for key, value in config.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e962629-43d8-49d8-84de-ab7506019bb3",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Test key pair authentication\n",
        "# Note: Public key must be registered with user first!\n",
        "result <- test_keypair_auth()\n",
        "rprint(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d37aef7-8b00-41e1-9cba-f50380f8dcf9",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 4.3 Authentication Summary\n",
        "\n",
        "### Working Methods\n",
        "\n",
        "| Method | Auth Type | Best For |\n",
        "|--------|-----------|----------|\n",
        "| **PAT** | `auth_pat` | Most use cases - easy programmatic setup |\n",
        "| **Key Pair** | `auth_jwt` | Long-lived credentials without expiry |\n",
        "\n",
        "### Non-Working Methods (Blocked by SPCS)\n",
        "\n",
        "| Method | Reason |\n",
        "|--------|--------|\n",
        "| SPCS OAuth Token | Restricted to specific Snowflake connectors |\n",
        "| Username/Password | SPCS enforces OAuth internally |\n",
        "\n",
        "> See `archive/auth_methods_not_working.ipynb` for test code if needed."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e2f1f8f-eee0-4da1-b29a-071880cd4a71",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 5: Reticulate - Access Snowpark from R\n",
        "\n",
        "This section demonstrates using **reticulate** to access the Python Snowpark session directly from R. This is an alternative to ADBC that leverages the notebook's built-in authentication.\n",
        "\n",
        "## Advantages of Reticulate Approach\n",
        "\n",
        "| Feature | Reticulate + Snowpark | ADBC |\n",
        "|---------|----------------------|------|\n",
        "| Authentication | Uses notebook's built-in auth | Requires PAT or Key Pair |\n",
        "| Setup | No additional auth setup | PAT creation or key registration |\n",
        "| Connection | Shares Python session | Separate R connection |\n",
        "| Best for | Quick queries, prototyping | Production R pipelines |\n",
        "\n",
        "## How It Works\n",
        "\n",
        "1. R accesses Python's Snowpark session via reticulate\n",
        "2. Execute SQL queries using `session$sql()`\n",
        "3. Convert results to pandas DataFrame with `.to_pandas()`\n",
        "4. Reticulate automatically converts pandas ‚Üí R data.frame\n",
        "\n",
        "## Output Pattern\n",
        "\n",
        "For best display in Notebooks, use `%%R -o variable` to export R data frames to Python, then display them in a subsequent Python cell. This lets the Notebook render the DataFrame with proper formatting."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "59d0ea0c-5ae6-4efd-aa08-0da369432f46",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 5.1 Setup Reticulate\n",
        "\n",
        "Configure reticulate to use the notebook's Python environment.\n",
        "\n",
        "> **Note:** You may see a warning about reticulate/rpy2 compatibility. This is safe to ignore if using reticulate >= 1.25 (installed by default). The issue was fixed in reticulate PR #1188."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "233e9988-bb37-4569-9960-6b9d72f2048a",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "library(reticulate)\n",
        "\n",
        "# Use the same Python that's running the notebook kernel\n",
        "# This ensures we access the same Snowpark session\n",
        "use_python(Sys.which(\"python3\"), required = TRUE)\n",
        "\n",
        "# Verify Python is accessible\n",
        "py_config()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## 8. Iceberg Integration via Horizon Catalog (Experimental)\n",
        "\n",
        "This section covers accessing Snowflake-managed Iceberg tables from external query engines using the Horizon Catalog REST API.\n",
        "\n",
        "**Status**: üî¨ Experimental - Some features may require additional configuration.\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "- **Horizon Catalog**: Snowflake's implementation of the Apache Iceberg REST API\n",
        "- **Vended Credentials**: Temporary S3/Azure/GCS credentials provided by the catalog\n",
        "- **Authentication**: JWT/OAuth flow using the same key-pair as Snowflake\n",
        "\n",
        "### What Works Now\n",
        "- ‚úÖ JWT generation and token exchange\n",
        "- ‚úÖ Catalog metadata queries (list namespaces, tables)\n",
        "- ‚úÖ Table metadata retrieval (schema, partition specs, snapshots)\n",
        "- ‚úÖ DuckDB iceberg extension ATTACH\n",
        "\n",
        "### In Progress\n",
        "- ‚ö†Ô∏è Full DuckDB query support (requires vended credentials)\n",
        "- ‚ö†Ô∏è PyIceberg integration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.1 Create an Iceberg Table (One-Time Setup)\n",
        "\n",
        "First, let's create a Snowflake-managed Iceberg table from the TPCH Nation data for testing.\n",
        "\n",
        "**Prerequisites:**\n",
        "- An external volume configured with S3/Azure/GCS storage\n",
        "- CREATE ICEBERG TABLE privilege"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Iceberg table from TPCH Nation data\n",
        "# Note: STRING must be used instead of VARCHAR(n) for Iceberg tables\n",
        "\n",
        "iceberg_setup_sql = \"\"\"\n",
        "-- Check for existing Iceberg table\n",
        "-- DESCRIBE TABLE NATION_ICEBERG;\n",
        "\n",
        "-- Create the table (uncomment to run)\n",
        "/*\n",
        "CREATE OR REPLACE ICEBERG TABLE NATION_ICEBERG (\n",
        "    N_NATIONKEY INT,\n",
        "    N_NAME STRING,\n",
        "    N_REGIONKEY INT,\n",
        "    N_COMMENT STRING\n",
        ")\n",
        "    CATALOG = 'SNOWFLAKE'\n",
        "    EXTERNAL_VOLUME = '<YOUR_EXTERNAL_VOLUME>'  -- e.g., 'SNOWCAT_ICEBERG'\n",
        "    BASE_LOCATION = 'r_integration/nation_iceberg/'\n",
        "    AS SELECT * FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.NATION;\n",
        "*/\n",
        "\n",
        "-- Verify the table\n",
        "SELECT COUNT(*) as row_count FROM NATION_ICEBERG;\n",
        "\"\"\"\n",
        "\n",
        "# Uncomment to run the setup\n",
        "# session.sql(iceberg_setup_sql.split(';')[0]).show()\n",
        "print(\"Iceberg table setup SQL prepared. Edit EXTERNAL_VOLUME and uncomment to create.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.2 Horizon Catalog Authentication\n",
        "\n",
        "Generate a JWT and exchange it for an access token to authenticate with the Horizon Catalog REST API.\n",
        "\n",
        "**Note**: This uses the same key-pair authentication as the DuckDB Snowflake extension."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Horizon Catalog Authentication Helper\n",
        "# Generates JWT and exchanges for access token\n",
        "\n",
        "def get_horizon_access_token(account, user, role, private_key_path):\n",
        "    \"\"\"\n",
        "    Generate JWT and exchange for Horizon Catalog access token.\n",
        "    \n",
        "    Args:\n",
        "        account: Account identifier (e.g., 'MYORG-MYACCOUNT')\n",
        "        user: Snowflake username\n",
        "        role: Role to use for Horizon access (e.g., 'SYSADMIN')\n",
        "        private_key_path: Path to private key file (.p8)\n",
        "    \n",
        "    Returns:\n",
        "        Access token string\n",
        "    \"\"\"\n",
        "    import jwt\n",
        "    import time\n",
        "    import hashlib\n",
        "    import base64\n",
        "    import requests\n",
        "    import os\n",
        "    from cryptography.hazmat.primitives import serialization\n",
        "    from cryptography.hazmat.backends import default_backend\n",
        "    \n",
        "    # Read private key\n",
        "    key_path = os.path.expanduser(private_key_path)\n",
        "    with open(key_path, 'rb') as key_file:\n",
        "        private_key = serialization.load_pem_private_key(\n",
        "            key_file.read(),\n",
        "            password=None,\n",
        "            backend=default_backend()\n",
        "        )\n",
        "    \n",
        "    # Generate fingerprint\n",
        "    public_key = private_key.public_key()\n",
        "    public_key_bytes = public_key.public_bytes(\n",
        "        encoding=serialization.Encoding.DER,\n",
        "        format=serialization.PublicFormat.SubjectPublicKeyInfo\n",
        "    )\n",
        "    sha256_hash = hashlib.sha256(public_key_bytes).digest()\n",
        "    fingerprint = \"SHA256:\" + base64.standard_b64encode(sha256_hash).decode('utf-8')\n",
        "    \n",
        "    # Create JWT\n",
        "    now = int(time.time())\n",
        "    payload = {\n",
        "        \"iss\": f\"{account}.{user}.{fingerprint}\",\n",
        "        \"sub\": f\"{account}.{user}\",\n",
        "        \"iat\": now,\n",
        "        \"exp\": now + 3600,  # 1 hour expiry\n",
        "    }\n",
        "    \n",
        "    private_key_pem = private_key.private_bytes(\n",
        "        encoding=serialization.Encoding.PEM,\n",
        "        format=serialization.PrivateFormat.PKCS8,\n",
        "        encryption_algorithm=serialization.NoEncryption()\n",
        "    )\n",
        "    \n",
        "    jwt_token = jwt.encode(payload, private_key_pem, algorithm='RS256')\n",
        "    \n",
        "    # Exchange for access token\n",
        "    token_url = f\"https://{account}.snowflakecomputing.com/polaris/api/catalog/v1/oauth/tokens\"\n",
        "    response = requests.post(\n",
        "        token_url,\n",
        "        headers={'Content-Type': 'application/x-www-form-urlencoded'},\n",
        "        data={\n",
        "            'grant_type': 'client_credentials',\n",
        "            'scope': f'session:role:{role}',\n",
        "            'client_secret': jwt_token\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        token_data = response.json()\n",
        "        return token_data.get('access_token', '')\n",
        "    else:\n",
        "        raise Exception(f\"Token exchange failed: {response.text}\")\n",
        "\n",
        "# Note: Install required packages if not available\n",
        "# !pip install pyjwt cryptography requests\n",
        "\n",
        "print(\"Horizon authentication helper defined.\")\n",
        "print(\"Usage: token = get_horizon_access_token(account, user, role, key_path)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.3 Query Horizon Catalog Metadata\n",
        "\n",
        "Use the REST API to list namespaces and tables in the Iceberg catalog."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query Horizon Catalog REST API\n",
        "import requests\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Configuration - update these for your environment\n",
        "HORIZON_CONFIG = {\n",
        "    'account': os.environ.get('SNOWFLAKE_ACCOUNT', '<YOUR_ORG>-<YOUR_ACCOUNT>'),\n",
        "    'user': os.environ.get('SNOWFLAKE_USER', '<YOUR_USER>'),\n",
        "    'role': 'SYSADMIN',\n",
        "    'database': '<YOUR_DATABASE>',  # Database with Iceberg tables\n",
        "    'private_key_path': os.environ.get(\n",
        "        'SNOWFLAKE_PRIVATE_KEY_PATH',\n",
        "        '~/.snowflake/keys/rsa_key.p8'\n",
        "    )\n",
        "}\n",
        "\n",
        "def query_horizon_catalog(endpoint, access_token):\n",
        "    \"\"\"Query the Horizon Catalog REST API.\"\"\"\n",
        "    account = HORIZON_CONFIG['account']\n",
        "    base_url = f\"https://{account}.snowflakecomputing.com/polaris/api/catalog/v1\"\n",
        "    \n",
        "    response = requests.get(\n",
        "        f\"{base_url}/{endpoint}\",\n",
        "        headers={\n",
        "            'Authorization': f'Bearer {access_token}',\n",
        "            'Content-Type': 'application/json'\n",
        "        }\n",
        "    )\n",
        "    \n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        return {'error': response.status_code, 'message': response.text}\n",
        "\n",
        "# Example usage (uncomment when configured):\n",
        "\"\"\"\n",
        "# Get access token\n",
        "access_token = get_horizon_access_token(\n",
        "    HORIZON_CONFIG['account'],\n",
        "    HORIZON_CONFIG['user'],\n",
        "    HORIZON_CONFIG['role'],\n",
        "    HORIZON_CONFIG['private_key_path']\n",
        ")\n",
        "\n",
        "# List namespaces (schemas)\n",
        "database = HORIZON_CONFIG['database']\n",
        "namespaces = query_horizon_catalog(f\"{database}/namespaces\", access_token)\n",
        "print(\"Namespaces:\", json.dumps(namespaces, indent=2))\n",
        "\n",
        "# List tables in PUBLIC schema\n",
        "tables = query_horizon_catalog(f\"{database}/namespaces/PUBLIC/tables\", access_token)\n",
        "print(\"Tables:\", json.dumps(tables, indent=2))\n",
        "\n",
        "# Get table metadata\n",
        "table_meta = query_horizon_catalog(\n",
        "    f\"{database}/namespaces/PUBLIC/tables/NATION_ICEBERG\",\n",
        "    access_token\n",
        ")\n",
        "print(\"Table metadata:\", json.dumps(table_meta, indent=2)[:500])\n",
        "\"\"\"\n",
        "\n",
        "print(\"Horizon Catalog query functions defined.\")\n",
        "print(\"Configure HORIZON_CONFIG and uncomment example code to test.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.4 DuckDB Iceberg Extension (Experimental)\n",
        "\n",
        "DuckDB's iceberg extension can connect to REST catalogs including Snowflake Horizon.\n",
        "\n",
        "**Current Status**: Catalog attachment works, but data queries may fail due to vended credentials limitations. See design document for workarounds."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%R\n",
        "# DuckDB Iceberg Integration (Experimental)\n",
        "# \n",
        "# NOTE: This demonstrates attaching to Horizon Catalog.\n",
        "# Full query support may require vended credentials configuration.\n",
        "\n",
        "library(DBI)\n",
        "library(duckdb)\n",
        "\n",
        "# Connect to DuckDB\n",
        "iceberg_con <- dbConnect(duckdb::duckdb(), dbdir = \":memory:\")\n",
        "\n",
        "# Install and load iceberg extension\n",
        "dbExecute(iceberg_con, \"INSTALL iceberg\")\n",
        "dbExecute(iceberg_con, \"LOAD iceberg\")\n",
        "\n",
        "cat(\"Iceberg extension loaded\\n\")\n",
        "\n",
        "# Configuration - update for your environment\n",
        "# Uncomment and configure when you have an access token\n",
        "\"\"\"\n",
        "ACCOUNT <- 'MYORG-MYACCOUNT'\n",
        "DATABASE <- 'MY_DATABASE'\n",
        "ACCESS_TOKEN <- '<your_access_token_from_section_8.2>'\n",
        "\n",
        "# Attach to Horizon Catalog\n",
        "attach_sql <- sprintf(\n",
        "    \\\"ATTACH '%s' AS horizon (\n",
        "        TYPE ICEBERG,\n",
        "        ENDPOINT 'https://%s.snowflakecomputing.com/polaris/api/catalog',\n",
        "        TOKEN '%s'\n",
        "    )\\\",\n",
        "    DATABASE,\n",
        "    ACCOUNT,\n",
        "    ACCESS_TOKEN\n",
        ")\n",
        "\n",
        "dbExecute(iceberg_con, attach_sql)\n",
        "cat('Horizon Catalog attached\\\\n')\n",
        "\n",
        "# List tables (this works!)\n",
        "tables <- dbGetQuery(iceberg_con, \n",
        "    \\\"SELECT * FROM duckdb_tables() WHERE database_name = 'horizon'\\\")\n",
        "print(tables)\n",
        "\n",
        "# Query table (may fail with current vended credentials limitations)\n",
        "# tryCatch({\n",
        "#     result <- dbGetQuery(iceberg_con, 'SELECT * FROM horizon.PUBLIC.NATION_ICEBERG')\n",
        "#     print(result)\n",
        "# }, error = function(e) {\n",
        "#     cat('Query failed - see design doc for workarounds:\\\\n')\n",
        "#     cat(conditionMessage(e), '\\\\n')\n",
        "# })\n",
        "\"\"\"\n",
        "\n",
        "cat(\"\\nDuckDB Iceberg demo configured.\\n\")\n",
        "cat(\"Configure variables and uncomment code to test.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8.5 Recommended Alternative: Snowflake + DuckDB Hybrid\n",
        "\n",
        "Until full Iceberg REST catalog support is available, use the working DuckDB Snowflake extension approach from Section 7:\n",
        "\n",
        "1. **Query Snowflake via ADBC** (using DuckDB Snowflake extension)\n",
        "2. **Cache results locally** in DuckDB\n",
        "3. **Use dplyr/dbplyr** on the local cache\n",
        "\n",
        "This provides the same benefits (local processing, R ecosystem) with full support today."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%%R\n",
        "# Hybrid Approach: Best of Both Worlds\n",
        "# Use the working DuckDB + Snowflake pattern for Iceberg-like benefits\n",
        "\n",
        "# Assuming DuckDB connection from Section 7 is active (duckdb_con)\n",
        "# If not, re-run Section 7.3\n",
        "\n",
        "# Example: Query Snowflake Iceberg table, cache locally\n",
        "# (Even though it's an Iceberg table in Snowflake, query via SQL works!)\n",
        "\n",
        "\"\"\"\n",
        "# Query the Iceberg table via standard Snowflake SQL\n",
        "dbExecute(duckdb_con, \\\"\n",
        "    CREATE OR REPLACE TABLE nation_iceberg_local AS \n",
        "    SELECT * FROM sf.PUBLIC.NATION_ICEBERG\n",
        "\\\")\n",
        "\n",
        "# Now use dplyr on the local cache\n",
        "library(dplyr)\n",
        "library(dbplyr)\n",
        "\n",
        "tbl(duckdb_con, 'nation_iceberg_local') %>%\n",
        "    group_by(N_REGIONKEY) %>%\n",
        "    summarise(\n",
        "        nations = n(),\n",
        "        sample_name = first(N_NAME)\n",
        "    ) %>%\n",
        "    collect() %>%\n",
        "    print()\n",
        "\"\"\"\n",
        "\n",
        "cat(\"Hybrid pattern example ready.\\n\")\n",
        "cat(\"Uncomment code after running Section 7 DuckDB setup.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a744bd12-1ed8-4e64-9129-a25142bd0e1e",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 5.2 Access Snowpark Session from R\n",
        "\n",
        "Import the Snowpark module and get the active session. This uses the notebook's built-in authentication - no PAT required!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bf4f44dd-af95-4cb4-8d75-70dc663cc358",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Import Snowpark module\n",
        "snowpark <- import(\"snowflake.snowpark\")\n",
        "\n",
        "# Get the active session (uses notebook's built-in auth)\n",
        "session <- snowpark$Session$builder$getOrCreate()\n",
        "\n",
        "# Verify connection\n",
        "rcat(\"Connected to Snowflake via Snowpark!\")\n",
        "rcat(\"Account: \", session$get_current_account())\n",
        "rcat(\"User: \", session$get_current_user())\n",
        "rcat(\"Database: \", session$get_current_database())\n",
        "rcat(\"Schema: \", session$get_current_schema())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50bdd984-6ac7-4db3-a7fa-25807dfa7a9a",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 5.3 Query Snowflake and Get R DataFrame\n",
        "\n",
        "Execute SQL queries and convert results to R data frames.\n",
        "\n",
        "**Output Pattern:** Use `%%R -o variable` to export results to Python, then display in the next cell for nice Notebook formatting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e8ebfdab-d6b3-4056-b3fc-94dfe140a945",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R -o nations_df\n",
        "# Execute a query and get Snowpark DataFrame\n",
        "# Use -o to export result to Python for nice display\n",
        "nations_df <- session$sql(\"\n",
        "    SELECT N_NATIONKEY, N_NAME, N_REGIONKEY \n",
        "    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.NATION \n",
        "    LIMIT 10\n",
        "\")$to_pandas()\n",
        "\n",
        "# Print data type (R sees this as a data.frame)\n",
        "cat(\"R data type:\", class(nations_df), \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd668a1b-6f73-4e27-ac85-f7f174233ce4",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Display the exported DataFrame (nice Notebook rendering)\n",
        "nations_df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e746a041-5ed3-4e76-928f-c4a0f5a4f98b",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 5.4 R Analysis on Snowflake Data\n",
        "\n",
        "Perform R analysis using dplyr on data retrieved via Snowpark. Use `-o` to export the result for display."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e853f863-b88b-44b1-8a3f-5179ab84c357",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R -o customer_analysis\n",
        "# Query customer data with aggregation\n",
        "customers_df <- session$sql(\"\n",
        "    SELECT \n",
        "        C_MKTSEGMENT,\n",
        "        COUNT(*) as CUSTOMER_COUNT,\n",
        "        AVG(C_ACCTBAL) as AVG_BALANCE,\n",
        "        MIN(C_ACCTBAL) as MIN_BALANCE,\n",
        "        MAX(C_ACCTBAL) as MAX_BALANCE\n",
        "    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.CUSTOMER\n",
        "    GROUP BY C_MKTSEGMENT\n",
        "    ORDER BY AVG_BALANCE DESC\n",
        "\")$to_pandas()\n",
        "\n",
        "# Use dplyr for additional analysis\n",
        "library(dplyr)\n",
        "\n",
        "customer_analysis <- customers_df %>%\n",
        "    mutate(\n",
        "        BALANCE_RANGE = MAX_BALANCE - MIN_BALANCE,\n",
        "        SEGMENT_SIZE = case_when(\n",
        "            CUSTOMER_COUNT > 30000 ~ \"Large\",\n",
        "            CUSTOMER_COUNT > 29000 ~ \"Medium\",\n",
        "            TRUE ~ \"Small\"\n",
        "        )\n",
        "    )\n",
        "\n",
        "cat(\"Analysis complete - result exported to Python\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3e5910f-a6ad-4329-a355-80ec1eef5f0d",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Display the R analysis result (exported via -o)\n",
        "customer_analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4d900768-6b13-4381-9477-23d9cdc568b4",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 5.5 Helper Function for Snowpark Queries\n",
        "\n",
        "Create a convenience function to simplify querying. Use `-o` to export results for display."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86189b02-9ffd-4fa3-9b58-a52b12e67f08",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R -o orders_summary\n",
        "#' Query Snowflake via Snowpark and return R data.frame\n",
        "#' \n",
        "#' @param sql SQL query string\n",
        "#' @return R data.frame with query results\n",
        "snowpark_query <- function(sql) {\n",
        "    session$sql(sql)$to_pandas()\n",
        "}\n",
        "\n",
        "# Example usage - export result with -o\n",
        "orders_summary <- snowpark_query(\"\n",
        "    SELECT \n",
        "        O_ORDERSTATUS,\n",
        "        COUNT(*) as ORDER_COUNT,\n",
        "        SUM(O_TOTALPRICE) as TOTAL_VALUE\n",
        "    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS\n",
        "    GROUP BY O_ORDERSTATUS\n",
        "\")\n",
        "\n",
        "cat(\"Query complete - orders_summary exported to Python\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3bc16d2-a25f-4493-bc59-867c0a381dc8",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Display the orders summary (exported via -o)\n",
        "orders_summary"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bf7b467-24bc-4eb3-b80d-e6fb1340fdaf",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 5.6 Reticulate vs ADBC Comparison\n",
        "\n",
        "| Aspect | Reticulate + Snowpark | ADBC (Section 3 & 4) |\n",
        "|--------|----------------------|----------------------|\n",
        "| **Authentication** | Automatic (notebook's session) | PAT or Key Pair required |\n",
        "| **Setup complexity** | Minimal | Moderate |\n",
        "| **Data path** | Snowflake ‚Üí Snowpark ‚Üí pandas ‚Üí R | Snowflake ‚Üí Arrow ‚Üí R |\n",
        "| **Performance** | Good for moderate data | Better for large data (Arrow) |\n",
        "| **R-native** | No (via Python) | Yes (native R driver) |\n",
        "| **Best for** | Quick analysis, prototyping | Production R workflows |\n",
        "\n",
        "### When to Use Each\n",
        "\n",
        "**Use Reticulate + Snowpark when:**\n",
        "- You need quick access without auth setup\n",
        "- Working interactively/prototyping\n",
        "- Data sizes are moderate (< 1M rows)\n",
        "- You're already using Python and R together\n",
        "\n",
        "**Use ADBC when:**\n",
        "- Building production R pipelines\n",
        "- Working with large datasets\n",
        "- Need pure R solution\n",
        "- Require connection pooling/management"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b1abb74-0c73-4aef-8c4e-a7cde51101de",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 6: Data Visualization with ggplot2\n",
        "\n",
        "This section demonstrates creating visualizations with **ggplot2** and displaying them in the Notebook.\n",
        "\n",
        "## Key Points\n",
        "\n",
        "- ggplot2 is included via `tidyverse` (installed by default)\n",
        "- Use `%%R -w WIDTH -h HEIGHT` to control plot dimensions (in pixels)\n",
        "- Call `print(p)` explicitly to render the plot\n",
        "- Plots render inline in the Notebook output\n",
        "\n",
        "## Plot Size Parameters\n",
        "\n",
        "| Parameter | Description | Example |\n",
        "|-----------|-------------|---------|\n",
        "| `-w` | Width in pixels | `-w 800` |\n",
        "| `-h` | Height in pixels | `-h 500` |\n",
        "| `--type` | Graphics device | `--type=cairo` (optional, better quality) |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5c8ba29-8ffe-4915-945e-d177b138eb8b",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 6.1 Basic ggplot2 Example\n",
        "\n",
        "Create a simple scatter plot using the built-in `mtcars` dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e918ee36-3fc9-48c6-a9e2-36fff893f47d",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R -w 700 -h 450\n",
        "library(ggplot2)\n",
        "\n",
        "# Basic scatter plot with mtcars\n",
        "p <- ggplot(mtcars, aes(x = wt, y = mpg, color = factor(cyl))) +\n",
        "    geom_point(size = 3) +\n",
        "    labs(\n",
        "        title = \"Fuel Efficiency vs Weight\",\n",
        "        x = \"Weight (1000 lbs)\",\n",
        "        y = \"Miles per Gallon\",\n",
        "        color = \"Cylinders\"\n",
        "    ) +\n",
        "    theme_minimal()\n",
        "\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c0eb03e-cc12-4f6e-b06a-d45afe8c75b3",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 6.2 Visualize Snowflake Data\n",
        "\n",
        "Query Snowflake data and create a bar chart. Bar charts work best when values have meaningful differences from zero.\n",
        "\n",
        "> **Tip:** Avoid bar charts when values are clustered in a narrow range (e.g., all ~$4,500). Use dot plots or adjust the visualization instead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aeec4aa1-3107-4b55-9f8e-f308ceb85a25",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R -w 800 -h 500\n",
        "library(ggplot2)\n",
        "library(dplyr)\n",
        "\n",
        "# Query Snowflake for order data by status\n",
        "# This data has more variance for a meaningful bar chart\n",
        "orders <- session$sql(\"\n",
        "    SELECT \n",
        "        O_ORDERSTATUS,\n",
        "        COUNT(*) as ORDER_COUNT,\n",
        "        ROUND(SUM(O_TOTALPRICE) / 1e9, 2) as TOTAL_VALUE_BILLIONS\n",
        "    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS\n",
        "    GROUP BY O_ORDERSTATUS\n",
        "    ORDER BY TOTAL_VALUE_BILLIONS DESC\n",
        "\")$to_pandas()\n",
        "\n",
        "# Create bar chart - good when values have meaningful differences\n",
        "p <- ggplot(orders, aes(x = reorder(O_ORDERSTATUS, -TOTAL_VALUE_BILLIONS), \n",
        "                         y = TOTAL_VALUE_BILLIONS)) +\n",
        "    geom_col(aes(fill = ORDER_COUNT), width = 0.6) +\n",
        "    geom_text(aes(label = paste0(\"$\", TOTAL_VALUE_BILLIONS, \"B\")), \n",
        "              vjust = -0.5, size = 4) +\n",
        "    scale_fill_viridis_c(option = \"plasma\", labels = scales::comma) +\n",
        "    scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +\n",
        "    labs(\n",
        "        title = \"Total Order Value by Status\",\n",
        "        subtitle = \"Data from Snowflake TPC-H Sample\",\n",
        "        x = \"Order Status\",\n",
        "        y = \"Total Value ($ Billions)\",\n",
        "        fill = \"Order\\nCount\"\n",
        "    ) +\n",
        "    theme_minimal(base_size = 12) +\n",
        "    theme(\n",
        "        plot.title = element_text(face = \"bold\")\n",
        "    )\n",
        "\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "48028ac8-fbab-4b4c-9dee-78a8e9a3563a",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 6.3 Multi-Panel Visualization (Facets)\n",
        "\n",
        "Create faceted plots to compare distributions across categories."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "837d3a97-0de7-41a4-8625-0aab612915b4",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R -w 900 -h 600\n",
        "library(ggplot2)\n",
        "library(dplyr)\n",
        "\n",
        "# Query order data by status and priority\n",
        "orders <- session$sql(\"\n",
        "    SELECT \n",
        "        O_ORDERSTATUS,\n",
        "        O_ORDERPRIORITY,\n",
        "        O_TOTALPRICE\n",
        "    FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS\n",
        "    LIMIT 5000\n",
        "\")$to_pandas()\n",
        "\n",
        "# Create faceted histogram\n",
        "p <- ggplot(orders, aes(x = O_TOTALPRICE, fill = O_ORDERSTATUS)) +\n",
        "    geom_histogram(bins = 30, alpha = 0.7) +\n",
        "    facet_wrap(~O_ORDERPRIORITY, scales = \"free_y\", ncol = 3) +\n",
        "    scale_x_continuous(labels = scales::dollar_format(scale = 0.001, suffix = \"K\")) +\n",
        "    scale_fill_brewer(palette = \"Set2\") +\n",
        "    labs(\n",
        "        title = \"Order Value Distribution by Priority\",\n",
        "        subtitle = \"Colored by Order Status\",\n",
        "        x = \"Total Price\",\n",
        "        y = \"Count\",\n",
        "        fill = \"Status\"\n",
        "    ) +\n",
        "    theme_light(base_size = 11) +\n",
        "    theme(\n",
        "        plot.title = element_text(face = \"bold\"),\n",
        "        strip.text = element_text(face = \"bold\")\n",
        "    )\n",
        "\n",
        "print(p)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2846d831-5d58-41c5-961b-d85116fc0a71",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 6.4 Saving and Loading Plots\n",
        "\n",
        "Use `ggsave()` to export plots to files, then display them from Python using `IPython.display.Image`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a6eaf65-3ead-4788-9bdd-5fe21df38c76",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R -w 700 -h 450\n",
        "library(ggplot2)\n",
        "\n",
        "# Create a plot\n",
        "p <- ggplot(mtcars, aes(x = hp, y = mpg)) +\n",
        "    geom_point(aes(color = factor(gear)), size = 3) +\n",
        "    geom_smooth(method = \"lm\", se = TRUE, color = \"darkgray\") +\n",
        "    labs(\n",
        "        title = \"MPG vs Horsepower\",\n",
        "        x = \"Horsepower\",\n",
        "        y = \"Miles per Gallon\",\n",
        "        color = \"Gears\"\n",
        "    ) +\n",
        "    theme_bw()\n",
        "\n",
        "# Display the plot inline\n",
        "print(p)\n",
        "\n",
        "# Save to file\n",
        "ggsave(\"/tmp/mpg_vs_hp.png\", p, width = 8, height = 5, dpi = 150)\n",
        "cat(\"Plot saved to /tmp/mpg_vs_hp.png\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58651527-4632-4301-b079-fb47e5d6af79",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Display the saved PNG file in the notebook\n",
        "from IPython.display import Image, display\n",
        "\n",
        "display(Image(filename=\"/tmp/mpg_vs_hp.png\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "duckdb-section-header",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "# Section 7: DuckDB Integration (Experimental)\n",
        "\n",
        "This section demonstrates using **DuckDB** as an intermediary between R and Snowflake, enabling:\n",
        "- **dbplyr workflows** with Snowflake data via DuckDB's Snowflake extension\n",
        "- **Local caching** of Snowflake query results for iterative analysis\n",
        "- **Cross-environment compatibility** - works in both Workspace Notebooks and local IDEs (VSCode/Cursor)\n",
        "\n",
        "## Architecture\n",
        "\n",
        "```\n",
        "R (dplyr/dbplyr)\n",
        "    ‚Üï DBI\n",
        "DuckDB (in-process analytics)\n",
        "    ‚Üï Snowflake extension (ADBC)\n",
        "Snowflake (key-pair auth)\n",
        "```\n",
        "\n",
        "## Prerequisites\n",
        "\n",
        "1. Run setup with `--full` flag: `bash setup_r_environment.sh --full`\n",
        "2. For local IDE: Configure key-pair authentication\n",
        "3. DuckDB Snowflake extension will be installed automatically"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "duckdb-env-detection",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 7.1 Environment Detection & Session Setup\n",
        "\n",
        "This cell detects whether you're running in:\n",
        "- **Workspace Notebook**: Uses `get_active_session()` for auth context\n",
        "- **Local IDE (VSCode/Cursor)**: Creates session with key-pair auth\n",
        "\n",
        "The detection is automatic - the same notebook works in both environments!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-env-setup",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Environment Detection and Snowflake Connection Setup\n",
        "import os\n",
        "import sys\n",
        "\n",
        "def detect_environment():\n",
        "    \"\"\"\n",
        "    Detect if running in Snowflake Workspace Notebook or local IDE.\n",
        "    \n",
        "    Returns:\n",
        "        tuple: (environment_type, session_or_config)\n",
        "        - ('workspace', session) if in Workspace Notebook\n",
        "        - ('local', config_dict) if in local IDE\n",
        "    \"\"\"\n",
        "    # Check for Snowflake Workspace indicators\n",
        "    workspace_indicators = [\n",
        "        os.path.exists('/snowflake/session/token'),  # SPCS token file\n",
        "        'SNOWFLAKE_HOST' in os.environ,              # Workspace env vars\n",
        "        '/home/udf' in os.getcwd(),                  # Workspace working dir\n",
        "    ]\n",
        "    \n",
        "    if any(workspace_indicators):\n",
        "        try:\n",
        "            from snowflake.snowpark.context import get_active_session\n",
        "            session = get_active_session()\n",
        "            return ('workspace', session)\n",
        "        except Exception as e:\n",
        "            print(f\"Warning: In Workspace but session failed: {e}\")\n",
        "    \n",
        "    # Local IDE - return config for manual connection\n",
        "    config = {\n",
        "        'account': os.environ.get('SNOWFLAKE_ACCOUNT', '<YOUR_ACCOUNT>'),\n",
        "        'user': os.environ.get('SNOWFLAKE_USER', '<YOUR_USER>'),\n",
        "        'database': os.environ.get('SNOWFLAKE_DATABASE', '<YOUR_DATABASE>'),\n",
        "        'warehouse': os.environ.get('SNOWFLAKE_WAREHOUSE', '<YOUR_WAREHOUSE>'),\n",
        "        'private_key_path': os.environ.get(\n",
        "            'SNOWFLAKE_PRIVATE_KEY_PATH', \n",
        "            os.path.expanduser('~/.snowflake/keys/rsa_key.p8')\n",
        "        ),\n",
        "    }\n",
        "    return ('local', config)\n",
        "\n",
        "# Detect and display environment\n",
        "ENV_TYPE, ENV_CONFIG = detect_environment()\n",
        "\n",
        "print(f\"Environment: {ENV_TYPE.upper()}\")\n",
        "if ENV_TYPE == 'workspace':\n",
        "    session = ENV_CONFIG\n",
        "    print(f\"  Account:   {session.sql('SELECT CURRENT_ACCOUNT()').collect()[0][0]}\")\n",
        "    print(f\"  User:      {session.sql('SELECT CURRENT_USER()').collect()[0][0]}\")\n",
        "    print(f\"  Database:  {session.get_current_database()}\")\n",
        "else:\n",
        "    print(f\"  Account:   {ENV_CONFIG['account']}\")\n",
        "    print(f\"  User:      {ENV_CONFIG['user']}\")\n",
        "    print(f\"  Key Path:  {ENV_CONFIG['private_key_path']}\")\n",
        "    print(\"\\n  Note: Set environment variables or edit config below for your setup.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "duckdb-local-config",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 7.2 Configure Connection (Local IDE Only)\n",
        "\n",
        "**Skip this cell if running in Workspace Notebook.**\n",
        "\n",
        "For local IDE (VSCode/Cursor), configure your Snowflake credentials below.\n",
        "You can either:\n",
        "1. Set environment variables before starting the notebook\n",
        "2. Edit the values directly in this cell\n",
        "\n",
        "**Key-pair authentication** is recommended for local development."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-local-config-cell",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Local IDE Configuration (skip if in Workspace Notebook)\n",
        "if ENV_TYPE == 'local':\n",
        "    # Edit these values for your environment\n",
        "    LOCAL_CONFIG = {\n",
        "        'account': 'YOUR_ACCOUNT',           # e.g., 'xy12345' or 'xy12345.us-east-1'\n",
        "        'user': 'YOUR_USER',                 # Your Snowflake username\n",
        "        'database': 'YOUR_DATABASE',         # Target database\n",
        "        'warehouse': 'YOUR_WAREHOUSE',       # Compute warehouse\n",
        "        'private_key_path': '~/.snowflake/keys/rsa_key.p8',  # Path to private key\n",
        "    }\n",
        "    \n",
        "    # Expand ~ in path\n",
        "    LOCAL_CONFIG['private_key_path'] = os.path.expanduser(LOCAL_CONFIG['private_key_path'])\n",
        "    \n",
        "    # Verify key exists\n",
        "    if os.path.exists(LOCAL_CONFIG['private_key_path']):\n",
        "        print(f\"‚úì Private key found: {LOCAL_CONFIG['private_key_path']}\")\n",
        "    else:\n",
        "        print(f\"‚úó Private key not found: {LOCAL_CONFIG['private_key_path']}\")\n",
        "        print(\"  Generate with: openssl genrsa 2048 | openssl pkcs8 -topk8 -nocrypt -out ~/.snowflake/keys/rsa_key.p8\")\n",
        "else:\n",
        "    print(\"Running in Workspace Notebook - using session authentication\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "duckdb-r-setup",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 7.3 DuckDB + Snowflake Setup in R\n",
        "\n",
        "This cell configures DuckDB with the Snowflake extension and creates a connection.\n",
        "\n",
        "**Authentication**: Uses `AUTH_TYPE 'key_pair'` with the private key for secure, MFA-compatible authentication."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-r-setup-cell",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "library(DBI)\n",
        "library(duckdb)\n",
        "library(dplyr)\n",
        "library(dbplyr)\n",
        "\n",
        "cat(\"Loading DuckDB with Snowflake extension...\\n\")\n",
        "\n",
        "# Connect to DuckDB (in-memory for speed, or file for persistence)\n",
        "duckdb_con <- dbConnect(duckdb::duckdb(), dbdir = \":memory:\")\n",
        "\n",
        "# Load the Snowflake extension\n",
        "tryCatch({\n",
        "    dbExecute(duckdb_con, \"INSTALL snowflake FROM community\")\n",
        "    dbExecute(duckdb_con, \"LOAD snowflake\")\n",
        "    cat(\"‚úì Snowflake extension loaded\\n\")\n",
        "}, error = function(e) {\n",
        "    cat(\"‚úó Error loading extension:\", conditionMessage(e), \"\\n\")\n",
        "})\n",
        "\n",
        "cat(\"DuckDB ready. Configure Snowflake secret in next cell.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-snowflake-secret",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Create Snowflake secret based on environment\n",
        "if ENV_TYPE == 'workspace':\n",
        "    # Workspace: Use PAT if available, otherwise guide user\n",
        "    pat = os.environ.get('SNOWFLAKE_PAT', '')\n",
        "    if pat:\n",
        "        account = session.sql('SELECT CURRENT_ACCOUNT()').collect()[0][0]\n",
        "        user = session.sql('SELECT CURRENT_USER()').collect()[0][0]\n",
        "        database = session.get_current_database() or 'SNOWFLAKE_SAMPLE_DATA'\n",
        "        warehouse = session.get_current_warehouse() or 'COMPUTE_WH'\n",
        "        \n",
        "        # Note: PAT auth not directly supported by DuckDB extension\n",
        "        # Use key-pair auth or the Python bridge approach instead\n",
        "        print(\"Workspace: For DuckDB, use key-pair auth (see Section 7.2 alternative)\")\n",
        "        print(\"Or use Reticulate (Section 5) which uses built-in auth\")\n",
        "    else:\n",
        "        print(\"No PAT found. Run Section 3.2 to create one, or use Reticulate (Section 5)\")\n",
        "else:\n",
        "    # Local IDE: Use key-pair auth\n",
        "    config = LOCAL_CONFIG if 'LOCAL_CONFIG' in dir() else ENV_CONFIG\n",
        "    \n",
        "    # Read private key\n",
        "    key_path = config['private_key_path']\n",
        "    if os.path.exists(key_path):\n",
        "        with open(key_path, 'r') as f:\n",
        "            private_key = f.read()\n",
        "        \n",
        "        # Store config for R\n",
        "        %store config\n",
        "        %store private_key\n",
        "        print(f\"‚úì Key loaded from: {key_path}\")\n",
        "        print(\"Run the next R cell to create the Snowflake secret\")\n",
        "    else:\n",
        "        print(f\"‚úó Key not found: {key_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-create-secret-r",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R -i config -i private_key\n",
        "# Create Snowflake secret with key-pair authentication\n",
        "# This cell uses variables passed from Python\n",
        "\n",
        "cat(\"Creating Snowflake secret with key-pair auth...\\n\")\n",
        "cat(\"  Account:\", config$account, \"\\n\")\n",
        "cat(\"  User:\", config$user, \"\\n\")\n",
        "cat(\"  Database:\", config$database, \"\\n\")\n",
        "\n",
        "# Build and execute the CREATE SECRET statement\n",
        "# Important: AUTH_TYPE 'key_pair' is REQUIRED for key-pair auth!\n",
        "# Important: DATABASE should be set for proper table references\n",
        "secret_sql <- sprintf(\"\n",
        "CREATE OR REPLACE SECRET snowflake_keypair (\n",
        "    TYPE snowflake,\n",
        "    ACCOUNT '%s',\n",
        "    USER '%s',\n",
        "    DATABASE '%s',\n",
        "    WAREHOUSE '%s',\n",
        "    AUTH_TYPE 'key_pair',\n",
        "    PRIVATE_KEY '%s'\n",
        ")\",\n",
        "    config$account,\n",
        "    config$user,\n",
        "    config$database,\n",
        "    config$warehouse,\n",
        "    gsub(\"'\", \"''\", private_key)  # Escape single quotes\n",
        ")\n",
        "\n",
        "tryCatch({\n",
        "    dbExecute(duckdb_con, secret_sql)\n",
        "    cat(\"‚úì Secret created successfully\\n\")\n",
        "    cat(\"\\nNote: Use sf.schema.table format for queries (e.g., sf.tpch_sf1.customer)\\n\")\n",
        "}, error = function(e) {\n",
        "    cat(\"‚úó Error:\", conditionMessage(e), \"\\n\")\n",
        "    cat(\"\\nCommon issues:\\n\")\n",
        "    cat(\"  - Missing AUTH_TYPE 'key_pair' parameter\\n\")\n",
        "    cat(\"  - Private key not in PKCS8 format\\n\")\n",
        "    cat(\"  - Account format (use 'xy12345' not full URL)\\n\")\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-attach-snowflake",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Attach Snowflake as a catalog in DuckDB\n",
        "cat(\"Attaching Snowflake database...\\n\")\n",
        "\n",
        "tryCatch({\n",
        "    dbExecute(duckdb_con, \"ATTACH '' AS sf (TYPE snowflake, SECRET snowflake_keypair, READ_ONLY)\")\n",
        "    cat(\"‚úì Snowflake attached as 'sf' catalog\\n\\n\")\n",
        "    \n",
        "    # List schemas\n",
        "    cat(\"Available schemas:\\n\")\n",
        "    schemas <- dbGetQuery(duckdb_con, \n",
        "        \"SELECT schema_name FROM sf.information_schema.schemata ORDER BY schema_name LIMIT 10\")\n",
        "    rprint(schemas)\n",
        "    \n",
        "}, error = function(e) {\n",
        "    cat(\"‚úó Error:\", conditionMessage(e), \"\\n\")\n",
        "    cat(\"\\nTroubleshooting:\\n\")\n",
        "    cat(\"  - Verify account name format (e.g., 'xy12345' not 'xy12345.snowflakecomputing.com')\\n\")\n",
        "    cat(\"  - Check private key is valid PKCS8 format\\n\")\n",
        "    cat(\"  - Ensure public key is registered in Snowflake (ALTER USER ... SET RSA_PUBLIC_KEY=...)\\n\")\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "duckdb-workspace-alternative",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "### Alternative: Python Bridge (Workspace Notebooks)\n",
        "\n",
        "If key-pair auth isn't configured, use this Python bridge approach.\n",
        "It queries Snowflake via Python and transfers data to R for dplyr analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-python-bridge",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Python Bridge: Query Snowflake from Python, analyze in R with dplyr\n",
        "# This works in Workspace Notebooks without additional auth setup\n",
        "\n",
        "if ENV_TYPE == 'workspace':\n",
        "    import rpy2.robjects as ro\n",
        "    from rpy2.robjects import pandas2ri\n",
        "    from rpy2.robjects.conversion import localconverter\n",
        "    \n",
        "    # Query Snowflake using the session\n",
        "    orders_df = session.sql(\"\"\"\n",
        "        SELECT O_ORDERKEY, O_CUSTKEY, O_ORDERSTATUS, \n",
        "               O_TOTALPRICE::FLOAT as O_TOTALPRICE, \n",
        "               O_ORDERDATE\n",
        "        FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.ORDERS\n",
        "        WHERE O_ORDERDATE >= '1995-01-01'\n",
        "        LIMIT 10000\n",
        "    \"\"\").to_pandas()\n",
        "    \n",
        "    # Transfer to R\n",
        "    with localconverter(ro.default_converter + pandas2ri.converter):\n",
        "        r_orders = ro.conversion.py2rpy(orders_df)\n",
        "        ro.globalenv['sf_orders'] = r_orders\n",
        "    \n",
        "    print(f\"‚úì Loaded {len(orders_df)} rows into R variable 'sf_orders'\")\n",
        "    print(\"Now you can use dplyr in R cells to analyze 'sf_orders'\")\n",
        "else:\n",
        "    print(\"In local IDE - use the DuckDB approach above instead\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-bridge-analysis",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Analyze data transferred via Python bridge\n",
        "# This cell works in Workspace Notebooks without DuckDB\n",
        "\n",
        "if (exists(\"sf_orders\")) {\n",
        "    library(dplyr)\n",
        "    \n",
        "    result <- sf_orders %>%\n",
        "        mutate(order_year = format(O_ORDERDATE, \"%Y\")) %>%\n",
        "        group_by(order_year, O_ORDERSTATUS) %>%\n",
        "        summarise(\n",
        "            orders = n(),\n",
        "            total_value = sum(O_TOTALPRICE, na.rm = TRUE),\n",
        "            .groups = \"drop\"\n",
        "        ) %>%\n",
        "        arrange(order_year, desc(orders))\n",
        "    \n",
        "    cat(\"Order analysis using dplyr (via Python bridge):\\n\")\n",
        "    rprint(result)\n",
        "} else {\n",
        "    cat(\"Note: sf_orders not found. Run the Python bridge cell above first.\\n\")\n",
        "    cat(\"Or use the DuckDB approach if in local IDE.\\n\")\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "duckdb-query-examples",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 7.4 Query Snowflake with dplyr\n",
        "\n",
        "The recommended pattern for dplyr workflows:\n",
        "1. **Direct SQL** for fetching data from Snowflake\n",
        "2. **Cache locally** in DuckDB for iterative analysis\n",
        "3. **Use dplyr** on local cached tables\n",
        "\n",
        "**Important**: Use 2-part table names (`sf.schema.table`) when database is set in the secret."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-direct-sql",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Pattern 1: Direct SQL Query to Snowflake\n",
        "# Best for: simple aggregations, data exploration\n",
        "\n",
        "cat(\"Direct SQL query to Snowflake...\\n\\n\")\n",
        "\n",
        "tryCatch({\n",
        "    # Note: Use sf.schema.table format (database set in secret)\n",
        "    customers <- dbGetQuery(duckdb_con, \"\n",
        "        SELECT C_MKTSEGMENT, COUNT(*) as customers, ROUND(AVG(C_ACCTBAL), 2) as avg_balance\n",
        "        FROM sf.tpch_sf1.customer\n",
        "        GROUP BY C_MKTSEGMENT\n",
        "        ORDER BY customers DESC\n",
        "    \")\n",
        "    \n",
        "    cat(\"Customer analysis by market segment:\\n\")\n",
        "    rprint(customers)\n",
        "    \n",
        "}, error = function(e) {\n",
        "    cat(\"Error:\", conditionMessage(e), \"\\n\")\n",
        "    cat(\"Note: Ensure database is set in secret (e.g., SNOWFLAKE_SAMPLE_DATA)\\n\")\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-dplyr-query",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Pattern 2: Cache locally, then use dplyr\n",
        "# Best for: complex analysis, joins, window functions\n",
        "\n",
        "cat(\"Caching Snowflake data locally for dplyr analysis...\\n\\n\")\n",
        "\n",
        "tryCatch({\n",
        "    # Cache data from Snowflake into local DuckDB table\n",
        "    dbExecute(duckdb_con, \"\n",
        "        CREATE OR REPLACE TABLE orders_local AS \n",
        "        SELECT O_ORDERKEY, O_CUSTKEY, O_ORDERSTATUS, O_TOTALPRICE, O_ORDERDATE, O_ORDERPRIORITY\n",
        "        FROM sf.tpch_sf1.orders\n",
        "        LIMIT 50000\n",
        "    \")\n",
        "    cat(\"‚úì Cached 50,000 orders locally\\n\\n\")\n",
        "    \n",
        "    # Now use dplyr on the local table - fast and featureful!\n",
        "    analysis <- tbl(duckdb_con, \"orders_local\") %>%\n",
        "        mutate(\n",
        "            order_year = year(O_ORDERDATE),\n",
        "            priority = case_when(\n",
        "                O_ORDERPRIORITY %in% c(\"1-URGENT\", \"2-HIGH\") ~ \"High\",\n",
        "                TRUE ~ \"Normal\"\n",
        "            )\n",
        "        ) %>%\n",
        "        group_by(order_year, O_ORDERSTATUS, priority) %>%\n",
        "        summarise(\n",
        "            orders = n(),\n",
        "            total_value = sum(O_TOTALPRICE, na.rm = TRUE),\n",
        "            .groups = 'drop'\n",
        "        ) %>%\n",
        "        arrange(order_year, O_ORDERSTATUS) %>%\n",
        "        collect()\n",
        "    \n",
        "    cat(\"Order analysis with dplyr:\\n\")\n",
        "    rprint(head(analysis, 10))\n",
        "    \n",
        "}, error = function(e) {\n",
        "    cat(\"Error:\", conditionMessage(e), \"\\n\")\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "duckdb-cache-pattern",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 7.5 Advanced Patterns\n",
        "\n",
        "Additional patterns for DuckDB + Snowflake workflows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-cache-example",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Pattern 3: Join local cached tables\n",
        "# Best for: combining reference data with transactional data\n",
        "\n",
        "cat(\"Caching reference tables for joins...\\n\\n\")\n",
        "\n",
        "tryCatch({\n",
        "    # Cache reference tables\n",
        "    dbExecute(duckdb_con, \"CREATE OR REPLACE TABLE nations AS SELECT * FROM sf.tpch_sf1.nation\")\n",
        "    dbExecute(duckdb_con, \"CREATE OR REPLACE TABLE regions AS SELECT * FROM sf.tpch_sf1.region\")\n",
        "    cat(\"‚úì Reference tables cached\\n\\n\")\n",
        "    \n",
        "    # Join using dplyr\n",
        "    result <- tbl(duckdb_con, \"nations\") %>%\n",
        "        inner_join(tbl(duckdb_con, \"regions\"), by = c(\"N_REGIONKEY\" = \"R_REGIONKEY\")) %>%\n",
        "        select(nation = N_NAME, region = R_NAME) %>%\n",
        "        arrange(region, nation) %>%\n",
        "        collect()\n",
        "    \n",
        "    cat(\"Nations by Region:\\n\")\n",
        "    rprint(result)\n",
        "    \n",
        "}, error = function(e) {\n",
        "    cat(\"Error:\", conditionMessage(e), \"\\n\")\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-window-functions",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Pattern 4: Window functions with dplyr\n",
        "# Best for: rankings, running totals, lead/lag analysis\n",
        "\n",
        "cat(\"Window functions on cached data...\\n\\n\")\n",
        "\n",
        "tryCatch({\n",
        "    # Ensure orders_local exists from previous cell\n",
        "    if (!dbExistsTable(duckdb_con, \"orders_local\")) {\n",
        "        dbExecute(duckdb_con, \"\n",
        "            CREATE TABLE orders_local AS \n",
        "            SELECT O_ORDERKEY, O_CUSTKEY, O_ORDERSTATUS, O_TOTALPRICE, O_ORDERDATE\n",
        "            FROM sf.tpch_sf1.orders\n",
        "            LIMIT 50000\n",
        "        \")\n",
        "    }\n",
        "    \n",
        "    # Top customers by total order value\n",
        "    top_customers <- tbl(duckdb_con, \"orders_local\") %>%\n",
        "        group_by(O_CUSTKEY) %>%\n",
        "        summarise(\n",
        "            orders = n(),\n",
        "            total_value = sum(O_TOTALPRICE, na.rm = TRUE),\n",
        "            avg_order = mean(O_TOTALPRICE, na.rm = TRUE),\n",
        "            .groups = 'drop'\n",
        "        ) %>%\n",
        "        arrange(desc(total_value)) %>%\n",
        "        head(10) %>%\n",
        "        collect()\n",
        "    \n",
        "    cat(\"Top 10 customers by total order value:\\n\")\n",
        "    rprint(top_customers)\n",
        "    \n",
        "}, error = function(e) {\n",
        "    cat(\"Error:\", conditionMessage(e), \"\\n\")\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "duckdb-cleanup",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "## 7.6 Cleanup\n",
        "\n",
        "Close the DuckDB connection when done."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duckdb-cleanup-cell",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "%%R\n",
        "# Cleanup: Disconnect from DuckDB\n",
        "# Uncomment to close connection\n",
        "\n",
        "# dbDisconnect(duckdb_con)\n",
        "# cat(\"DuckDB connection closed\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e96125a8-ea1b-4e54-bacb-f106bf2cee79",
      "metadata": {
        "codeCollapsed": true
      },
      "source": [
        "---\n",
        "\n",
        "## Troubleshooting\n",
        "\n",
        "### Common Issues\n",
        "\n",
        "| Issue | Solution |\n",
        "|-------|----------|\n",
        "| `ModuleNotFoundError: No module named 'rpy2'` | Run Section 1.2 to install rpy2 |\n",
        "| `R.version.string` returns error | Verify PATH and R_HOME are set correctly |\n",
        "| ADBC `auth_pat` error | Ensure PAT was created and stored in `SNOWFLAKE_PAT` |\n",
        "| Network policy error | PAT may need `MINS_TO_BYPASS_NETWORK_POLICY_REQUIREMENT` |\n",
        "| `adbcsnowflake` not found | Ensure setup script ran with `--adbc` flag |\n",
        "| Setup script fails | Check `setup_r.log` for detailed error messages |\n",
        "| `r_sf_con` not found | Run `get_snowflake_connection()` to create connection |\n",
        "\n",
        "### Run Full Diagnostics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3f31ce02-b7b8-4cc0-a2fb-38e3b45bfedd",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Comprehensive diagnostic check\n",
        "from r_helpers import print_diagnostics\n",
        "print_diagnostics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fdef786-f0f5-474c-8faa-b6af52a56ef1",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# Quick environment check\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "print(\"Quick Environment Check:\")\n",
        "print(f\"  R_HOME: {os.environ.get('R_HOME', 'NOT SET')}\")\n",
        "print(f\"  R binary: {shutil.which('R') or 'NOT FOUND'}\")\n",
        "print(f\"  SNOWFLAKE_ACCOUNT: {os.environ.get('SNOWFLAKE_ACCOUNT', 'NOT SET')}\")\n",
        "print(f\"  SNOWFLAKE_PAT: {'SET' if os.environ.get('SNOWFLAKE_PAT') else 'NOT SET'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fcf4f8e4-213b-40a0-9e54-1a97208b7646",
      "metadata": {
        "language": "python"
      },
      "outputs": [],
      "source": [
        "# View setup log if something went wrong\n",
        "# !tail -50 setup_r.log"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
