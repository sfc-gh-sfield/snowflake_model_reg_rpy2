{
  "metadata": {
    "kernelspec": {
      "display_name": "Jupyter Notebook",
      "name": "jupyter"
    }
  },
  "nbformat_minor": 5,
  "nbformat": 4,
  "cells": [
    {
      "id": "d00181a1-f377-4cad-a563-598763ac499c",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Python Packages"
    },
    {
      "id": "0ee09cad-1093-4b71-b7cc-0a0de5d3a7ee",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "!pip install tabulate\n!pip install -U ipywidgets",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "f40faa05-1a3b-49be-9204-b7f30b662681",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "### Packages\n## Python packages\nimport os\nfrom os import listdir\nfrom os.path import isfile, join\nfrom datetime import date, datetime\nimport time \nfrom decimal import Decimal\nimport numpy as np\nimport pandas as pd\npd.set_option('display.max_colwidth', 500)\nimport tabulate\nfrom pathlib import Path\nimport json\n\n## SNOWFLAKE\n\n## Snowpark\nfrom snowflake.snowpark.version import VERSION\nfrom snowflake.snowpark import functions as F, types as T\nfrom snowflake.snowpark.types import StringType\n# Snowpark functions representing some SQL functions we need\n# tryparsejson = F.builtin('TRY_PARSE_JSON')\n# timestampadd = F.builtin('TIMESTAMPADD')\n# \n# from snowflake.ml.utils import connection_params\n# \n# # Snowflake ML preprocessing\n# from snowflake.ml.modeling.preprocessing import OrdinalEncoder\n# \n# # Model Registry\n# from snowflake.ml.registry import registry\n# from snowflake.ml.model import custom_model\n# from typing import Optional\n# from snowflake.ml.model.model_signature import FeatureSpec, DataType, ModelSignature",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5c26bd23-b9d9-4a42-a329-9a1fd5b72670",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Python Database Session"
    },
    {
      "id": "6e070841-6b78-4fc7-915b-756d05dc08e3",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Source Data Database and Schema\nsrc_database = 'SIMON'\nsrc_schema = 'RPY2' # <-- Modify this if you want to test with one of the larger data scale-factors. e.g. TPCH_SF1, TPCH_SF10, TPCH_SF100, TPCH_SF1000\n\n# Database to use to create Schemas\nsess_db = 'SIMON' # The database within which we will create our Feature Store (schema), and data-source schema.",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "26ea1bf2-6ab4-4802-b627-a177d61e9b71",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# CREATE SESSION\n# ## Using Snowflake Notebook\nfrom snowflake.snowpark.context import get_active_session\n\nsession = get_active_session()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "15003b54-e2aa-4da3-9345-e44edf7057b4",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "session.sql_simplifier_enabled = True\n\n# Capture and Print the Current Environment Details\nsnowflake_environment = session.sql('SELECT current_user(), current_version()').collect()\nsnowpark_version = VERSION\nsession_role = session.get_current_role().replace('\"', \"\")\nsession.use_database(src_database)\nsession.use_schema(src_schema)\nsession_database = session.get_current_database().replace('\"', \"\")\nsession_schema = session.get_current_schema().replace('\"', \"\")\nsession_vw = session.get_current_warehouse().replace('\"', \"\")\n\nvw_status = session.sql(f\"\"\"show warehouses like '{session_vw}' \"\"\").collect()[0]\nvw_type = vw_status['type']\nvw_state = vw_status['state']\nvw_size = vw_status['size'].upper()\nvw_available = vw_status['available']\nprint('================================================================================')\nprint('\\nConnection Established with the following parameters:')\nprint(f'Account                      : {session.sql(\"select current_account()\").collect()[0][0]}')\nprint(f'User                         : {snowflake_environment[0][0]}')\nprint(f'Role                         : {session_role}')\nprint(f'Database                     : {session.get_current_database().replace('\"', \"\")}')\nprint(f'Schema                       : {session.get_current_schema().replace('\"', \"\")}')\nprint(f'Warehouse Name               : {session_vw}')\nprint(f'Warehouse Type               : {vw_type}')\nprint(f'Warehouse State              : {vw_state}')\nprint(f'Warehouse Size               : {vw_size}')\nprint(f'Warehouse Available Resource :{vw_available}')\nprint(f'Snowflake version            : {snowflake_environment[0][1]}')\nprint(f'Snowpark for Python version  : {snowpark_version[0]}.{snowpark_version[1]}.{snowpark_version[2]} \\n')",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "6979ca9d-5809-442e-bcc3-f10953b34683",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Oauth token exists in Notebook File-System"
    },
    {
      "cell_type": "code",
      "id": "74aeb609-7937-4f12-82a2-5f201c33e44a",
      "metadata": {
        "language": "python"
      },
      "source": "\n! [ -f /snowflake/session/token ] && echo \"SPCS OAuth token file is present\" || echo \"No token file\"\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "id": "56d68ca5-41c0-4614-b7db-d20065492f7c",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "! ls -l /snowflake/session 2>/dev/null || echo \"No /snowflake/session directory\"",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "47c78019-1219-41a3-9f3a-4549be888e9a",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import os\nprint(\"Token file exists:\", os.path.isfile(\"/snowflake/session/token\"))",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5b9c26f1-e558-4341-814d-1ccef5f9a9d3",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Install R, ADBC & requested R Packages"
    },
    {
      "id": "ed876b64-c333-44dd-a62d-a254814af723",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "!bash setup_r_micromamba_adbc.sh",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "711428a2-c611-44ef-acd4-498b6f874a76",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Configure the R Environment & iPython magic"
    },
    {
      "id": "3f5282b7-1824-4838-a7c0-207b97a13377",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import os, sys, subprocess\n\n# Point kernel Python to the R env we created\nENV_PREFIX = \"/root/.local/share/mamba/envs/r_env\"  # from script output\n\nos.environ[\"PATH\"] = f\"{ENV_PREFIX}/bin:\" + os.environ[\"PATH\"]\nos.environ[\"R_HOME\"] = f\"{ENV_PREFIX}/lib/R\"\n\nprint(\"Kernel Python:\", sys.executable)\nprint(\"R_HOME:\", os.environ[\"R_HOME\"])\n\n# Install rpy2 into THIS Python (the notebook venv), no --user\nsubprocess.run(\n    [sys.executable, \"-m\", \"pip\", \"install\", \"rpy2\"],\n    check=True,\n)\n# Add %%R magic so we can use R from within Python Notebook cells\nfrom rpy2.ipython import rmagic\nip = get_ipython()\nip.register_magics(rmagic.RMagics)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "731bb337-e0f6-4c05-b479-cdb3933a2ff3",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "%%R\nR.version.string",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1a340b9f-d1fb-4f21-81a6-20ebd0989ee6",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "### Working with Dataframes"
    },
    {
      "id": "c3feb7d7-5eac-4d95-88c6-355aad228d84",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "We show how we can inter-operate with R dataframes and Pandas Dataframes.\n\n#### Using Python"
    },
    {
      "id": "26fbc4f2-4303-49cb-b8ef-a08c3b2ef31c",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from functools import partial\nfrom rpy2.ipython import html\nfrom rpy2.robjects.packages import importr\n# Import R package - Utils\nutils = importr('utils')\n\nhtml.html_rdataframe=partial(html.html_rdataframe, table_class=\"docutils\")\n\ndataf = utils.read_csv('https://raw.githubusercontent.com/jakevdp/PythonDataScienceHandbook/refs/heads/master/notebooks_v1/data/california_cities.csv')\n\n# import rpy2.ipython.html\nrpy2.ipython.html.init_printing()\n\ndataf",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "beda1630-a2e7-469c-8b4a-3be4eee7ade1",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# R Dataframe column names\ndataf.colnames",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "62ef6ef8-d84d-47e9-aa86-c67b8f028bc0",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# R Linear Regression\nstats = importr('stats')\nbase = importr('base')\nstats.lm('elevation_m ~ latd + longd', data=dataf)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "dde0e380-807d-480a-a7ad-4f7e6275f53f",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "%%R -i dataf\n# Pass the Python object into R (%%R) using -i (above), and make use of it in an R cell.\nrequire(dplyr)\nglimpse(dataf)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "af19e201-2ce6-4451-850a-6708266e06bf",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Create and print a Pandas Dataframe"
    },
    {
      "id": "9f69013b-4c09-46a3-9e9a-bef5a59c9a91",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import pandas as pd\nimport rpy2.robjects as ro\nfrom rpy2.robjects.packages import importr\nfrom rpy2.robjects import pandas2ri\n\npd_df = pd.DataFrame({'int_values': [1,2,3],\n                      'str_values': ['abc', 'def', 'ghi']})\n\npd_df",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ba0cbf2a-2edd-4695-a67e-d34267cfa5f9",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "print(pd_df)\nprint('\\n\\n')\nprint(pd_df.to_markdown())",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ecb55c9d-8c59-406f-919a-75961609714c",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Convert the Python Pandas Dataframe to an R Dataframe\nwith (ro.default_converter + pandas2ri.converter).context():\n  r_from_pd_df = ro.conversion.get_conversion().py2rpy(pd_df)\n\nr_from_pd_df",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c5c1c73a-b24a-4954-9ff1-5d58edf52546",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "Convert Pandas dataframe to R dataframe, and print it."
    },
    {
      "id": "0d8734fd-53bf-4352-8da0-cc9b2dfe19b9",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# Run an R summary on the Pandas Dataframe (inline conversion).\n# Result returned as Pandas dataframe for printing\nwith (ro.default_converter + pandas2ri.converter).context():\n  df_summary = base.summary(pd_df)\n\n#print(df_summary)\nprint(df_summary)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "80bda6dd-c32e-4ef8-a776-4b56520caae8",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from rpy2 import robjects as ro\nfrom rpy2.robjects import pandas2ri\nfrom rpy2.robjects.conversion import localconverter\n\n# Load iris into the R session (it’s in the 'datasets' package), imported by default\nro.r(\"data(iris)\")\n\n# Grab the R data.frame, and assign to a python variable\niris_r = ro.r[\"iris\"]\n\n# Convert inside a local converter context to a Pandas Dataframe, to display it using Notebook\nwith localconverter(ro.default_converter + pandas2ri.converter):\n    iris_df = pandas2ri.rpy2py(iris_r)\n\niris_df.head()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "1986bdf4-5c41-464d-9099-0224d397712b",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "from rpy2.robjects import r\n# Get the installed packages in our R environment\nro.r(\"ip =  as.data.frame(installed.packages()[,c(1,3:4)])\")\nip_pyt = ro.r(\"ip[is.na(ip$Priority),1:2,drop=FALSE]\")\nprint(ip_pyt)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "abc70523-dcc7-409d-8109-843cd4c68b99",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "%%R \n# Get the installed packages in an R cell (R%%) \n# Create an R dataframe \nipr <- as.data.frame(installed.packages()[,c(1,3:4)])\nipr <- ip[is.na(ip$Priority),1:2,drop=FALSE]\n# Doesnt pring very nicely!!\nprint(ipr)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "bf500f9b-793a-4f00-8b7e-934dfba625c9",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "# But we can grab the R dataframe (ipr) from the R environment in a Python cell, and print it from Python.\nprint(ro.r.ipr)",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4198dfa9-cc54-4c31-8447-1de7201e66f7",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "%%bash\n# Make sure micromamba is on PATH\nexport PATH=\"$HOME/micromamba/bin:$PATH\"\n\n# Install Go into the existing r_env\nmicromamba install -y -n r_env -c conda-forge go",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "5f0e59e5-78cc-4822-bc93-fb344d940115",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "## Install ADBC\nWe installed GO from micromamba during the R installation script.  We needed it install the snowflake adbc package that needs to be compiled with GO during installation"
    },
    {
      "id": "7fd25e7d-f994-4570-9171-3aea26a2df12",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "%%R\n# Point GO_BIN at the go inside r_env\nSys.setenv(\n  GO_BIN = file.path(\n    Sys.getenv(\"HOME\"),\n    \".local/share/mamba/envs/r_env/bin/go\"\n  )\n)\n\ncat(\"GO_BIN =\", Sys.getenv(\"GO_BIN\"), \"\\n\")\n\ninstall.packages(\"adbcsnowflake\", repos = \"https://community.r-multiverse.org\")",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "c362bb63-d983-4b4e-b0b0-621830104e17",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "#### Using OAuth Token stored in Container"
    },
    {
      "id": "b389202f-5a9e-4874-9e80-e4d5bb4ada9e",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "```\n%%R\nlibrary(adbcdrivermanager)\nlibrary(adbcsnowflake)\n\ntoken <- readLines(\"/snowflake/session/token\", warn = FALSE)\n\ndb <- adbc_database_init(\n  adbcsnowflake::adbcsnowflake(),\n  `adbc.snowflake.sql.account`                  = Sys.getenv(\"SNOWFLAKE_ACCOUNT\"),\n  `adbc.snowflake.sql.client_option.auth_token` = token,\n  `adbc.snowflake.sql.auth_type`                = \"auth_oauth\",\n  `adbc.snowflake.sql.db`                       = Sys.getenv(\"SNOWFLAKE_DATABASE\"),\n  `adbc.snowflake.sql.schema`                   = Sys.getenv(\"SNOWFLAKE_SCHEMA\"),\n  `adbc.snowflake.sql.warehouse`                = \"YOUR_WH\"\n)\ncon <- adbc_connection_init(db)\nstmt <- adbc_statement_init(con)\nadbc_statement_set_sql_query(stmt, \"SELECT CURRENT_USER(), CURRENT_ROLE(), CURRENT_WAREHOUSE()\")\nres <- adbc_statement_execute_query(stmt)\nres\n```\nThis doesnt work.  You cant make use of the OAuth token that Snowflake injects into the container at start up for this purpose.\n\n\n```\nIO: [Snowflake] 395092 (08004): Error connecting to Snowflake via Snowpark Container Services. Client is unauthorized to use Snowpark Container Services OAuth token.\n```",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "95a23438-dedb-4587-9f90-a26ee62e6c68",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "#### Using conventional username and password.\n\n__Python Cell__\n```\nimport os\n\n# TEMP for testing – don't check this into git\nos.environ[\"SNOWFLAKE_PASSWORD\"] = \"yourpasswordhere\"\n```\n\n__R Cell__\n```\n%%R\nlibrary(adbcdrivermanager)\nlibrary(adbcsnowflake)\n\n# Sanity check on env\nSys.getenv(c(\n  \"SNOWFLAKE_ACCOUNT\",\n  \"SNOWFLAKE_HOST\",\n  \"SNOWFLAKE_DATABASE\",\n  \"SNOWFLAKE_SCHEMA\",\n  \"SNOWFLAKE_USER\",\n  \"SNOWFLAKE_PASSWORD\"\n))\n\ndb <- adbc_database_init(\n  adbcsnowflake::adbcsnowflake(),\n  # core auth\n  username                          = Sys.getenv(\"SNOWFLAKE_USER\"),\n  password                          = Sys.getenv(\"SNOWFLAKE_PASSWORD\"),\n\n  # connection context\n  `adbc.snowflake.sql.account`      = Sys.getenv(\"SNOWFLAKE_ACCOUNT\"),\n  `adbc.snowflake.sql.uri.host`     = Sys.getenv(\"SNOWFLAKE_HOST\"),\n\n  # session defaults\n  `adbc.snowflake.sql.db`           = Sys.getenv(\"SNOWFLAKE_DATABASE\"),\n  `adbc.snowflake.sql.schema`       = Sys.getenv(\"SNOWFLAKE_SCHEMA\"),\n  `adbc.snowflake.sql.warehouse`    = \"COMPUTE_WH\"   # <- change to a real warehouse\n)\n\ncon  <- adbc_connection_init(db)\nstmt <- adbc_statement_init(con)\n\nadbc_statement_set_sql_query(\n  stmt,\n  \"SELECT CURRENT_USER(), CURRENT_ROLE(), CURRENT_WAREHOUSE()\"\n)\n\nres <- adbc_statement_execute_query(stmt)\nres\n```\nThis doesnt work either\n\n```\n[Snowflake] 395090 (08004): Error connecting to Snowflake via Snowpark Container Services. Please use OAuth when connecting to Snowflake. For more information please refer to https://docs.snowflake.com/en/developer-guide/snowpark-container-services/additional-considerations-services-jobs#connecting-to-snowflake-from-inside-a-container.'\n```"
    },
    {
      "id": "fcfffbc0-e6c8-4982-86a1-6d8bf060ebf4",
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "codeCollapsed": true
      },
      "source": "#### Using Programmatic Access Token (PAT)"
    },
    {
      "id": "d9deea99-9849-455d-910b-2d6df9326d0d",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "session.sql('''\nALTER USER SIMON REMOVE PROGRAMMATIC ACCESS TOKEN r_notebook_pat;\n''').collect()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "7cbab655-ebb1-4562-bd20-d4b8604d9841",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "pat_df = session.sql('''\nALTER USER SIMON\nADD PROGRAMMATIC ACCESS TOKEN r_notebook_pat\n  ROLE_RESTRICTION = 'SYSADMIN'\n  DAYS_TO_EXPIRY   = 1              -- short-lived for testing\n  MINS_TO_BYPASS_NETWORK_POLICY_REQUIREMENT = 240  -- 4 hours\n  COMMENT = 'PAT for R/ADBC test from Notebook';\n  ''').collect()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "0dd99414-1e99-4169-b04a-b3d6ea6480c5",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "import os\nos.environ[\"SNOWFLAKE_PAT\"] = pat_df[0]['token_secret']",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "8a21ba05-80ef-42a9-9239-1673e772402a",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "%%R\nlibrary(adbcdrivermanager)\nlibrary(adbcsnowflake)\n\n# Read connection context from environment\naccount   <- Sys.getenv(\"SNOWFLAKE_ACCOUNT\")\nuser      <- Sys.getenv(\"SNOWFLAKE_USER\")\ndatabase  <- Sys.getenv(\"SNOWFLAKE_DATABASE\")\nschema    <- Sys.getenv(\"SNOWFLAKE_SCHEMA\")\nwarehouse <- Sys.getenv(\"SNOWFLAKE_WAREHOUSE\")\nrole      <- Sys.getenv(\"SNOWFLAKE_ROLE\")          # may be empty, that's fine\npat       <- Sys.getenv(\"SNOWFLAKE_PAT\")\npublic_host <- Sys.getenv(\"SNOWFLAKE_PUBLIC_HOST\") # optional\n\nif (identical(pat, \"\")) {\n  stop(\"SNOWFLAKE_PAT is not set; cannot authenticate with PAT.\")\n}\n\n# Sanity check (optional)\ncat(\"Account  :\", account,  \"\\n\")\ncat(\"User     :\", user,     \"\\n\")\ncat(\"Database :\", database, \"\\n\")\ncat(\"Schema   :\", schema,   \"\\n\")\ncat(\"Warehouse:\", warehouse, \"\\n\")\ncat(\"Role     :\", role,     \"\\n\")\ncat(\"Public host:\", if (nzchar(public_host)) public_host else \"<driver default>\", \"\\n\")\n\n# Build the ADBC Snowflake database handle\nif (nzchar(public_host)) {\n  db <- adbc_database_init(\n    adbcsnowflake::adbcsnowflake(),\n\n    # Core identity (user may be required even with PAT)\n    username                          = user,\n\n    # Connection context\n    `adbc.snowflake.sql.account`      = account,\n    `adbc.snowflake.sql.uri.host`     = public_host,\n\n    # Session defaults\n    `adbc.snowflake.sql.db`           = database,\n    `adbc.snowflake.sql.schema`       = schema,\n    `adbc.snowflake.sql.warehouse`    = warehouse,\n    `adbc.snowflake.sql.role`         = role,\n\n    # Authentication: Programmatic Access Token\n    `adbc.snowflake.sql.auth_type`                = \"auth_pat\",\n    `adbc.snowflake.sql.client_option.auth_token` = pat\n  )\n} else {\n  # Let driver infer host from account/region\n  db <- adbc_database_init(\n    adbcsnowflake::adbcsnowflake(),\n\n    username                          = user,\n    `adbc.snowflake.sql.account`      = account,\n    `adbc.snowflake.sql.db`           = database,\n    `adbc.snowflake.sql.schema`       = schema,\n    `adbc.snowflake.sql.warehouse`    = warehouse,\n    `adbc.snowflake.sql.role`         = role,\n\n    `adbc.snowflake.sql.auth_type`                = \"auth_pat\",\n    `adbc.snowflake.sql.client_option.auth_token` = pat\n  )\n}\n\n# Open a connection and run a test query\ncon  <- adbc_connection_init(db)\nstmt <- adbc_statement_init(con)\n\nadbc_statement_set_sql_query(\n  stmt,\n  \"SELECT 'THIS_COLUMN' as THIS_COLUMN \"\n)\n\nres <- adbc_statement_execute_query(stmt)\nres",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "ea4e10e5-6375-458e-a670-0dd4867640e2",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "%%R \ncon |>\n  read_adbc(\"SELECT 'THIS_COLUMN' as THIS_COLUMN \") |>\n  tibble::as_tibble()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "4f5d65c8-32f2-4646-8463-9cb6b328f72d",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "%%R \ncon |>\n  read_adbc(\"SELECT N_NATIONKEY, N_NAME FROM SNOWFLAKE_SAMPLE_DATA.TPCH_SF1.NATION LIMIT 10\") |>\n  tibble::as_tibble()",
      "outputs": [],
      "execution_count": null
    },
    {
      "id": "e1e82f3b-c9c7-4f2b-b462-343e0fb8143d",
      "cell_type": "code",
      "metadata": {
        "language": "python"
      },
      "source": "",
      "outputs": [],
      "execution_count": null
    }
  ]
}